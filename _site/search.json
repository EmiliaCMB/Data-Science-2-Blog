[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This blog encompasses a variety of Data Science projects."
  },
  {
    "objectID": "Analyse.html",
    "href": "Analyse.html",
    "title": "Analyse",
    "section": "",
    "text": "library(tidyverse)\n\n-- Attaching packages --------------------------------------- tidyverse 1.3.1 --\n\n\nv ggplot2 3.4.4     v purrr   1.0.1\nv tibble  3.2.1     v dplyr   1.1.2\nv tidyr   1.2.0     v stringr 1.5.0\nv readr   2.1.2     v forcats 0.5.1\n\n\n-- Conflicts ------------------------------------------ tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\n\nlibrary(tokenizers)\nlibrary(tidyverse)\nlibrary(tidytext)\nlibrary(hcandersenr)\nlibrary(SnowballC)  # Stemming\nlibrary(lsa)  # Stopwörter\nlibrary(easystats)  # Komfort für deskriptive Statistiken, wie `describe_distribution`\n\n# Attaching packages: easystats 0.6.0 (red = needs update)\nv bayestestR  0.13.1   v correlation 0.8.4 \nx datawizard  0.7.1    x effectsize  0.8.3 \nx insight     0.19.2   v modelbased  0.8.6 \nx performance 0.10.3   x parameters  0.21.0\nx report      0.5.7    v see         0.8.1 \n\nRestart the R-Session and update packages in red with `easystats::easystats_update()`.\n\nlibrary(textclean)  # Emojis ersetzen\nlibrary(wordcloud)\n\nLade nötiges Paket: RColorBrewer"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html",
    "title": "Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ dataset_summary | default(““, true) }}\n\n\n\n\n\n{{ dataset_description | default(““, true) }}\n\nCurated by: {{ curators | default(“[More Information Needed]”, true)}}\nFunded by [optional]: {{ funded_by | default(“[More Information Needed]”, true)}}\nShared by [optional]: {{ shared_by | default(“[More Information Needed]”, true)}}\nLanguage(s) (NLP): {{ language | default(“[More Information Needed]”, true)}}\nLicense: {{ license | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\nRepository: {{ repo | default(“[More Information Needed]”, true)}}\nPaper [optional]: {{ paper | default(“[More Information Needed]”, true)}}\nDemo [optional]: {{ demo | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n\n\n\n\n{{ direct_use | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ out_of_scope_use | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n{{ dataset_structure | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n{{ curation_rationale_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n\n{{ data_collection_and_processing_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ source_data_producers_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n\n\n{{ annotation_process_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ who_are_annotators_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ personal_and_sensitive_information | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n{{ bias_risks_limitations | default(“[More Information Needed]”, true)}}\n\n\n\n{{ bias_recommendations | default(“Users should be made aware of the risks, biases and limitations of the dataset. More information needed for further recommendations.”, true)}}\n\n\n\n\n\nBibTeX:\n{{ citation_bibtex | default(“[More Information Needed]”, true)}}\nAPA:\n{{ citation_apa | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ glossary | default(“[More Information Needed]”, true)}}\n\n\n\n{{ more_information | default(“[More Information Needed]”, true)}}\n\n\n\n{{ dataset_card_authors | default(“[More Information Needed]”, true)}}\n\n\n\n{{ dataset_card_contact | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-details",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-details",
    "title": "Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ dataset_description | default(““, true) }}\n\nCurated by: {{ curators | default(“[More Information Needed]”, true)}}\nFunded by [optional]: {{ funded_by | default(“[More Information Needed]”, true)}}\nShared by [optional]: {{ shared_by | default(“[More Information Needed]”, true)}}\nLanguage(s) (NLP): {{ language | default(“[More Information Needed]”, true)}}\nLicense: {{ license | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\nRepository: {{ repo | default(“[More Information Needed]”, true)}}\nPaper [optional]: {{ paper | default(“[More Information Needed]”, true)}}\nDemo [optional]: {{ demo | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#uses",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#uses",
    "title": "Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ direct_use | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ out_of_scope_use | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-structure",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-structure",
    "title": "Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ dataset_structure | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-creation",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-creation",
    "title": "Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ curation_rationale_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n\n{{ data_collection_and_processing_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ source_data_producers_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n\n\n{{ annotation_process_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ who_are_annotators_section | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ personal_and_sensitive_information | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#bias-risks-and-limitations",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#bias-risks-and-limitations",
    "title": "Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ bias_risks_limitations | default(“[More Information Needed]”, true)}}\n\n\n\n{{ bias_recommendations | default(“Users should be made aware of the risks, biases and limitations of the dataset. More information needed for further recommendations.”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#citation-optional",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#citation-optional",
    "title": "Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "BibTeX:\n{{ citation_bibtex | default(“[More Information Needed]”, true)}}\nAPA:\n{{ citation_apa | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#glossary-optional",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#glossary-optional",
    "title": "Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ glossary | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#more-information-optional",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#more-information-optional",
    "title": "Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ more_information | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-card-authors-optional",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-card-authors-optional",
    "title": "Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ dataset_card_authors | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-card-contact",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/datasetcard_template.html#dataset-card-contact",
    "title": "Dataset Card for {{ pretty_name | default(“Dataset Name”, true) }}",
    "section": "",
    "text": "{{ dataset_card_contact | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ model_summary | default(““, true) }}\n\n\n\n\n\n{{ model_description | default(““, true) }}\n\nDeveloped by: {{ developers | default(“[More Information Needed]”, true)}}\nFunded by [optional]: {{ funded_by | default(“[More Information Needed]”, true)}}\nShared by [optional]: {{ shared_by | default(“[More Information Needed]”, true)}}\nModel type: {{ model_type | default(“[More Information Needed]”, true)}}\nLanguage(s) (NLP): {{ language | default(“[More Information Needed]”, true)}}\nLicense: {{ license | default(“[More Information Needed]”, true)}}\nFinetuned from model [optional]: {{ base_model | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\nRepository: {{ repo | default(“[More Information Needed]”, true)}}\nPaper [optional]: {{ paper | default(“[More Information Needed]”, true)}}\nDemo [optional]: {{ demo | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n\n\n\n{{ direct_use | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ downstream_use | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ out_of_scope_use | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n{{ bias_risks_limitations | default(“[More Information Needed]”, true)}}\n\n\n\n{{ bias_recommendations | default(“Users (both direct and downstream) should be made aware of the risks, biases and limitations of the model. More information needed for further recommendations.”, true)}}\n\n\n\n\nUse the code below to get started with the model.\n{{ get_started_code | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n{{ training_data | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n{{ preprocessing | default(“[More Information Needed]”, true)}}\n\n\n\n\nTraining regime: {{ training_regime | default(“[More Information Needed]”, true)}} \n\n\n\n\n\n{{ speeds_sizes_times | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n\n\n\n\n\n{{ testing_data | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ testing_factors | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ testing_metrics | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ results | default(“[More Information Needed]”, true)}}\n\n\n{{ results_summary | default(““, true) }}\n\n\n\n\n\n\n{{ model_examination | default(“[More Information Needed]”, true)}}\n\n\n\n\nCarbon emissions can be estimated using the Machine Learning Impact calculator presented in Lacoste et al. (2019).\n\nHardware Type: {{ hardware_type | default(“[More Information Needed]”, true)}}\nHours used: {{ hours_used | default(“[More Information Needed]”, true)}}\nCloud Provider: {{ cloud_provider | default(“[More Information Needed]”, true)}}\nCompute Region: {{ cloud_region | default(“[More Information Needed]”, true)}}\nCarbon Emitted: {{ co2_emitted | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n{{ model_specs | default(“[More Information Needed]”, true)}}\n\n\n\n{{ compute_infrastructure | default(“[More Information Needed]”, true)}}\n\n\n{{ hardware_requirements | default(“[More Information Needed]”, true)}}\n\n\n\n{{ software | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\nBibTeX:\n{{ citation_bibtex | default(“[More Information Needed]”, true)}}\nAPA:\n{{ citation_apa | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ glossary | default(“[More Information Needed]”, true)}}\n\n\n\n{{ more_information | default(“[More Information Needed]”, true)}}\n\n\n\n{{ model_card_authors | default(“[More Information Needed]”, true)}}\n\n\n\n{{ model_card_contact | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#model-details",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#model-details",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ model_description | default(““, true) }}\n\nDeveloped by: {{ developers | default(“[More Information Needed]”, true)}}\nFunded by [optional]: {{ funded_by | default(“[More Information Needed]”, true)}}\nShared by [optional]: {{ shared_by | default(“[More Information Needed]”, true)}}\nModel type: {{ model_type | default(“[More Information Needed]”, true)}}\nLanguage(s) (NLP): {{ language | default(“[More Information Needed]”, true)}}\nLicense: {{ license | default(“[More Information Needed]”, true)}}\nFinetuned from model [optional]: {{ base_model | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\nRepository: {{ repo | default(“[More Information Needed]”, true)}}\nPaper [optional]: {{ paper | default(“[More Information Needed]”, true)}}\nDemo [optional]: {{ demo | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#uses",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#uses",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ direct_use | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ downstream_use | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ out_of_scope_use | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#bias-risks-and-limitations",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#bias-risks-and-limitations",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ bias_risks_limitations | default(“[More Information Needed]”, true)}}\n\n\n\n{{ bias_recommendations | default(“Users (both direct and downstream) should be made aware of the risks, biases and limitations of the model. More information needed for further recommendations.”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#how-to-get-started-with-the-model",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#how-to-get-started-with-the-model",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "Use the code below to get started with the model.\n{{ get_started_code | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#training-details",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#training-details",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ training_data | default(“[More Information Needed]”, true)}}\n\n\n\n\n\n\n{{ preprocessing | default(“[More Information Needed]”, true)}}\n\n\n\n\nTraining regime: {{ training_regime | default(“[More Information Needed]”, true)}} \n\n\n\n\n\n{{ speeds_sizes_times | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#evaluation",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#evaluation",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ testing_data | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ testing_factors | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ testing_metrics | default(“[More Information Needed]”, true)}}\n\n\n\n\n{{ results | default(“[More Information Needed]”, true)}}\n\n\n{{ results_summary | default(““, true) }}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#model-examination-optional",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#model-examination-optional",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ model_examination | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#environmental-impact",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#environmental-impact",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "Carbon emissions can be estimated using the Machine Learning Impact calculator presented in Lacoste et al. (2019).\n\nHardware Type: {{ hardware_type | default(“[More Information Needed]”, true)}}\nHours used: {{ hours_used | default(“[More Information Needed]”, true)}}\nCloud Provider: {{ cloud_provider | default(“[More Information Needed]”, true)}}\nCompute Region: {{ cloud_region | default(“[More Information Needed]”, true)}}\nCarbon Emitted: {{ co2_emitted | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#technical-specifications-optional",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#technical-specifications-optional",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ model_specs | default(“[More Information Needed]”, true)}}\n\n\n\n{{ compute_infrastructure | default(“[More Information Needed]”, true)}}\n\n\n{{ hardware_requirements | default(“[More Information Needed]”, true)}}\n\n\n\n{{ software | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#citation-optional",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#citation-optional",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "BibTeX:\n{{ citation_bibtex | default(“[More Information Needed]”, true)}}\nAPA:\n{{ citation_apa | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#glossary-optional",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#glossary-optional",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ glossary | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#more-information-optional",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#more-information-optional",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ more_information | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#model-card-authors-optional",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#model-card-authors-optional",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ model_card_authors | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#model-card-contact",
    "href": "ds2venv/Lib/site-packages/huggingface_hub/templates/modelcard_template.html#model-card-contact",
    "title": "Model Card for {{ model_id | default(“Model ID”, true) }}",
    "section": "",
    "text": "{{ model_card_contact | default(“[More Information Needed]”, true)}}"
  },
  {
    "objectID": "ds2venv/Lib/site-packages/idna-3.6.dist-info/LICENSE.html",
    "href": "ds2venv/Lib/site-packages/idna-3.6.dist-info/LICENSE.html",
    "title": "ecmbblog",
    "section": "",
    "text": "BSD 3-Clause License\nCopyright (c) 2013-2023, Kim Davies and contributors. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "ds2venv/Lib/site-packages/Markdown-3.5.2.dist-info/LICENSE.html",
    "href": "ds2venv/Lib/site-packages/Markdown-3.5.2.dist-info/LICENSE.html",
    "title": "ecmbblog",
    "section": "",
    "text": "Copyright 2007, 2008 The Python Markdown Project (v. 1.7 and later) Copyright 2004, 2005, 2006 Yuri Takhteyev (v. 0.2-1.6b) Copyright 2004 Manfred Stienstra (the original version)\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the Python Markdown Project nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE PYTHON MARKDOWN PROJECT ‘’AS IS’’ AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL ANY CONTRIBUTORS TO THE PYTHON MARKDOWN PROJECT BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "ds2venv/Lib/site-packages/numpy/random/LICENSE.html",
    "href": "ds2venv/Lib/site-packages/numpy/random/LICENSE.html",
    "title": "NCSA Open Source License",
    "section": "",
    "text": "This software is dual-licensed under the The University of Illinois/NCSA Open Source License (NCSA) and The 3-Clause BSD License\n\nNCSA Open Source License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nDeveloped by: Kevin Sheppard (kevin.sheppard@economics.ox.ac.uk, kevin.k.sheppard@gmail.com) http://www.kevinsheppard.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal with the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimers.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimers in the documentation and/or other materials provided with the distribution.\nNeither the names of Kevin Sheppard, nor the names of any contributors may be used to endorse or promote products derived from this Software without specific prior written permission.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH THE SOFTWARE.\n\n\n3-Clause BSD License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nComponents\nMany parts of this module have been derived from original sources, often the algorithm’s designer. Component licenses are located with the component code."
  },
  {
    "objectID": "ds2venv/Lib/site-packages/tensorflow/include/external/libjpeg_turbo/LICENSE.html",
    "href": "ds2venv/Lib/site-packages/tensorflow/include/external/libjpeg_turbo/LICENSE.html",
    "title": "libjpeg-turbo Licenses",
    "section": "",
    "text": "libjpeg-turbo Licenses\nlibjpeg-turbo is covered by three compatible BSD-style open source licenses:\n\nThe IJG (Independent JPEG Group) License, which is listed in README.ijg\nThis license applies to the libjpeg API library and associated programs (any code inherited from libjpeg, and any modifications to that code.)\nThe Modified (3-clause) BSD License, which is listed below\nThis license covers the TurboJPEG API library and associated programs, as well as the build system.\nThe zlib License\nThis license is a subset of the other two, and it covers the libjpeg-turbo SIMD extensions.\n\n\n\nComplying with the libjpeg-turbo Licenses\nThis section provides a roll-up of the libjpeg-turbo licensing terms, to the best of our understanding.\n\nIf you are distributing a modified version of the libjpeg-turbo source, then:\n\nYou cannot alter or remove any existing copyright or license notices from the source.\nOrigin\n\nClause 1 of the IJG License\nClause 1 of the Modified BSD License\nClauses 1 and 3 of the zlib License\n\nYou must add your own copyright notice to the header of each source file you modified, so others can tell that you modified that file (if there is not an existing copyright header in that file, then you can simply add a notice stating that you modified the file.)\nOrigin\n\nClause 1 of the IJG License\nClause 2 of the zlib License\n\nYou must include the IJG README file, and you must not alter any of the copyright or license text in that file.\nOrigin\n\nClause 1 of the IJG License\n\n\nIf you are distributing only libjpeg-turbo binaries without the source, or if you are distributing an application that statically links with libjpeg-turbo, then:\n\nYour product documentation must include a message stating:\nThis software is based in part on the work of the Independent JPEG Group.\nOrigin\n\nClause 2 of the IJG license\n\nIf your binary distribution includes or uses the TurboJPEG API, then your product documentation must include the text of the Modified BSD License (see below.)\nOrigin\n\nClause 2 of the Modified BSD License\n\n\nYou cannot use the name of the IJG or The libjpeg-turbo Project or the contributors thereof in advertising, publicity, etc.\nOrigin\n\nIJG License\nClause 3 of the Modified BSD License\n\nThe IJG and The libjpeg-turbo Project do not warrant libjpeg-turbo to be free of defects, nor do we accept any liability for undesirable consequences resulting from your use of the software.\nOrigin\n\nIJG License\nModified BSD License\nzlib License\n\n\n\n\nThe Modified (3-clause) BSD License\nCopyright (C)2009-2022 D. R. Commander. All Rights Reserved. Copyright (C)2015 Viktor Szathmáry. All Rights Reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the libjpeg-turbo Project nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS”, AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDERS OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nWhy Three Licenses?\nThe zlib License could have been used instead of the Modified (3-clause) BSD License, and since the IJG License effectively subsumes the distribution conditions of the zlib License, this would have effectively placed libjpeg-turbo binary distributions under the IJG License. However, the IJG License specifically refers to the Independent JPEG Group and does not extend attribution and endorsement protections to other entities. Thus, it was desirable to choose a license that granted us the same protections for new code that were granted to the IJG for code derived from their software."
  },
  {
    "objectID": "ds2venv/Lib/site-packages/werkzeug/debug/shared/ICON_LICENSE.html",
    "href": "ds2venv/Lib/site-packages/werkzeug/debug/shared/ICON_LICENSE.html",
    "title": "ecmbblog",
    "section": "",
    "text": "Silk icon set 1.3 by Mark James mjames@gmail.com\nhttp://www.famfamfam.com/lab/icons/silk/\nLicense: CC-BY-2.5 or CC-BY-3.0"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "Hate Speech Klassifikation\n\n\n\n\n\n\n\nTextanalyse\n\n\nTidymodels\n\n\nKlassifikation\n\n\nTransformers\n\n\nNeuronale Netze\n\n\n\n\n\n\n\n\n\n\n\nFeb 9, 2024\n\n\nEmilia Braun\n\n\n\n\n\n\n  \n\n\n\n\nRaucherstatus Klassifikation\n\n\n\n\n\n\n\nTidymodels\n\n\nKlassifikation\n\n\nGesundheit\n\n\n\n\n\n\n\n\n\n\n\nJan 12, 2024\n\n\nEmilia Braun\n\n\n\n\n\n\n  \n\n\n\n\nKlassifikation von Hate Speech\n\n\n\n\n\n\n\nTextanalyse\n\n\nTidymodels\n\n\nKlassifikation\n\n\n\n\n\n\n\n\n\n\n\nNov 28, 2023\n\n\nEmilia Braun\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/Angewandtes Projekt/Projekt.html",
    "href": "posts/Angewandtes Projekt/Projekt.html",
    "title": "Raucherstatus Klassifikation",
    "section": "",
    "text": "Anhand von verschiedenen biologischen Daten und Signalen soll in einer Soft Classification bestimmt werden, mit welcher Wahrscheinlichkeit eine Person Raucher ist.\n\n\nIm Folgenden sollen sowohl neue Beobachtungsfälle auf ihre Wahrscheinlichkeit hin, Raucher zu sein, klassifiziert werden, als auch mögliche Effekte von biologischen Signalen auf den Raucherstatus identifiziert werden.\nWarum könnte eine Klassifikation des Raucherstatus interessieren?\n\n\nGesundheitswesen: Eine Klassifikation des Raucherstatus auf Basis von biologischen Signalen kann verwendet werden, um Menschen mit einem erhöhten Risiko für Raucherkrankheiten zu identifizieren. Dies kann dazu beitragen, diese Krankheiten zu verhindern oder zu behandeln.\nRaucherentwöhnung: Eine Klassifikation des Raucherstatus auf Basis von biologischen Signalen kann verwendet werden, um die Wirksamkeit von Raucherentwöhnungsmaßnahmen zu bewerten. Dies kann dazu beitragen, die Entwicklung neuer und effektiverer Raucherentwöhnungsmaßnahmen zu unterstützen.\nMarktforschung: Eine Klassifikation des Raucherstatus auf Basis von biologischen Signalen kann verwendet werden, um neue Produkte und Dienstleistungen für Raucher zu entwickeln. Dies kann dazu beitragen, die Raucherprävention und -entwöhnung zu unterstützen.\n\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(easystats)\nlibrary(glmnet)\nlibrary(corrr)\nlibrary(fastDummies)\nlibrary(reshape2)\nlibrary(lubridate)\nlibrary(tictoc)\nlibrary(xgboost)\nlibrary(doParallel)\nlibrary(cowplot)\nlibrary(rlang)\nlibrary(purrr)\nlibrary(timetk)\nlibrary(discrim)\nlibrary(ggthemes)\nlibrary(klaR)\nlibrary(rstanarm)\nlibrary(car)\nlibrary(caret)\nlibrary(pROC)\n\n\n\n\nDie Daten stammen von einer kaggle Competition. Es gibt einen train und einen test Datensatz.\nEs geht darum, Menschen als Raucher oder Nicht-Raucher anhand von verschiedenen biologischen Signalen und Eigenschaften zu klassifizieren. Dabei soll die Klassifikation aber nicht hart sein, also nur aussagen ob man Raucher ist oder nicht, sondern es soll eine weiche Klassifikation sein, die angibt, mit welcher Wahrscheinlichkeit jemand aufgrund der vorliegenden Daten Raucher ist.\n\nd_train &lt;- read_csv(path_train)\nd_test &lt;- read_csv(path_test)\n\nSchauen wir uns die Daten einmal an. Der Datensatz besteht aus 24 Variablen, wovon eine die ID-Spalte ist und eine die vorzusagende Variable smoking.\n\nd_train\n\n\n\n  \n\n\n\nDer Train Datensatz wird nochmal in train und test Daten gesplittet. Davor werden einige Variablen für einfacheres Handling noch umbenannt und die AV wird als Faktorvariable angelegt.\n\nd_train &lt;-\n  d_train |&gt; \n  mutate(weight = `weight(kg)`,\n         waist = `waist(cm)`,\n         height = `height(cm)`,\n         eyesight_left = `eyesight(left)`,\n         eyesight_right = `eyesight(right)`,\n         hearing_left = `hearing(left)`,\n         hearing_right = `hearing(right)`,\n         dental_caries = `dental caries`) |&gt; \n  dplyr::select(-`weight(kg)`, -`height(cm)`, -`eyesight(left)`, -`eyesight(right)`, -`hearing(left)`, -`hearing(right)`, - `dental caries`, -`waist(cm)`)\n\nd_test &lt;-\n  d_test |&gt; \n  mutate(weight = `weight(kg)`,\n         waist = `waist(cm)`,\n         height = `height(cm)`,\n         eyesight_left = `eyesight(left)`,\n         eyesight_right = `eyesight(right)`,\n         hearing_left = `hearing(left)`,\n         hearing_right = `hearing(right)`,\n         dental_caries = `dental caries`) |&gt; \n  dplyr::select(-`weight(kg)`, - `height(cm)`, -`eyesight(left)`, -`eyesight(right)`, -`hearing(left)`, -`hearing(right)`, - `dental caries`, -`waist(cm)`)\n\ncolnames(d_test) &lt;- gsub(\" \", \"_\", colnames(d_test))\n\nd_trainf &lt;-\n  d_train |&gt; \n  mutate(smokingf = factor(smoking)) |&gt; \n  dplyr::select(-smoking)\n\ncolnames(d_trainf) &lt;- gsub(\" \", \"_\", colnames(d_trainf))\n\nd_split &lt;- initial_split(d_trainf, prop = .8, strata = smokingf)\ntrain &lt;- training(d_split)\ntest &lt;- testing(d_split)\n\n\n\n\n\n\n\n\nsum(is.na(d_trainf))\n\n[1] 0\n\nvisdat::vis_dat(d_trainf, warn_large_data = FALSE)\n\n\n\n\nIm Datensatz gibt es keine fehlenden Werte. Bis auf die AV liegen nur nummerische Variablen vor.\n\n\n\n\n\nShow the code\ns_cor &lt;-\n  d_train |&gt;\n  dplyr::select(-id) |&gt; \n  correlate() |&gt; \n  shave()\n\ns_cor\n\n\n\n\n  \n\n\n\nShow the code\ns_cor2 &lt;-\n  d_train |&gt; \n  dplyr::select(-id)\n\ncorr_matrix &lt;- cor(s_cor2)\ncorr_melted &lt;- melt(corr_matrix)\n\nggplot(corr_melted, aes(x=Var1, y=Var2, fill=value)) + \n  geom_tile() +\n  scale_fill_gradient2(low=\"blue\", mid=\"white\", high=\"red\", midpoint=0) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n  labs(title=\"Korrelations-Heatmap für accidents\")\n\n\n\n\n\n\n\n\n\nd_train |&gt; \n  count(smoking == 1) |&gt; \n  mutate(Anteil = n/sum(n))\n\n\n\n  \n\n\n\n–&gt; Die AV scheint einigermaßen gleichverteilt zu sein.\n\n\n\n\n\nShow the code\n# Funktion zur Erstellung eines Histogramms mit Facettierung\ncreate_histogram_plot &lt;- function(data, variable) {\n  ggplot(data, aes(x = !!sym(variable))) +\n    geom_histogram() +\n    labs(x = variable, y = \"Häufigkeit\") +\n    theme(\n    text = element_text(color = \"darkblue\"),  # Ändere die Farbe des Texts\n    panel.background = element_rect(fill = \"lightgray\"),  # Hintergrundfarbe des Plots\n    panel.grid.major = element_line(color = \"white\"),  # Farbe der Hauptgitterlinien\n    panel.grid.minor = element_line(color = \"lightblue\"),  # Farbe der Nebengitterlinien\n    strip.background = element_rect(fill = \"cyan\"),  # Hintergrundfarbe der Facettenüberschriften\n    strip.text = element_text(color = \"black\"),  # Farbe des Texts in den Facettenüberschriften\n    axis.title = element_text(color = \"purple\"),  # Farbe der Achsentitel\n    axis.text = element_text(color = \"black\"),  # Farbe des Achsentexts\n    axis.line = element_line(color = \"blue\"),  # Farbe der Achsenlinien\n    panel.border = element_rect(color = \"darkgray\", fill = NA),  # Farbe der Panelgrenzen\n    plot.background = element_rect(fill = \"lightyellow\")  # Hintergrundfarbe des gesamten Plots\n  ) +\n    facet_wrap(~ ., scales = \"free\")\n}\n\n# Liste der Variablen, für die Plots erstellt werden sollen\nvariables_to_plot &lt;- c(\"smoking\", \"age\", \"height\", \"weight\", \"triglyceride\", \"hemoglobin\")\n\n# Erstelle die Plots für jede Variable\nplots_list &lt;- map(variables_to_plot, ~ create_histogram_plot(data = d_train, variable = .x))\n\n# Kombiniere die Plots in einem Raster\nplot_grid(plotlist = plots_list, ncol = 3)\n\n\n\n\n\nDie Variable smoking ist einigermaßen gleichverteilt, was für die Klassifikation natürlich sinnvoll ist, jedoch vielleicht kein gutes Bild der gesamten Population. In Deutschland liegt der Anteil an regelmäßig Rauchenden bei ca. 25 % (WHO, 2025).\nDie Variable age ist einigermaßen erwartungsmäßig verteilt, wobei es einen erstaunlich hohen Anteil an 40 Jährigen gibt.\nDie Variablen heigth und weight sind beide wie zu erwarten normalverteilt.\ntriglyceride, welche im medizinischen Bereich auch im Rahmen der Blutanalyse gemessen werden und zusammen mit Cholosterol zur Bestimmung von Fettwechselstörung notwendig sind, liegen bei einem Erwachsenen zwischen 40 - 240 mg/dl (natürlich auch abhängig von Alter und Geschlecht) (Rassow & Netzker, 2016). Deshalb macht die Verteilung der Werte auch Sinn so wie dargestellt.\nhemoglobin ist Teil der roten Blutkörperchen und ein Protein, in dessen Mitte ein Eisenatom liegt, welches Sauerstoff anlagern kann. Typische Werte liegen zwischen 12 und 19 g/dl (natürlich auch wieder abhängig von Alter und Geschlecht) (DRK, 2021), weshalb auch hier die Verteilung wieder sinnvoll erscheint.\n\n\n\n\n\nShow the code\n# Plot für Alter erstellen\n\nggplot(d_trainf, aes(x = age, fill = smokingf)) +\n  geom_bar(position = \"dodge\", width = 4)  +\n  labs(title = \"Häufigkeit von Alter nach Raucherstatus\",\n       x = \"Alter\",\n       y = \"Häufigkeit\",\n       fill = \"Raucher\")  +\n  scale_fill_tableau(\"Nuriel Stone\")\n\n\nWarning: `position_dodge()` requires non-overlapping x intervals\n\n\n\n\n\nDer größte Anteil in beiden Gruppen scheint bei 40 Jahren zu sein. Bei den Rauchern scheint es aber nochmal einen beachtlichen Anteil an 60 Jährigen zu geben im Vergleich zu den Nicht-Rauchern.\n\n\nShow the code\n# Plot für Gewicht erstellen\n\nggplot(d_trainf, aes(x = weight, fill = smokingf)) +\n  geom_bar(position = \"dodge\", width = 4)  +\n  labs(title = \"Häufigkeit von Gewicht nach Raucherstatus\",\n       x = \"Gewicht\",\n       y = \"Häufigkeit\",\n       fill = \"Raucher\") +\n  scale_fill_tableau(\"Nuriel Stone\")\n\n\nWarning: `position_dodge()` requires non-overlapping x intervals\n\n\n\n\n\nDie Nicht-Raucher haben bis 65 kg den höheren Anteil an der Verteilung, darüber gibt es mehr Raucher als Nicht-Raucher.\n\n\nShow the code\n# Plot für Größe erstellen\n\nggplot(d_trainf, aes(x = height, fill = smokingf)) +\n  geom_bar(position = \"dodge\", width = 4)  +\n  labs(title = \"Häufigkeit von Größe nach Raucherstatus\",\n       x = \"Größe\",\n       y = \"Häufigkeit\",\n       fill = \"Raucher\") +\n  scale_fill_tableau(\"Nuriel Stone\")\n\n\nWarning: `position_dodge()` requires non-overlapping x intervals\n\n\n\n\n\nEs gibt sehr viel mehr kleinere Nicht-Raucher als kleine Raucher (klein: &lt; 160 cm). Andersherum gibt es viel mehr große Raucher (groß: &gt; 170 cm) als große Nicht-Raucher. Interessant wäre hierbei noch zu wissen, wie die Geschlechterverteilung aussieht, denn falls es mehr männliche als weibliche Raucher geben würde, dann macht es auch Sinn, dass es mehr große Raucher gibt. Leider gibt es dazu keine Daten in dem Datensatz.\n\n\nShow the code\n# Plot für Karies erstellen\n\nggplot(d_trainf, aes(x = dental_caries, fill = smokingf)) +\n  geom_bar(position = \"dodge\") +\n  labs(title = \"Häufigkeit von Karies nach Raucherstatus\",\n       x = \"Karies\",\n       y = \"Häufigkeit\",\n       fill = \"Raucher\") +\n  scale_fill_tableau(\"Nuriel Stone\")\n\n\n\n\n\nInsgesamt gibt es viel weniger Menschen mit Karies, wobei es etwas mehr Raucher als Nicht-Raucher sind.\n\n\n\nHier waren einmal typische Merkmalen der Beobachtungsfälle interessant als auch vereinzelte Daten zu biochemischen Signalen.\n\n\nShow the code\nggplot(d_trainf, aes(x = smokingf, y = height, fill = smokingf)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot der Größe nach Raucherstatus\", x = \"Raucherstatus\", y = \"Größe\") +\n  scale_fill_tableau(\"Nuriel Stone\")\n\n\n\n\n\nShow the code\nd_trainf |&gt; \n  group_by(smokingf) |&gt; \n  summarise(mean(height))\n\n\n\n\n  \n\n\n\nAnscheinend sind Raucher (mean = 169.74 cm) im Durchschnitt etwas größer als Nicht-Raucher (mean = 161.79 cm). Zudem scheinen Nicht-Raucher breiter gestreut zu sein als Raucher. Die Verteilung zur Größer der Nicht-Raucher könnte möglicherweise auch nicht ganz normalverteilt sein. Die\n\n\nShow the code\nggplot(d_trainf, aes(x = smokingf, y = weight, fill = smokingf)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot des Gewichts nach Raucherstatus\", x = \"Raucherstatus\", y = \"Gewicht\") +\n  scale_fill_tableau(\"Nuriel Stone\")\n\n\n\n\n\nShow the code\nd_trainf |&gt; \n  group_by(smokingf) |&gt; \n  summarise(mean(weight))\n\n\n\n\n  \n\n\n\nNicht-Raucher scheinen im Durchschnitt mit 63.24 kg etwas leichter zu sein als die Raucher mit 72.16 kg. Die Nicht-Raucher haben mehr Ausreißer nach oben hin, während es bei den Rauchern sowohl Ausreißer nach unten als nach oben gibt. Beide Gruppen scheinen nicht ganz normalverteilt zu sein.\n\n\nShow the code\nggplot(d_trainf, aes(x = smokingf, y = age, fill = smokingf)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot des Alters nach Raucherstatus\", x = \"Raucherstatus\", y = \"Alter\") +\n  scale_fill_tableau(\"Nuriel Stone\")\n\n\n\n\n\nShow the code\nd_trainf |&gt; \n  group_by(smokingf) |&gt; \n  summarise(mean(age))\n\n\n\n\n  \n\n\n\nShow the code\nd_trainf |&gt; \n  group_by(smokingf) |&gt; \n  count(age &lt; 20)\n\n\n\n\n  \n\n\n\nRaucher liegen mit 41.5 Jahren durschnittlich unter den Nicht-Rauchern mit 46.5 Jahren. Es gibt in beiden Gruppen keine Personen, die unter 20 Jahren sind, also wurden wohl nur Daten zu Personen &gt;= 20 gesammelt. Beide Gruppen scheinen nicht ganz normalverteilt zu sein.\n\n\nShow the code\nggplot(d_trainf, aes(x = smokingf, y = Cholesterol, fill = smokingf)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot Cholersterol nach Raucherstatus\", x = \"Raucherstatus\", y = \"Cholesterol\") +\n  scale_fill_tableau(\"Nuriel Stone\")\n\n\n\n\n\nShow the code\nd_trainf |&gt; \n  group_by(smokingf) |&gt; \n  summarise(mean(Cholesterol))\n\n\n\n\n  \n\n\n\nDie Cholosterol-Spiegel sind für beide Gruppen ähnlich. Auch sonst gibt es wenig Auffäligkeiten.\n\n\nShow the code\nggplot(d_trainf, aes(x = smokingf, y = hemoglobin, fill = smokingf)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot des Hemoglobins nach Raucherstatus\", x = \"Raucherstatus\", y = \"Hemoglobin\") +\n  scale_fill_tableau(\"Nuriel Stone\")\n\n\n\n\n\nShow the code\nd_trainf |&gt; \n  group_by(smokingf) |&gt; \n  summarise(mean(hemoglobin))\n\n\n\n\n  \n\n\n\nDer Hämoglobin Wert für die Raucher liegt knapp über 15, während er bei den Nicht-Rauchern knapp unter 15 liegt. Bei den Nicht-Raucher gehen die Ausreißer jedoch auch unter den Wert 7.5, während es bei den Rauchern etwas mehr Ausreißer nach oben hin gibt bzw diese haben höhere Werte als die Ausreißer der Nicht-Raucher.\n\n\n\n\nUm zu überprüfen, welche Variablen einen Einfluss auf die AV haben, wurde im Folgenden ein stan_glm aufgestellt und anschließend das rope berechnet.\n\nm1 &lt;- stan_glm(smoking ~ ., data = d_train, seed = 42, refresh = 0)\n\nparameters(m1)\n\n\n\n  \n\n\nrope(m1)\n\nPossible multicollinearity between relaxation and systolic (r = 0.72), HDL and Cholesterol (r = 0.72), HDL and triglyceride (r = 0.7), waist and weight (r = 0.79). This might lead to inappropriate results. See 'Details' in '?rope'.\n\n\n\n\n  \n\n\nplot(rope(m1))\n\nPossible multicollinearity between relaxation and systolic (r = 0.72), HDL and Cholesterol (r = 0.72), HDL and triglyceride (r = 0.7), waist and weight (r = 0.79). This might lead to inappropriate results. See 'Details' in '?rope'.\n\n\n\n\nvif(m1)\n\n                   id                   age              systolic \n             1.018681              1.887934              2.587834 \n           relaxation `fasting blood sugar`           Cholesterol \n             2.505630              1.142631              7.455405 \n         triglyceride                   HDL                   LDL \n             3.078763              3.389189              6.134903 \n           hemoglobin       `Urine protein`    `serum creatinine` \n             1.905295              1.017452              1.445274 \n                  AST                   ALT                   Gtp \n             1.741287              1.959108              1.339327 \n               weight                 waist                height \n             6.919126              4.749702              2.929081 \n        eyesight_left        eyesight_right          hearing_left \n             1.319455              1.342833              1.487325 \n        hearing_right         dental_caries \n             1.460736              1.026594 \n\n\nAnscheinend haben nur 2 Variablen wirklich Einfluss auf die AV, und zwar hemoglobin und dental_caries. Es wurde aber als Warnung ausgegeben, dass es eine mögliche Multikollinearität zwischen relaxation und sysolic, HDL und Cholosterol, HDL und triglyceride und waistund weightgibt. Dadurch könnten die Ergebnisse verfälscht werden und der Anteil, der sich im rope befindet, verschieben. Deshalb ist es schwierig zu sagen, ob noch andere Variablen einen identifizierten Effekt auf die AV haben.\nDer Varianzinflationsfaktor (VIF) wird verwendet, um Multikollinearität zwischen den Prädiktoren in einem Regressionsmodell zu quantifizieren. Die betroffenen Variablen scheinen alle ein höheren Faktor zu haben als die anderen.\nEs macht aber Sinn, dass die Variablen-Pärchen eine Korrelation aufweisen, denn zum Beispiel stehen die Variablen relaxation und sysolic beide im Zusammenhang mit dem Blutdruck, genauso wie es bei dem Taillenumfang (waist) und Gewicht auch Sinn macht, dass sie miteinander korrelieren.\n\n\n\n\n\nVerschiedene Rezepte mit unterschiedlicher Vorverarbeitung, um am Ende das beste zu finden.\nAufgrund von hohen Rechenzeiten habe ich mich dafür entschieden, mein test-sample aus dem Split-Objekt zu verwenden.\n\n# Rezept basic\nrec1 &lt;-\n  recipe(smokingf ~ ., data = test) %&gt;% \n  update_role(id, new_role = \"id variable\" )\n\n\ntidy(rec1)\n\n\n\n  \n\n\nd_baked1 &lt;- prep(rec1) |&gt; bake(new_data = NULL)\nsum(is.na(d_baked1))\n\n[1] 0\n\n# Basic Rezept mit Yeo Johnson & step normalize\nrec2 &lt;-\n  recipe(smokingf ~ ., data = test) %&gt;% \n  update_role(id, new_role = \"id variable\") |&gt; \n  step_normalize(all_numeric_predictors()) |&gt; \n  step_YeoJohnson(all_double_predictors())\n\ntidy(rec2)\n\n\n\n  \n\n\nd_baked2 &lt;- prep(rec2) |&gt; bake(new_data = NULL)\nsum(is.na(d_baked2))\n\n[1] 0\n\n# Rezept 3\nrec3 &lt;-\n  recipe(smokingf ~ height + weight + hemoglobin + triglyceride + Gtp + serum_creatinine + HDL + waist + age, data = test) %&gt;%\n  step_normalize(all_numeric_predictors())\n\ntidy(rec3)\n\n\n\n  \n\n\nd_baked3 &lt;- prep(rec3) |&gt; bake(new_data = NULL)\nsum(is.na(d_baked3))\n\n[1] 0\n\n# Rezept 4\nrec4 &lt;-\n  recipe(smokingf ~ height + weight + hemoglobin + triglyceride + Gtp + serum_creatinine + HDL + waist + age, data = test) %&gt;%\n  step_normalize(all_numeric_predictors()) |&gt; \n  step_pca(all_numeric_predictors(), num_comp = 3) \n\ntidy(rec4)\n\n\n\n  \n\n\nd_baked4 &lt;- prep(rec4) |&gt; bake(new_data = NULL)\nsum(is.na(d_baked4))\n\n[1] 0\n\n# Rezept 5 auf Basis des stan_glm\nrec5 &lt;-\n  recipe(smokingf ~ dental_caries + hemoglobin, data = test) %&gt;%\n  step_scale(all_numeric_predictors()) |&gt; \n  step_pca(all_numeric_predictors(), num_comp = 3) \n\ntidy(rec5)\n\n\n\n  \n\n\nd_baked5 &lt;- prep(rec5) |&gt; bake(new_data = NULL)\nsum(is.na(d_baked5))\n\n[1] 0\n\n#Rezept 6 mit yeo Johnson und z-skalieren\nrec6 &lt;-\n  recipe(smokingf ~ ., data = test) %&gt;% \n  update_role(id, new_role = \"id variable\") |&gt; \n  step_normalize(all_numeric_predictors()) |&gt; \n  step_scale(all_numeric_predictors()) |&gt; \n  step_YeoJohnson(all_double_predictors())\n\ntidy(rec6)\n\n\n\n  \n\n\nd_baked6 &lt;- prep(rec6) |&gt; bake(new_data = NULL)\nsum(is.na(d_baked6))\n\n[1] 0\n\n\n\n\n\n\nset.seed(42)\ncv_scheme &lt;- vfold_cv(test,\n  v = 5, \n  repeats = 2,\n  strata = smokingf)\n\n\n\n\n\n# Baum\nmod_tree &lt;-\n  decision_tree(cost_complexity = tune(),\n  tree_depth = tune(),\n  mode = \"classification\")\n\n# Random Forest\nmod_rf &lt;-\n  rand_forest(mtry = tune(),\n  min_n = tune(),\n  trees = 1000,\n  mode = \"classification\") %&gt;% \n  set_engine(\"ranger\", num.threads = 4)\n\n# XGBoost\n\nmod_boost &lt;- boost_tree(\n  mode = \"classification\",\n  engine = \"xgboost\",\n  mtry = tune(),\n  trees = 100,\n  min_n = 10\n)\n\n\n# logistische Regression\nmod_logreg &lt;- logistic_reg(\n              mode = \"classification\",\n              engine = \"glm\",\n              penalty = 1)\n\n\n# knn\nmod_knn &lt;-\n  nearest_neighbor(\n    mode = \"classification\",\n    engine = \"kknn\",\n    neighbors = tune()\n  ) \n\n\n\n\n\n\nShow the code\npreproc1 &lt;- list(rec1 = rec1)\n\nmodels1 &lt;- list(tree1 = mod_tree, rf1 = mod_rf, boost1 = mod_boost, lg1 = mod_logreg, knn1 = mod_knn)\n\nmodels2 &lt;- list(tree1 = mod_tree, boost1 = mod_boost, lg1 = mod_logreg, knn1 = mod_knn)\n\n# mit Rezept 1\nall_workflows1 &lt;- workflow_set(preproc1, models2)\n\n# mit Rezept 2\npreproc2 &lt;- list(rec2 = rec2)\nall_workflows2 &lt;- workflow_set(preproc2, models2)\n\n# mit Rezept 3\npreproc3 &lt;- list(rec3 = rec3)\nall_workflows3 &lt;- workflow_set(preproc3, models2)\n\n# mit Rezept 4\npreproc4 &lt;- list(rec4 = rec4)\nall_workflows4 &lt;- workflow_set(preproc4, models2)\n\n# mit Rezept 5\npreproc5 &lt;- list(rec5 = rec5)\nall_workflows5 &lt;- workflow_set(preproc5, models2)\n\n# mit Rezept 6\npreproc6 &lt;- list(rec6 = rec6)\nall_workflows6 &lt;- workflow_set(preproc6, models2)\n\n\n\nworkflow6 &lt;-\n  workflow() |&gt; \n  add_model(mod_boost) |&gt; \n  add_recipe(rec6)\n\n\n\n\n\n\nShow the code\n# mit Rezept 2\nset.seed(42)\ntic()\nsmokingset2 &lt;-\n  all_workflows2 %&gt;% \n  workflow_map(\n  resamples = cv_scheme,\n  grid = 10,\n  verbose = TRUE)\ntoc()\n\n# mit Rezept 3\nset.seed(42)\ntic()\nsmokingset3 &lt;-\n  all_workflows3 %&gt;% \n  workflow_map(\n  resamples = cv_scheme,\n  grid = 10,\n  verbose = TRUE)\ntoc()\n\n# mit Rezept 4\nset.seed(42)\ntic()\nsmokingset4 &lt;-\n  all_workflows4 %&gt;% \n  workflow_map(\n  resamples = cv_scheme,\n  grid = 10,\n  verbose = TRUE)\ntoc()\n\n# mit Rezept 5\nset.seed(42)\ntic()\nsmokingset5 &lt;-\n  all_workflows5 %&gt;% \n  workflow_map(\n  resamples = cv_scheme,\n  grid = 10,\n  verbose = TRUE)\ntoc()\n\n# mit Rezept 6\nset.seed(42)\ntic()\nsmokingset6 &lt;-\n  all_workflows6 %&gt;% \n  workflow_map(\n  resamples = cv_scheme,\n  grid = 10,\n  verbose = TRUE)\ntoc()\n\n\nBester Workflow, dieser hat sich durch ausprobieren der Workflowsets ergeben. Aufgrund von Rechenzeitersparnis wird hier nur noch mit dem besten Workflow weitergearbeitet.\n\n# mit Rezept 6\nset.seed(42)\ntic()\ntune6 &lt;-\n  tune_grid(object = workflow6,\n            resamples = cv_scheme,\n            grid = 10,\n            control = control_grid(save_workflow = TRUE))\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\ni The workflow being saved contains a recipe, which is 5.74 Mb in i memory. If\nthis was not intentional, please set the control setting i `save_workflow =\nFALSE`.\n\ntoc()\n\n348.19 sec elapsed\n\n\n\n\n\n\n\nShow the code\n# mit Rezept 2\ntune::autoplot(smokingset2) +\n  theme(legend.position = \"bottom\")\n\nsmokingset2 %&gt;% \n  collect_metrics(.metric = \"roc_auc\") %&gt;% \n  arrange(mean) \n\n# mit Rezept 3\ntune::autoplot(smokingset3) +\n  theme(legend.position = \"bottom\")\n\nsmokingset3 %&gt;% \n  collect_metrics(.metric = \"roc_auc\") %&gt;% \n  arrange(mean) \n\n# mit Rezept 4\ntune::autoplot(smokingset4) +\n  theme(legend.position = \"bottom\")\n\nsmokingset4 %&gt;% \n  collect_metrics(.metric = \"roc_auc\") %&gt;% \n  arrange(mean) \n\n# mit Rezept 5\ntune::autoplot(smokingset5) +\n  theme(legend.position = \"bottom\")\n\nsmokingset5 %&gt;% \n  collect_metrics(.metric = \"roc_auc\") %&gt;% \n  arrange(mean) \n\n# mit Rezept 6\ntune::autoplot(smokingset6) +\n  theme(legend.position = \"bottom\")\n\nsmokingset6 %&gt;% \n  collect_metrics() %&gt;% \n  arrange(mean) \n\n\nBestes Workflowset:\n\n# mit Rezept 6\ntune6 |&gt; collect_metrics()\n\n\n\n  \n\n\nautoplot(tune6)\n\n\n\n\n\n\n\nDer beste workflow scheint eine Kombination aus einem xgBoost-Modell und dem 6. Rezept zu sein. Die accuracy liegt bei ca. 0.771 und der roc_auc wert bei 0.856.\n\nbest_model6 &lt;-\n  fit_best(tune6)\n\n\n\n\n\n\nfinal_preds6 &lt;- \n  best_model6 %&gt;% \n  predict(new_data = d_test, type = \"prob\") %&gt;% \n  bind_cols(d_test)\n\nsubmission &lt;-\n  final_preds6 |&gt; \n  mutate(pred_prob = .pred_1,\n         pred_class = round(.pred_1, 0)) |&gt; \n  dplyr::select(id, pred_class, pred_prob)\n\n\n\nAnhand dem eigenen train-sample wird die roc-auc Kurve dargestellt.\n\nprobe &lt;- \n  best_model6 %&gt;% \n  predict(new_data = train, type = \"prob\")\n\n\ntrain2 &lt;- train |&gt; \n  mutate(smoking = as.numeric(smokingf))\nrocobj &lt;- roc(train2$smoking, probe$.pred_1)\n\nSetting levels: control = 1, case = 2\n\n\nSetting direction: controls &lt; cases\n\n#define object to plot and calculate AUC\nrocobj &lt;- roc(train2$smoking, probe$.pred_1)\n\nSetting levels: control = 1, case = 2\nSetting direction: controls &lt; cases\n\nauc &lt;- round(auc(train2$smoking, probe$.pred_1),4)\n\nSetting levels: control = 1, case = 2\nSetting direction: controls &lt; cases\n\n#create ROC plot\nggroc(rocobj, colour = 'cyan', size = 1) +\n  ggtitle(paste0('ROC Curve ', '(AUC = ', auc, ')')) +\n  scale_fill_tableau(\"Nuriel Stone\")\n\n\n\n\nDas Modell ist in der Lage, die positiven Fälle von den negativen Fällen mit einer Wahrscheinlichkeit von ca. 86 % zu unterscheiden.\nEs ist wichtig zu beachten, dass der ROC AUC-Wert nur ein Maß für die Fähigkeit eines Modells ist, die positiven Fälle von den negativen Fällen zu unterscheiden. Er sagt nichts darüber aus, wie gut das Modell die tatsächlichen Werte der positiven Fälle vorhersagt.\n\n\n\n\nprobe2 &lt;-\n  probe |&gt; \n  bind_cols(train2)\n\nprobe2 &lt;-\n  probe2 |&gt; \n  mutate(pred1 = round(.pred_1)) |&gt; \n  mutate(predf = factor(pred1))\n\nconfusion_matrix &lt;- confusionMatrix(probe2$smokingf, probe2$predf)\nprint(confusion_matrix)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction     0     1\n         0 54390 17292\n         1 11529 44193\n                                          \n               Accuracy : 0.7738          \n                 95% CI : (0.7715, 0.7761)\n    No Information Rate : 0.5174          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.5456          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.8251          \n            Specificity : 0.7188          \n         Pos Pred Value : 0.7588          \n         Neg Pred Value : 0.7931          \n             Prevalence : 0.5174          \n         Detection Rate : 0.4269          \n   Detection Prevalence : 0.5626          \n      Balanced Accuracy : 0.7719          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nDie Sensitivität ist ein Maß dafür, wie gut das Modell positive Fälle (Nicht-Raucher) erkennt. In diesem Fall ist die Sensitivität von 0,8271 gut. Das Modell erkennt 82,71 % der positiven Fälle korrekt.\nDie Spezifität ist ein Maß dafür, wie gut das Modell negative Fälle (Raucher) erkennt. In diesem Fall ist die Spezifität von 0,7194 auch gut. Das Modell erkennt 71,94 % der negativen Fälle korrekt.\n\n\n\n\nEs sollten innerhalb dieser Analyse zwei Fragen bzw. Aufgaben bewältigit werden. Zum einem sollten die mögliche Effekte auf den Raucherstatus identifiziert werden, zum anderen sollten Beobachtungsfälle aufgrund ihrer biologischen Daten nach ihrem Raucherstatus klassifiziert werden bzw. es sollte die Wahrscheinlichkeit, ob jemand Raucher ist, angegeben werden.\nEs wurden zwei Effekte auf die AV smoking identifiziert, einmal hemoglobin und dental_caries. Es kann jedoch nicht mit Sicherheit gesagt werden, ob es nicht noch mehr geben könnte, denn im Modell befinden sich Hinweise auf eine mögliche Multikollinerität.\nDas Klassifikations-Modell ist in der Lage, die positiven Fälle von den negativen Fällen mit einer Wahrscheinlichkeit von ca. 86 % zu unterscheiden.\nIm Allgemeinen kann man sagen: Die Klassifikation des Raucherstatus auf der Grundlage biologischer Signale hat einige Vorteile gegenüber der Klassifikation auf der Grundlage von Selbstberichten. Selbstberichte sind anfällig für Verzerrungen, z. B. soziale Erwünschtheit oder Erinnerungsfehler. Biologische Signale hingegen sind objektive Messungen, die nicht von den subjektiven Wahrnehmungen der Person abhängen.\nEs gibt jedoch auch einige Herausforderungen bei der Klassifikation des Raucherstatus auf der Grundlage biologischer Signale. Zum einen sind die biologischen Signale von Rauchern und Nichtrauchern nicht immer eindeutig voneinander zu unterscheiden. Zum anderen können die biologischen Signale durch andere Faktoren beeinflusst werden, z. B. durch die Ernährung oder die Einnahme von Medikamenten.\n\n\n\nRaucheranteil Deutschland: WHO. (31. August, 2015). Anteil der Raucher in Deutschland nach Geschlecht in den Jahren 2000 bis 2025 [Graph]. In Statista. Zugriff am 12. Januar 2024, von https://de.statista.com/statistik/daten/studie/596512/umfrage/verbreitung-des-rauchens-in-deutschland-nach-geschlecht/\nTriglyceride-Werte: Rassow, J., & Netzker, D. (2016). Duale Reihe Biochemie, Thieme. Edited by J. Rassow et al. Stuttgart: Georg Thieme Verlag.\nHämoglobin-Werte: https://www.blutspende.de/magazin/von-a-bis-0/was-ist-haemoglobin-und-warum-ist-es-wichtig"
  },
  {
    "objectID": "posts/Angewandtes Projekt/Projekt.html#forschungsfrage",
    "href": "posts/Angewandtes Projekt/Projekt.html#forschungsfrage",
    "title": "Raucherstatus Klassifikation",
    "section": "",
    "text": "Im Folgenden sollen sowohl neue Beobachtungsfälle auf ihre Wahrscheinlichkeit hin, Raucher zu sein, klassifiziert werden, als auch mögliche Effekte von biologischen Signalen auf den Raucherstatus identifiziert werden.\nWarum könnte eine Klassifikation des Raucherstatus interessieren?\n\n\nGesundheitswesen: Eine Klassifikation des Raucherstatus auf Basis von biologischen Signalen kann verwendet werden, um Menschen mit einem erhöhten Risiko für Raucherkrankheiten zu identifizieren. Dies kann dazu beitragen, diese Krankheiten zu verhindern oder zu behandeln.\nRaucherentwöhnung: Eine Klassifikation des Raucherstatus auf Basis von biologischen Signalen kann verwendet werden, um die Wirksamkeit von Raucherentwöhnungsmaßnahmen zu bewerten. Dies kann dazu beitragen, die Entwicklung neuer und effektiverer Raucherentwöhnungsmaßnahmen zu unterstützen.\nMarktforschung: Eine Klassifikation des Raucherstatus auf Basis von biologischen Signalen kann verwendet werden, um neue Produkte und Dienstleistungen für Raucher zu entwickeln. Dies kann dazu beitragen, die Raucherprävention und -entwöhnung zu unterstützen."
  },
  {
    "objectID": "posts/Angewandtes Projekt/Projekt.html#vorbereitung",
    "href": "posts/Angewandtes Projekt/Projekt.html#vorbereitung",
    "title": "Raucherstatus Klassifikation",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(easystats)\nlibrary(glmnet)\nlibrary(corrr)\nlibrary(fastDummies)\nlibrary(reshape2)\nlibrary(lubridate)\nlibrary(tictoc)\nlibrary(xgboost)\nlibrary(doParallel)\nlibrary(cowplot)\nlibrary(rlang)\nlibrary(purrr)\nlibrary(timetk)\nlibrary(discrim)\nlibrary(ggthemes)\nlibrary(klaR)\nlibrary(rstanarm)\nlibrary(car)\nlibrary(caret)\nlibrary(pROC)\n\n\n\n\nDie Daten stammen von einer kaggle Competition. Es gibt einen train und einen test Datensatz.\nEs geht darum, Menschen als Raucher oder Nicht-Raucher anhand von verschiedenen biologischen Signalen und Eigenschaften zu klassifizieren. Dabei soll die Klassifikation aber nicht hart sein, also nur aussagen ob man Raucher ist oder nicht, sondern es soll eine weiche Klassifikation sein, die angibt, mit welcher Wahrscheinlichkeit jemand aufgrund der vorliegenden Daten Raucher ist.\n\nd_train &lt;- read_csv(path_train)\nd_test &lt;- read_csv(path_test)\n\nSchauen wir uns die Daten einmal an. Der Datensatz besteht aus 24 Variablen, wovon eine die ID-Spalte ist und eine die vorzusagende Variable smoking.\n\nd_train\n\n\n\n  \n\n\n\nDer Train Datensatz wird nochmal in train und test Daten gesplittet. Davor werden einige Variablen für einfacheres Handling noch umbenannt und die AV wird als Faktorvariable angelegt.\n\nd_train &lt;-\n  d_train |&gt; \n  mutate(weight = `weight(kg)`,\n         waist = `waist(cm)`,\n         height = `height(cm)`,\n         eyesight_left = `eyesight(left)`,\n         eyesight_right = `eyesight(right)`,\n         hearing_left = `hearing(left)`,\n         hearing_right = `hearing(right)`,\n         dental_caries = `dental caries`) |&gt; \n  dplyr::select(-`weight(kg)`, -`height(cm)`, -`eyesight(left)`, -`eyesight(right)`, -`hearing(left)`, -`hearing(right)`, - `dental caries`, -`waist(cm)`)\n\nd_test &lt;-\n  d_test |&gt; \n  mutate(weight = `weight(kg)`,\n         waist = `waist(cm)`,\n         height = `height(cm)`,\n         eyesight_left = `eyesight(left)`,\n         eyesight_right = `eyesight(right)`,\n         hearing_left = `hearing(left)`,\n         hearing_right = `hearing(right)`,\n         dental_caries = `dental caries`) |&gt; \n  dplyr::select(-`weight(kg)`, - `height(cm)`, -`eyesight(left)`, -`eyesight(right)`, -`hearing(left)`, -`hearing(right)`, - `dental caries`, -`waist(cm)`)\n\ncolnames(d_test) &lt;- gsub(\" \", \"_\", colnames(d_test))\n\nd_trainf &lt;-\n  d_train |&gt; \n  mutate(smokingf = factor(smoking)) |&gt; \n  dplyr::select(-smoking)\n\ncolnames(d_trainf) &lt;- gsub(\" \", \"_\", colnames(d_trainf))\n\nd_split &lt;- initial_split(d_trainf, prop = .8, strata = smokingf)\ntrain &lt;- training(d_split)\ntest &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/Angewandtes Projekt/Projekt.html#überblick-über-die-daten-verschaffen",
    "href": "posts/Angewandtes Projekt/Projekt.html#überblick-über-die-daten-verschaffen",
    "title": "Raucherstatus Klassifikation",
    "section": "",
    "text": "sum(is.na(d_trainf))\n\n[1] 0\n\nvisdat::vis_dat(d_trainf, warn_large_data = FALSE)\n\n\n\n\nIm Datensatz gibt es keine fehlenden Werte. Bis auf die AV liegen nur nummerische Variablen vor.\n\n\n\n\n\nShow the code\ns_cor &lt;-\n  d_train |&gt;\n  dplyr::select(-id) |&gt; \n  correlate() |&gt; \n  shave()\n\ns_cor\n\n\n\n\n  \n\n\n\nShow the code\ns_cor2 &lt;-\n  d_train |&gt; \n  dplyr::select(-id)\n\ncorr_matrix &lt;- cor(s_cor2)\ncorr_melted &lt;- melt(corr_matrix)\n\nggplot(corr_melted, aes(x=Var1, y=Var2, fill=value)) + \n  geom_tile() +\n  scale_fill_gradient2(low=\"blue\", mid=\"white\", high=\"red\", midpoint=0) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n  labs(title=\"Korrelations-Heatmap für accidents\")\n\n\n\n\n\n\n\n\n\nd_train |&gt; \n  count(smoking == 1) |&gt; \n  mutate(Anteil = n/sum(n))\n\n\n\n  \n\n\n\n–&gt; Die AV scheint einigermaßen gleichverteilt zu sein.\n\n\n\n\n\nShow the code\n# Funktion zur Erstellung eines Histogramms mit Facettierung\ncreate_histogram_plot &lt;- function(data, variable) {\n  ggplot(data, aes(x = !!sym(variable))) +\n    geom_histogram() +\n    labs(x = variable, y = \"Häufigkeit\") +\n    theme(\n    text = element_text(color = \"darkblue\"),  # Ändere die Farbe des Texts\n    panel.background = element_rect(fill = \"lightgray\"),  # Hintergrundfarbe des Plots\n    panel.grid.major = element_line(color = \"white\"),  # Farbe der Hauptgitterlinien\n    panel.grid.minor = element_line(color = \"lightblue\"),  # Farbe der Nebengitterlinien\n    strip.background = element_rect(fill = \"cyan\"),  # Hintergrundfarbe der Facettenüberschriften\n    strip.text = element_text(color = \"black\"),  # Farbe des Texts in den Facettenüberschriften\n    axis.title = element_text(color = \"purple\"),  # Farbe der Achsentitel\n    axis.text = element_text(color = \"black\"),  # Farbe des Achsentexts\n    axis.line = element_line(color = \"blue\"),  # Farbe der Achsenlinien\n    panel.border = element_rect(color = \"darkgray\", fill = NA),  # Farbe der Panelgrenzen\n    plot.background = element_rect(fill = \"lightyellow\")  # Hintergrundfarbe des gesamten Plots\n  ) +\n    facet_wrap(~ ., scales = \"free\")\n}\n\n# Liste der Variablen, für die Plots erstellt werden sollen\nvariables_to_plot &lt;- c(\"smoking\", \"age\", \"height\", \"weight\", \"triglyceride\", \"hemoglobin\")\n\n# Erstelle die Plots für jede Variable\nplots_list &lt;- map(variables_to_plot, ~ create_histogram_plot(data = d_train, variable = .x))\n\n# Kombiniere die Plots in einem Raster\nplot_grid(plotlist = plots_list, ncol = 3)\n\n\n\n\n\nDie Variable smoking ist einigermaßen gleichverteilt, was für die Klassifikation natürlich sinnvoll ist, jedoch vielleicht kein gutes Bild der gesamten Population. In Deutschland liegt der Anteil an regelmäßig Rauchenden bei ca. 25 % (WHO, 2025).\nDie Variable age ist einigermaßen erwartungsmäßig verteilt, wobei es einen erstaunlich hohen Anteil an 40 Jährigen gibt.\nDie Variablen heigth und weight sind beide wie zu erwarten normalverteilt.\ntriglyceride, welche im medizinischen Bereich auch im Rahmen der Blutanalyse gemessen werden und zusammen mit Cholosterol zur Bestimmung von Fettwechselstörung notwendig sind, liegen bei einem Erwachsenen zwischen 40 - 240 mg/dl (natürlich auch abhängig von Alter und Geschlecht) (Rassow & Netzker, 2016). Deshalb macht die Verteilung der Werte auch Sinn so wie dargestellt.\nhemoglobin ist Teil der roten Blutkörperchen und ein Protein, in dessen Mitte ein Eisenatom liegt, welches Sauerstoff anlagern kann. Typische Werte liegen zwischen 12 und 19 g/dl (natürlich auch wieder abhängig von Alter und Geschlecht) (DRK, 2021), weshalb auch hier die Verteilung wieder sinnvoll erscheint.\n\n\n\n\n\nShow the code\n# Plot für Alter erstellen\n\nggplot(d_trainf, aes(x = age, fill = smokingf)) +\n  geom_bar(position = \"dodge\", width = 4)  +\n  labs(title = \"Häufigkeit von Alter nach Raucherstatus\",\n       x = \"Alter\",\n       y = \"Häufigkeit\",\n       fill = \"Raucher\")  +\n  scale_fill_tableau(\"Nuriel Stone\")\n\n\nWarning: `position_dodge()` requires non-overlapping x intervals\n\n\n\n\n\nDer größte Anteil in beiden Gruppen scheint bei 40 Jahren zu sein. Bei den Rauchern scheint es aber nochmal einen beachtlichen Anteil an 60 Jährigen zu geben im Vergleich zu den Nicht-Rauchern.\n\n\nShow the code\n# Plot für Gewicht erstellen\n\nggplot(d_trainf, aes(x = weight, fill = smokingf)) +\n  geom_bar(position = \"dodge\", width = 4)  +\n  labs(title = \"Häufigkeit von Gewicht nach Raucherstatus\",\n       x = \"Gewicht\",\n       y = \"Häufigkeit\",\n       fill = \"Raucher\") +\n  scale_fill_tableau(\"Nuriel Stone\")\n\n\nWarning: `position_dodge()` requires non-overlapping x intervals\n\n\n\n\n\nDie Nicht-Raucher haben bis 65 kg den höheren Anteil an der Verteilung, darüber gibt es mehr Raucher als Nicht-Raucher.\n\n\nShow the code\n# Plot für Größe erstellen\n\nggplot(d_trainf, aes(x = height, fill = smokingf)) +\n  geom_bar(position = \"dodge\", width = 4)  +\n  labs(title = \"Häufigkeit von Größe nach Raucherstatus\",\n       x = \"Größe\",\n       y = \"Häufigkeit\",\n       fill = \"Raucher\") +\n  scale_fill_tableau(\"Nuriel Stone\")\n\n\nWarning: `position_dodge()` requires non-overlapping x intervals\n\n\n\n\n\nEs gibt sehr viel mehr kleinere Nicht-Raucher als kleine Raucher (klein: &lt; 160 cm). Andersherum gibt es viel mehr große Raucher (groß: &gt; 170 cm) als große Nicht-Raucher. Interessant wäre hierbei noch zu wissen, wie die Geschlechterverteilung aussieht, denn falls es mehr männliche als weibliche Raucher geben würde, dann macht es auch Sinn, dass es mehr große Raucher gibt. Leider gibt es dazu keine Daten in dem Datensatz.\n\n\nShow the code\n# Plot für Karies erstellen\n\nggplot(d_trainf, aes(x = dental_caries, fill = smokingf)) +\n  geom_bar(position = \"dodge\") +\n  labs(title = \"Häufigkeit von Karies nach Raucherstatus\",\n       x = \"Karies\",\n       y = \"Häufigkeit\",\n       fill = \"Raucher\") +\n  scale_fill_tableau(\"Nuriel Stone\")\n\n\n\n\n\nInsgesamt gibt es viel weniger Menschen mit Karies, wobei es etwas mehr Raucher als Nicht-Raucher sind.\n\n\n\nHier waren einmal typische Merkmalen der Beobachtungsfälle interessant als auch vereinzelte Daten zu biochemischen Signalen.\n\n\nShow the code\nggplot(d_trainf, aes(x = smokingf, y = height, fill = smokingf)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot der Größe nach Raucherstatus\", x = \"Raucherstatus\", y = \"Größe\") +\n  scale_fill_tableau(\"Nuriel Stone\")\n\n\n\n\n\nShow the code\nd_trainf |&gt; \n  group_by(smokingf) |&gt; \n  summarise(mean(height))\n\n\n\n\n  \n\n\n\nAnscheinend sind Raucher (mean = 169.74 cm) im Durchschnitt etwas größer als Nicht-Raucher (mean = 161.79 cm). Zudem scheinen Nicht-Raucher breiter gestreut zu sein als Raucher. Die Verteilung zur Größer der Nicht-Raucher könnte möglicherweise auch nicht ganz normalverteilt sein. Die\n\n\nShow the code\nggplot(d_trainf, aes(x = smokingf, y = weight, fill = smokingf)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot des Gewichts nach Raucherstatus\", x = \"Raucherstatus\", y = \"Gewicht\") +\n  scale_fill_tableau(\"Nuriel Stone\")\n\n\n\n\n\nShow the code\nd_trainf |&gt; \n  group_by(smokingf) |&gt; \n  summarise(mean(weight))\n\n\n\n\n  \n\n\n\nNicht-Raucher scheinen im Durchschnitt mit 63.24 kg etwas leichter zu sein als die Raucher mit 72.16 kg. Die Nicht-Raucher haben mehr Ausreißer nach oben hin, während es bei den Rauchern sowohl Ausreißer nach unten als nach oben gibt. Beide Gruppen scheinen nicht ganz normalverteilt zu sein.\n\n\nShow the code\nggplot(d_trainf, aes(x = smokingf, y = age, fill = smokingf)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot des Alters nach Raucherstatus\", x = \"Raucherstatus\", y = \"Alter\") +\n  scale_fill_tableau(\"Nuriel Stone\")\n\n\n\n\n\nShow the code\nd_trainf |&gt; \n  group_by(smokingf) |&gt; \n  summarise(mean(age))\n\n\n\n\n  \n\n\n\nShow the code\nd_trainf |&gt; \n  group_by(smokingf) |&gt; \n  count(age &lt; 20)\n\n\n\n\n  \n\n\n\nRaucher liegen mit 41.5 Jahren durschnittlich unter den Nicht-Rauchern mit 46.5 Jahren. Es gibt in beiden Gruppen keine Personen, die unter 20 Jahren sind, also wurden wohl nur Daten zu Personen &gt;= 20 gesammelt. Beide Gruppen scheinen nicht ganz normalverteilt zu sein.\n\n\nShow the code\nggplot(d_trainf, aes(x = smokingf, y = Cholesterol, fill = smokingf)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot Cholersterol nach Raucherstatus\", x = \"Raucherstatus\", y = \"Cholesterol\") +\n  scale_fill_tableau(\"Nuriel Stone\")\n\n\n\n\n\nShow the code\nd_trainf |&gt; \n  group_by(smokingf) |&gt; \n  summarise(mean(Cholesterol))\n\n\n\n\n  \n\n\n\nDie Cholosterol-Spiegel sind für beide Gruppen ähnlich. Auch sonst gibt es wenig Auffäligkeiten.\n\n\nShow the code\nggplot(d_trainf, aes(x = smokingf, y = hemoglobin, fill = smokingf)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot des Hemoglobins nach Raucherstatus\", x = \"Raucherstatus\", y = \"Hemoglobin\") +\n  scale_fill_tableau(\"Nuriel Stone\")\n\n\n\n\n\nShow the code\nd_trainf |&gt; \n  group_by(smokingf) |&gt; \n  summarise(mean(hemoglobin))\n\n\n\n\n  \n\n\n\nDer Hämoglobin Wert für die Raucher liegt knapp über 15, während er bei den Nicht-Rauchern knapp unter 15 liegt. Bei den Nicht-Raucher gehen die Ausreißer jedoch auch unter den Wert 7.5, während es bei den Rauchern etwas mehr Ausreißer nach oben hin gibt bzw diese haben höhere Werte als die Ausreißer der Nicht-Raucher."
  },
  {
    "objectID": "posts/Angewandtes Projekt/Projekt.html#effekte-identifizieren",
    "href": "posts/Angewandtes Projekt/Projekt.html#effekte-identifizieren",
    "title": "Raucherstatus Klassifikation",
    "section": "",
    "text": "Um zu überprüfen, welche Variablen einen Einfluss auf die AV haben, wurde im Folgenden ein stan_glm aufgestellt und anschließend das rope berechnet.\n\nm1 &lt;- stan_glm(smoking ~ ., data = d_train, seed = 42, refresh = 0)\n\nparameters(m1)\n\n\n\n  \n\n\nrope(m1)\n\nPossible multicollinearity between relaxation and systolic (r = 0.72), HDL and Cholesterol (r = 0.72), HDL and triglyceride (r = 0.7), waist and weight (r = 0.79). This might lead to inappropriate results. See 'Details' in '?rope'.\n\n\n\n\n  \n\n\nplot(rope(m1))\n\nPossible multicollinearity between relaxation and systolic (r = 0.72), HDL and Cholesterol (r = 0.72), HDL and triglyceride (r = 0.7), waist and weight (r = 0.79). This might lead to inappropriate results. See 'Details' in '?rope'.\n\n\n\n\nvif(m1)\n\n                   id                   age              systolic \n             1.018681              1.887934              2.587834 \n           relaxation `fasting blood sugar`           Cholesterol \n             2.505630              1.142631              7.455405 \n         triglyceride                   HDL                   LDL \n             3.078763              3.389189              6.134903 \n           hemoglobin       `Urine protein`    `serum creatinine` \n             1.905295              1.017452              1.445274 \n                  AST                   ALT                   Gtp \n             1.741287              1.959108              1.339327 \n               weight                 waist                height \n             6.919126              4.749702              2.929081 \n        eyesight_left        eyesight_right          hearing_left \n             1.319455              1.342833              1.487325 \n        hearing_right         dental_caries \n             1.460736              1.026594 \n\n\nAnscheinend haben nur 2 Variablen wirklich Einfluss auf die AV, und zwar hemoglobin und dental_caries. Es wurde aber als Warnung ausgegeben, dass es eine mögliche Multikollinearität zwischen relaxation und sysolic, HDL und Cholosterol, HDL und triglyceride und waistund weightgibt. Dadurch könnten die Ergebnisse verfälscht werden und der Anteil, der sich im rope befindet, verschieben. Deshalb ist es schwierig zu sagen, ob noch andere Variablen einen identifizierten Effekt auf die AV haben.\nDer Varianzinflationsfaktor (VIF) wird verwendet, um Multikollinearität zwischen den Prädiktoren in einem Regressionsmodell zu quantifizieren. Die betroffenen Variablen scheinen alle ein höheren Faktor zu haben als die anderen.\nEs macht aber Sinn, dass die Variablen-Pärchen eine Korrelation aufweisen, denn zum Beispiel stehen die Variablen relaxation und sysolic beide im Zusammenhang mit dem Blutdruck, genauso wie es bei dem Taillenumfang (waist) und Gewicht auch Sinn macht, dass sie miteinander korrelieren."
  },
  {
    "objectID": "posts/Angewandtes Projekt/Projekt.html#workflows",
    "href": "posts/Angewandtes Projekt/Projekt.html#workflows",
    "title": "Raucherstatus Klassifikation",
    "section": "",
    "text": "Verschiedene Rezepte mit unterschiedlicher Vorverarbeitung, um am Ende das beste zu finden.\nAufgrund von hohen Rechenzeiten habe ich mich dafür entschieden, mein test-sample aus dem Split-Objekt zu verwenden.\n\n# Rezept basic\nrec1 &lt;-\n  recipe(smokingf ~ ., data = test) %&gt;% \n  update_role(id, new_role = \"id variable\" )\n\n\ntidy(rec1)\n\n\n\n  \n\n\nd_baked1 &lt;- prep(rec1) |&gt; bake(new_data = NULL)\nsum(is.na(d_baked1))\n\n[1] 0\n\n# Basic Rezept mit Yeo Johnson & step normalize\nrec2 &lt;-\n  recipe(smokingf ~ ., data = test) %&gt;% \n  update_role(id, new_role = \"id variable\") |&gt; \n  step_normalize(all_numeric_predictors()) |&gt; \n  step_YeoJohnson(all_double_predictors())\n\ntidy(rec2)\n\n\n\n  \n\n\nd_baked2 &lt;- prep(rec2) |&gt; bake(new_data = NULL)\nsum(is.na(d_baked2))\n\n[1] 0\n\n# Rezept 3\nrec3 &lt;-\n  recipe(smokingf ~ height + weight + hemoglobin + triglyceride + Gtp + serum_creatinine + HDL + waist + age, data = test) %&gt;%\n  step_normalize(all_numeric_predictors())\n\ntidy(rec3)\n\n\n\n  \n\n\nd_baked3 &lt;- prep(rec3) |&gt; bake(new_data = NULL)\nsum(is.na(d_baked3))\n\n[1] 0\n\n# Rezept 4\nrec4 &lt;-\n  recipe(smokingf ~ height + weight + hemoglobin + triglyceride + Gtp + serum_creatinine + HDL + waist + age, data = test) %&gt;%\n  step_normalize(all_numeric_predictors()) |&gt; \n  step_pca(all_numeric_predictors(), num_comp = 3) \n\ntidy(rec4)\n\n\n\n  \n\n\nd_baked4 &lt;- prep(rec4) |&gt; bake(new_data = NULL)\nsum(is.na(d_baked4))\n\n[1] 0\n\n# Rezept 5 auf Basis des stan_glm\nrec5 &lt;-\n  recipe(smokingf ~ dental_caries + hemoglobin, data = test) %&gt;%\n  step_scale(all_numeric_predictors()) |&gt; \n  step_pca(all_numeric_predictors(), num_comp = 3) \n\ntidy(rec5)\n\n\n\n  \n\n\nd_baked5 &lt;- prep(rec5) |&gt; bake(new_data = NULL)\nsum(is.na(d_baked5))\n\n[1] 0\n\n#Rezept 6 mit yeo Johnson und z-skalieren\nrec6 &lt;-\n  recipe(smokingf ~ ., data = test) %&gt;% \n  update_role(id, new_role = \"id variable\") |&gt; \n  step_normalize(all_numeric_predictors()) |&gt; \n  step_scale(all_numeric_predictors()) |&gt; \n  step_YeoJohnson(all_double_predictors())\n\ntidy(rec6)\n\n\n\n  \n\n\nd_baked6 &lt;- prep(rec6) |&gt; bake(new_data = NULL)\nsum(is.na(d_baked6))\n\n[1] 0\n\n\n\n\n\n\nset.seed(42)\ncv_scheme &lt;- vfold_cv(test,\n  v = 5, \n  repeats = 2,\n  strata = smokingf)\n\n\n\n\n\n# Baum\nmod_tree &lt;-\n  decision_tree(cost_complexity = tune(),\n  tree_depth = tune(),\n  mode = \"classification\")\n\n# Random Forest\nmod_rf &lt;-\n  rand_forest(mtry = tune(),\n  min_n = tune(),\n  trees = 1000,\n  mode = \"classification\") %&gt;% \n  set_engine(\"ranger\", num.threads = 4)\n\n# XGBoost\n\nmod_boost &lt;- boost_tree(\n  mode = \"classification\",\n  engine = \"xgboost\",\n  mtry = tune(),\n  trees = 100,\n  min_n = 10\n)\n\n\n# logistische Regression\nmod_logreg &lt;- logistic_reg(\n              mode = \"classification\",\n              engine = \"glm\",\n              penalty = 1)\n\n\n# knn\nmod_knn &lt;-\n  nearest_neighbor(\n    mode = \"classification\",\n    engine = \"kknn\",\n    neighbors = tune()\n  ) \n\n\n\n\n\n\nShow the code\npreproc1 &lt;- list(rec1 = rec1)\n\nmodels1 &lt;- list(tree1 = mod_tree, rf1 = mod_rf, boost1 = mod_boost, lg1 = mod_logreg, knn1 = mod_knn)\n\nmodels2 &lt;- list(tree1 = mod_tree, boost1 = mod_boost, lg1 = mod_logreg, knn1 = mod_knn)\n\n# mit Rezept 1\nall_workflows1 &lt;- workflow_set(preproc1, models2)\n\n# mit Rezept 2\npreproc2 &lt;- list(rec2 = rec2)\nall_workflows2 &lt;- workflow_set(preproc2, models2)\n\n# mit Rezept 3\npreproc3 &lt;- list(rec3 = rec3)\nall_workflows3 &lt;- workflow_set(preproc3, models2)\n\n# mit Rezept 4\npreproc4 &lt;- list(rec4 = rec4)\nall_workflows4 &lt;- workflow_set(preproc4, models2)\n\n# mit Rezept 5\npreproc5 &lt;- list(rec5 = rec5)\nall_workflows5 &lt;- workflow_set(preproc5, models2)\n\n# mit Rezept 6\npreproc6 &lt;- list(rec6 = rec6)\nall_workflows6 &lt;- workflow_set(preproc6, models2)\n\n\n\nworkflow6 &lt;-\n  workflow() |&gt; \n  add_model(mod_boost) |&gt; \n  add_recipe(rec6)\n\n\n\n\n\n\nShow the code\n# mit Rezept 2\nset.seed(42)\ntic()\nsmokingset2 &lt;-\n  all_workflows2 %&gt;% \n  workflow_map(\n  resamples = cv_scheme,\n  grid = 10,\n  verbose = TRUE)\ntoc()\n\n# mit Rezept 3\nset.seed(42)\ntic()\nsmokingset3 &lt;-\n  all_workflows3 %&gt;% \n  workflow_map(\n  resamples = cv_scheme,\n  grid = 10,\n  verbose = TRUE)\ntoc()\n\n# mit Rezept 4\nset.seed(42)\ntic()\nsmokingset4 &lt;-\n  all_workflows4 %&gt;% \n  workflow_map(\n  resamples = cv_scheme,\n  grid = 10,\n  verbose = TRUE)\ntoc()\n\n# mit Rezept 5\nset.seed(42)\ntic()\nsmokingset5 &lt;-\n  all_workflows5 %&gt;% \n  workflow_map(\n  resamples = cv_scheme,\n  grid = 10,\n  verbose = TRUE)\ntoc()\n\n# mit Rezept 6\nset.seed(42)\ntic()\nsmokingset6 &lt;-\n  all_workflows6 %&gt;% \n  workflow_map(\n  resamples = cv_scheme,\n  grid = 10,\n  verbose = TRUE)\ntoc()\n\n\nBester Workflow, dieser hat sich durch ausprobieren der Workflowsets ergeben. Aufgrund von Rechenzeitersparnis wird hier nur noch mit dem besten Workflow weitergearbeitet.\n\n# mit Rezept 6\nset.seed(42)\ntic()\ntune6 &lt;-\n  tune_grid(object = workflow6,\n            resamples = cv_scheme,\n            grid = 10,\n            control = control_grid(save_workflow = TRUE))\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\n\ni The workflow being saved contains a recipe, which is 5.74 Mb in i memory. If\nthis was not intentional, please set the control setting i `save_workflow =\nFALSE`.\n\ntoc()\n\n348.19 sec elapsed\n\n\n\n\n\n\n\nShow the code\n# mit Rezept 2\ntune::autoplot(smokingset2) +\n  theme(legend.position = \"bottom\")\n\nsmokingset2 %&gt;% \n  collect_metrics(.metric = \"roc_auc\") %&gt;% \n  arrange(mean) \n\n# mit Rezept 3\ntune::autoplot(smokingset3) +\n  theme(legend.position = \"bottom\")\n\nsmokingset3 %&gt;% \n  collect_metrics(.metric = \"roc_auc\") %&gt;% \n  arrange(mean) \n\n# mit Rezept 4\ntune::autoplot(smokingset4) +\n  theme(legend.position = \"bottom\")\n\nsmokingset4 %&gt;% \n  collect_metrics(.metric = \"roc_auc\") %&gt;% \n  arrange(mean) \n\n# mit Rezept 5\ntune::autoplot(smokingset5) +\n  theme(legend.position = \"bottom\")\n\nsmokingset5 %&gt;% \n  collect_metrics(.metric = \"roc_auc\") %&gt;% \n  arrange(mean) \n\n# mit Rezept 6\ntune::autoplot(smokingset6) +\n  theme(legend.position = \"bottom\")\n\nsmokingset6 %&gt;% \n  collect_metrics() %&gt;% \n  arrange(mean) \n\n\nBestes Workflowset:\n\n# mit Rezept 6\ntune6 |&gt; collect_metrics()\n\n\n\n  \n\n\nautoplot(tune6)\n\n\n\n\n\n\n\nDer beste workflow scheint eine Kombination aus einem xgBoost-Modell und dem 6. Rezept zu sein. Die accuracy liegt bei ca. 0.771 und der roc_auc wert bei 0.856.\n\nbest_model6 &lt;-\n  fit_best(tune6)"
  },
  {
    "objectID": "posts/Angewandtes Projekt/Projekt.html#ergebnisse",
    "href": "posts/Angewandtes Projekt/Projekt.html#ergebnisse",
    "title": "Raucherstatus Klassifikation",
    "section": "",
    "text": "final_preds6 &lt;- \n  best_model6 %&gt;% \n  predict(new_data = d_test, type = \"prob\") %&gt;% \n  bind_cols(d_test)\n\nsubmission &lt;-\n  final_preds6 |&gt; \n  mutate(pred_prob = .pred_1,\n         pred_class = round(.pred_1, 0)) |&gt; \n  dplyr::select(id, pred_class, pred_prob)\n\n\n\nAnhand dem eigenen train-sample wird die roc-auc Kurve dargestellt.\n\nprobe &lt;- \n  best_model6 %&gt;% \n  predict(new_data = train, type = \"prob\")\n\n\ntrain2 &lt;- train |&gt; \n  mutate(smoking = as.numeric(smokingf))\nrocobj &lt;- roc(train2$smoking, probe$.pred_1)\n\nSetting levels: control = 1, case = 2\n\n\nSetting direction: controls &lt; cases\n\n#define object to plot and calculate AUC\nrocobj &lt;- roc(train2$smoking, probe$.pred_1)\n\nSetting levels: control = 1, case = 2\nSetting direction: controls &lt; cases\n\nauc &lt;- round(auc(train2$smoking, probe$.pred_1),4)\n\nSetting levels: control = 1, case = 2\nSetting direction: controls &lt; cases\n\n#create ROC plot\nggroc(rocobj, colour = 'cyan', size = 1) +\n  ggtitle(paste0('ROC Curve ', '(AUC = ', auc, ')')) +\n  scale_fill_tableau(\"Nuriel Stone\")\n\n\n\n\nDas Modell ist in der Lage, die positiven Fälle von den negativen Fällen mit einer Wahrscheinlichkeit von ca. 86 % zu unterscheiden.\nEs ist wichtig zu beachten, dass der ROC AUC-Wert nur ein Maß für die Fähigkeit eines Modells ist, die positiven Fälle von den negativen Fällen zu unterscheiden. Er sagt nichts darüber aus, wie gut das Modell die tatsächlichen Werte der positiven Fälle vorhersagt.\n\n\n\n\nprobe2 &lt;-\n  probe |&gt; \n  bind_cols(train2)\n\nprobe2 &lt;-\n  probe2 |&gt; \n  mutate(pred1 = round(.pred_1)) |&gt; \n  mutate(predf = factor(pred1))\n\nconfusion_matrix &lt;- confusionMatrix(probe2$smokingf, probe2$predf)\nprint(confusion_matrix)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction     0     1\n         0 54390 17292\n         1 11529 44193\n                                          \n               Accuracy : 0.7738          \n                 95% CI : (0.7715, 0.7761)\n    No Information Rate : 0.5174          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.5456          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.8251          \n            Specificity : 0.7188          \n         Pos Pred Value : 0.7588          \n         Neg Pred Value : 0.7931          \n             Prevalence : 0.5174          \n         Detection Rate : 0.4269          \n   Detection Prevalence : 0.5626          \n      Balanced Accuracy : 0.7719          \n                                          \n       'Positive' Class : 0               \n                                          \n\n\nDie Sensitivität ist ein Maß dafür, wie gut das Modell positive Fälle (Nicht-Raucher) erkennt. In diesem Fall ist die Sensitivität von 0,8271 gut. Das Modell erkennt 82,71 % der positiven Fälle korrekt.\nDie Spezifität ist ein Maß dafür, wie gut das Modell negative Fälle (Raucher) erkennt. In diesem Fall ist die Spezifität von 0,7194 auch gut. Das Modell erkennt 71,94 % der negativen Fälle korrekt."
  },
  {
    "objectID": "posts/Angewandtes Projekt/Projekt.html#fazit",
    "href": "posts/Angewandtes Projekt/Projekt.html#fazit",
    "title": "Raucherstatus Klassifikation",
    "section": "",
    "text": "Es sollten innerhalb dieser Analyse zwei Fragen bzw. Aufgaben bewältigit werden. Zum einem sollten die mögliche Effekte auf den Raucherstatus identifiziert werden, zum anderen sollten Beobachtungsfälle aufgrund ihrer biologischen Daten nach ihrem Raucherstatus klassifiziert werden bzw. es sollte die Wahrscheinlichkeit, ob jemand Raucher ist, angegeben werden.\nEs wurden zwei Effekte auf die AV smoking identifiziert, einmal hemoglobin und dental_caries. Es kann jedoch nicht mit Sicherheit gesagt werden, ob es nicht noch mehr geben könnte, denn im Modell befinden sich Hinweise auf eine mögliche Multikollinerität.\nDas Klassifikations-Modell ist in der Lage, die positiven Fälle von den negativen Fällen mit einer Wahrscheinlichkeit von ca. 86 % zu unterscheiden.\nIm Allgemeinen kann man sagen: Die Klassifikation des Raucherstatus auf der Grundlage biologischer Signale hat einige Vorteile gegenüber der Klassifikation auf der Grundlage von Selbstberichten. Selbstberichte sind anfällig für Verzerrungen, z. B. soziale Erwünschtheit oder Erinnerungsfehler. Biologische Signale hingegen sind objektive Messungen, die nicht von den subjektiven Wahrnehmungen der Person abhängen.\nEs gibt jedoch auch einige Herausforderungen bei der Klassifikation des Raucherstatus auf der Grundlage biologischer Signale. Zum einen sind die biologischen Signale von Rauchern und Nichtrauchern nicht immer eindeutig voneinander zu unterscheiden. Zum anderen können die biologischen Signale durch andere Faktoren beeinflusst werden, z. B. durch die Ernährung oder die Einnahme von Medikamenten."
  },
  {
    "objectID": "posts/Angewandtes Projekt/Projekt.html#quellen",
    "href": "posts/Angewandtes Projekt/Projekt.html#quellen",
    "title": "Raucherstatus Klassifikation",
    "section": "",
    "text": "Raucheranteil Deutschland: WHO. (31. August, 2015). Anteil der Raucher in Deutschland nach Geschlecht in den Jahren 2000 bis 2025 [Graph]. In Statista. Zugriff am 12. Januar 2024, von https://de.statista.com/statistik/daten/studie/596512/umfrage/verbreitung-des-rauchens-in-deutschland-nach-geschlecht/\nTriglyceride-Werte: Rassow, J., & Netzker, D. (2016). Duale Reihe Biochemie, Thieme. Edited by J. Rassow et al. Stuttgart: Georg Thieme Verlag.\nHämoglobin-Werte: https://www.blutspende.de/magazin/von-a-bis-0/was-ist-haemoglobin-und-warum-ist-es-wichtig"
  },
  {
    "objectID": "posts/Data Science 2/DS2.html",
    "href": "posts/Data Science 2/DS2.html",
    "title": "Hate Speech Klassifikation",
    "section": "",
    "text": "Verschiedene Tweets sollen auf Hate Speech überprüft und klassifiziert werden\n\n\nDie Klassifizierung von Hate Speech in Tweets ist ein bedeutendes Thema im Bereich der digitalen Kommunikation und sozialen Medien. Angesichts der zunehmenden Verbreitung von Hassrede im Internet ist es von entscheidender Bedeutung, effektive Methoden zu entwickeln, um solche Inhalte zu erkennen und einzudämmen.\nWarum könnte eine Klassifikation von Hate Speech interessieren?\n\n\nSchutz der Nutzer: Die Identifizierung von Hate Speech ermöglicht es Plattformen und Behörden, Maßnahmen zum Schutz der Nutzer vor Belästigung, Diskriminierung und Gewalt zu ergreifen.\nFörderung der digitalen Sicherheit: Die Bekämpfung von Hassrede trägt zur Schaffung einer sichereren und respektvolleren Online-Umgebung bei, die die digitale Sicherheit und das Wohlbefinden fördert.\nEindämmung von sozialen Konflikten: Durch die frühzeitige Erkennung und Entfernung von Hate Speech kann die Eskalation sozialer Konflikte verhindert und die Förderung eines harmonischen sozialen Zusammenlebens unterstützt werden.\n\n\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(easystats)\nlibrary(glmnet)\nlibrary(tictoc)\nlibrary(xgboost)\nlibrary(cowplot)\nlibrary(rlang)\nlibrary(purrr)\nlibrary(discrim)\nlibrary(ggthemes)\nlibrary(klaR)\nlibrary(rstanarm)\nlibrary(car)\nlibrary(caret)\nlibrary(pROC)\nlibrary(tm)\nlibrary(wordcloud)\nlibrary(tidytext)  \nlibrary(textrecipes)  \nlibrary(lsa)  \nlibrary(naivebayes)\nlibrary(fastrtext)  \nlibrary(remoji)  \nlibrary(tokenizers)  \nlibrary(syuzhet)\nlibrary(beepr)\nlibrary(quanteda.textstats)\nlibrary(sentimentr)\nlibrary(igraph)\nlibrary(ggraph)\nlibrary(readxl)\nlibrary(topicmodels)\nlibrary(glue)\n\n\n\n\n\nd_hate &lt;- read_csv(path_data)\n\nInsults &lt;- read_excel(insult_path)\nnew_colnames &lt;- \"word\"\ncolnames(Insults) &lt;- new_colnames\nInsults$value &lt;- 1\n\ndata(\"nrc_emotions\")\n\ncolorsn &lt;- c(\"#8175AAFF\", \"#6FB899FF\", \"#5E8A67FF\", \"#E87A90FF\", \"#A39FC9FF\", \"#94D0C0FF\", \"#AA7584\", \"#90B58B\", \"#027B8EFF\",  \"#E04F6C\", \"#028E5B\", \"#7A4FE0\", \"#B8996F\", \"#8E027B\",  \"#B8756F\" )\n\nDas Schimpfwörterlexikon stammt von der Seite https://www.insult.wiki/.\n\n\n\n\nhate2 &lt;- d_hate |&gt; \n  mutate(textclean = tweet)\nhate2$textclean &lt;-  gsub(\"https\\\\S*\", \"\", hate2$textclean)\nhate2$textclean &lt;-  gsub(\"@\\\\S*\", \"\", hate2$textclean) \nhate2$textclean  &lt;-  gsub(\"amp\", \"\", hate2$textclean) \nhate2$textclean  &lt;-  gsub(\"[\\r\\n]\", \"\", hate2$textclean)\nhate2$textclean  &lt;-  gsub(\"[[:punct:]]\", \"\", hate2$textclean)\nhate2$textclean &lt;- gsub(\"(RT|via)((?:\\\\b\\\\w*@\\\\w+)+)\",\"\", hate2$textclean)\n\nhate2 &lt;- hate2 %&gt;%\n  mutate(classc = as.factor(class))\n\n\n\n\nUm overfitting zu vermeiden werden die Daten vor dem Trainieren der Modelle noch in Train und Testdaten aufgeteilt.\n\nset.seed(42)\nd_hate2 &lt;- d_hate |&gt; \n  mutate(class = factor(class))\nd_split &lt;- initial_split(d_hate2, prop = .8, strata = class)\ntrain &lt;- training(d_split)\ntest &lt;- testing(d_split)\n\n\n\n\n\nEin Großteil der explorativen Datenanalyse orientiert sich an der Treemap House of Horror, welche wiederum auf dem tidyverse Packet basiert.\n\n\n\nsum(is.na(d_hate))\n\n[1] 0\n\nvisdat::vis_dat(d_hate, warn_large_data = FALSE)\n\n\n\n\nIm Datensatz gibt es keine fehlenden Werte. Sowohl tweet als auch class sind character-Variablen. Für die Klassifikation würde es eventuell Sinn machen class in eine factor Variable umzuwandeln.\n\n\n\n\n\nShow the code\nggplot(d_hate, aes(x = class, fill = class)) +\n  geom_bar() +\n  labs(title = \"Verteilung der Klassen\") +\n  scale_fill_tableau(\"Nuriel Stone\") +\n  theme_minimal()\n\n\n\n\n\nShow the code\nd_hate |&gt; \n  count(class == \"other\") |&gt; \n  mutate(Anteil = n/sum(n))\n\n\n\n\n  \n\n\n\nCa. 25 % der Daten sind der Klasse hate speech zugeordnet. Zum Trainieren der Modelle wäre ein höherer Anteil möglicherweise besser, aber diese Verteilung ist auf jeden Fall realistischer.\n\n\n\n\ntweets &lt;- hate2 %&gt;%\n  unnest_tokens(word, textclean)\ntweets &lt;- tweets %&gt;%\n  anti_join(stop_words)\n\nJoining with `by = join_by(word)`\n\n\nEntfernen des Worts “rt”, welches für retweet steht.\n\n# Das zu entfernende Wort\nword_to_remove &lt;- \"rt\"\n\ntweets3 &lt;- anti_join(tweets, data.frame(word = word_to_remove), by = \"word\")\n\n\n\n\n\n\nShow the code\ntweets3 %&gt;% \n  count(word, sort = TRUE) %&gt;%\n  top_n(15) %&gt;%\n  mutate(word = reorder(word, n)) %&gt;%\n  ggplot(aes(x = word, y = n)) +\n  geom_col(fill = \"#A39FC9FF\") +\n  xlab(NULL) +\n  coord_flip() +\n  labs(y = \"Count\",\n       x = \"Unique words\",\n       title = \"Most frequent words found in the tweets\",\n       subtitle = \"Stop words removed from the list\") +\n  theme_minimal()\n\n\nSelecting by n\n\n\n\n\n\nDas mit Abstand am häufigsten verwendete Wort ist trash. Dieses kommt fast 800 Mal in den Daten vor, was vielleicht darauf zu schließen ist, dass es sowohl im negativen, neutralen als auch im hate speech Kontext vorkommen kann. Es könnte nämlich dabei um trash cans, trash talking oder um trash als Beleidung für Personen gehen.\n\n\n\n\n\nShow the code\nset.seed(42)\nwordcloud(tweets3$word, max.words = 200, min.freq=5, scale=c(2.2, 1), random.order=FALSE, rot.per=0.35, colors = colorsn)\n\n\n\n\n\nAuch in der Wortwolke sieht man nochmal, dass trash das am häufigsten verwendete Wort ist, wobei einige Wörter vom plot darüber hier nicht auftauchen.\n\n\n\n\n\nShow the code\n# Converting tweets to ASCII to trackle strange characters\ntweets2 &lt;- iconv(tweets, from=\"UTF-8\", to=\"ASCII\", sub=\"\")\n# removing retweets, in case needed \ntweets2 &lt;-gsub(\"(RT|via)((?:\\\\b\\\\w*@\\\\w+)+)\",\"\",tweets)\n# removing mentions, in case needed\ntweets2 &lt;-gsub(\"@\\\\w+\",\"\",tweets)\new_sentiment&lt;-get_nrc_sentiment((tweets2))\nsentimentscores&lt;-data.frame(colSums(ew_sentiment[,]))\nnames(sentimentscores) &lt;- \"Score\"\nsentimentscores &lt;- cbind(\"sentiment\"=rownames(sentimentscores),sentimentscores)\nrownames(sentimentscores) &lt;- NULL\nggplot(data=sentimentscores,aes(x=sentiment,y=Score))+\n  geom_bar(aes(fill=sentiment),stat = \"identity\")+\n  theme(legend.position=\"none\")+\n  xlab(\"Sentiments\")+ylab(\"Scores\")+\n  ggtitle(\"Total sentiment based on scores\")+\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = colorsn)\n\n\n\n\n\nEs gibt mehr negativ gestimmte Tweets als positive, aber der Unterschied ist nicht so hoch. Die stärkste Stimmung scheint trust, also Vertrauen, zu sein, dicht gefolgt von fear. Das niedrigste Sentiment ist suprise. Jetzt wäre es noch interessant zu wissen wie sich die Sentimentanalyse noch jeweils für die beiden Klassen unterscheidet.\nFÜr die Klasse hate speech:\n\n\nShow the code\ntweetsh &lt;- tweets |&gt; \n  filter(classc == \"hate speech\")\n\n\ntweetsh1 &lt;- iconv(tweetsh, from=\"UTF-8\", to=\"ASCII\", sub=\"\")\ntweetsh1 &lt;-gsub(\"(RT|via)((?:\\\\b\\\\w*@\\\\w+)+)\",\"\",tweetsh)\ntweetsh1 &lt;-gsub(\"@\\\\w+\",\"\",tweetsh)\new_sentimenth&lt;-get_nrc_sentiment((tweetsh1))\nsentimentscoresh&lt;-data.frame(colSums(ew_sentimenth[,]))\nnames(sentimentscoresh) &lt;- \"Score\"\nsentimentscoresh &lt;- cbind(\"sentiment\"=rownames(sentimentscoresh),sentimentscoresh)\nrownames(sentimentscoresh) &lt;- NULL\nggplot(data=sentimentscoresh,aes(x=sentiment,y=Score))+\n  geom_bar(aes(fill=sentiment),stat = \"identity\")+\n  theme(legend.position=\"none\")+\n  xlab(\"Sentiments\")+ylab(\"Scores\")+\n  ggtitle(\"Class `hate speech` sentiment based on scores\")+\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = colorsn)\n\n\n\n\n\nWie zu erwarten mehr negative als positive Sentiments, jedoch ist positive immer noch erstaunlich hoch dafür, dass es hate speech ist. Insgesamt sind die negativen Sentimente wie anger, fear, disgust und sadness höher als die positiven, jedoch hätte ich gerade was anger und distgust angeht viel höhere Werte im Vergleich erwartet.\n\n\nShow the code\ntweetso &lt;- tweets |&gt; \n  filter(classc == \"other\")\n\n\ntweetso1 &lt;- iconv(tweetso, from=\"UTF-8\", to=\"ASCII\", sub=\"\")\ntweetso1 &lt;-gsub(\"(RT|via)((?:\\\\b\\\\w*@\\\\w+)+)\",\"\",tweetso)\ntweetso1 &lt;-gsub(\"@\\\\w+\",\"\",tweetso)\new_sentimento&lt;-get_nrc_sentiment((tweetso1))\nsentimentscoreso&lt;-data.frame(colSums(ew_sentimento[,]))\nnames(sentimentscoreso) &lt;- \"Score\"\nsentimentscoreso &lt;- cbind(\"sentiment\"=rownames(sentimentscoreso),sentimentscoreso)\nrownames(sentimentscoreso) &lt;- NULL\nggplot(data=sentimentscoreso,aes(x=sentiment,y=Score))+\n  geom_bar(aes(fill=sentiment),stat = \"identity\")+\n  theme(legend.position=\"none\")+\n  xlab(\"Sentiments\")+ylab(\"Scores\")+\n  ggtitle(\"Class `Other` sentiment based on scores\")+\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = colorsn)\n\n\n\n\n\nAuch bei der Klasse other überwiegen negative Sentiments, jedoch nicht so stark. Den höchsten Score hat trust, dicht gefolgt von fear. Insgesamt ist die Verteilung sehr ähnlich zu den Scores von allen tweets.\n\n\nShow the code\nfoo &lt;- tweets3 %&gt;%\n  group_by(word, classc) %&gt;%\n  count()\n\nbar &lt;- tweets3 %&gt;%\n  group_by(word) %&gt;%\n  count() %&gt;%\n  rename(all = n)\n\nfoo %&gt;%\n  left_join(bar, by = \"word\") %&gt;%\n  arrange(desc(all)) %&gt;%\n  head(50) %&gt;%\n  ungroup() %&gt;%\n  ggplot(aes(reorder(word, all, FUN = min), n, fill = classc)) +\n  geom_col(witdh = 10) +\n  xlab(NULL) +\n  coord_flip() +\n  facet_wrap(~ classc) +\n  scale_fill_tableau(\"Nuriel Stone\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\nWarning in geom_col(witdh = 10): Ignoring unknown parameters: `witdh`\n\n\n\n\n\nHier wird das Vorkommen der häufigsten Wörter in den beiden Klassen verglichen. Gut zu sehen ist dabei, dass manche Wörter erst im Kontext eine negative Bedeutung bekommen, wie z.B. trash oder white. Diese können sowohl der sachlichen Beschreibung als auch zur Beleidigung dienen.\n\n\n\n\n\nShow the code\nhate1 &lt;-\n  d_hate |&gt; \n  mutate(text_length = str_length(tweet))\n\nggplot(hate1, aes(x = class, y = text_length, color = class)) +\n  geom_point() +\n  labs(title = \"Datensatz Visualisierung\",\n       x = \"Class\",\n       y = \"Textlänge\",\n       color = \"Class\") +\n  scale_color_tableau(\"Nuriel Stone\") +\n  theme_minimal()\n\n\n\n\n\nDie Klasse other besitzt mehr Ausreißer nach oben hin, aber sonst scheint es keine großen Unterschiede zwischen beiden Klassen zu geben.\n\n\n\n\n\nShow the code\nggplot(hate1, aes(x = text_length)) +\n  geom_histogram(binwidth = 5, fill = \"#6FB899FF\", ) +\n  scale_fill_tableau(\"Nuriel Stone\") +\n  labs(title = \"Histogramm der Textlängen\", \n       x = \"Textlänge\", \n       y = \"Häufigkeit\") +\n  theme_minimal()\n\n\n\n\n\nDie Textlänge ist etwas linkschief verteilt, wobei ein Großteil der tweets unter 150 Zeichen hat. Die meisten Tweets wurden jedoch mit knapp 150 Zeichen verfasst. Dies lässt sich möglicherweise durch das Alter der Daten erklären, denn bis 2017 waren Tweets auf 140 Zeichen begrenzt und danach waren erst mehr (aktuell 280) erlaubt.\n\n\n\n\n\nShow the code\nggplot(hate1, aes(x = class, y = text_length, fill = class)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot der Textlängen nach Klasse\", x = \"class\", y = \"Textlänge\", fill = \"class\")+\n  scale_fill_tableau(\"Nuriel Stone\") +\n  theme_minimal()\n\n\n\n\n\nShow the code\nhate1 |&gt; \n  group_by(class) |&gt; \n  summarise(mean(text_length))\n\n\n\n\n  \n\n\n\nWie man zuvor schon sehen konnte, ist die Verteilung der beiden Klassen ungefähr gleich, jedoch liegt bei other die durchschnittliche Textlänge etwas höher und auch die Ausreißer haben eine höhere Textlänge. ### 3.10 TF-IDF\n\n\nShow the code\nfrequency2 &lt;-tweets3 %&gt;%\n  count(classc, word)\n\ntf_idf &lt;- frequency2 %&gt;%\n  bind_tf_idf(word, classc, n)\n\ntf_idf %&gt;%\n  arrange(desc(tf_idf)) %&gt;%\n  mutate(word = factor(word, levels = rev(unique(word)))) %&gt;%\n  top_n(30, tf_idf) %&gt;%\n  ggplot(aes(word, tf_idf, fill = classc)) +\n  geom_col() +\n  labs(x = NULL, y = \"TF-IDF values\") +\n  theme(legend.position = \"top\", axis.text.x  = element_text(angle=45, hjust=1, vjust=0.9)) +\n  scale_fill_manual(values = colorsn)\n\n\n\n\n\nTF-IDF gibt die Häufigkeit eines Wortes in einem spezifischen Kontext (also einer Klasse) innerhalb einer größeren Textsammlung (also alle Klassen) an. Dies ermöglicht es uns, Wörter zu identifizieren, die charakteristisch für eine bestimmte Klasse sind.\nFür die Klassifizierung von hate speech sind vor allem Beleidigungen wichtig, während other scheinbar neutrale Wörter enthält.\n\n\nShow the code\ntf_idf %&gt;%\n  arrange(desc(tf_idf)) %&gt;%\n  mutate(word = factor(word, levels = rev(unique(word)))) %&gt;%\n  group_by(classc) %&gt;%\n  top_n(20, tf_idf) %&gt;%\n  ungroup() %&gt;%  \n  ggplot(aes(word, tf_idf, fill = classc)) +\n  geom_col() +\n  labs(x = NULL, y = \"tf-idf\") +\n  theme(legend.position = \"none\") +\n  facet_wrap(~ classc, ncol = 3, scales = \"free\") +\n  coord_flip() +\n  labs(y = \"TF-IDF values\") +\n  scale_fill_manual(values = colorsn)\n\n\n\n\n\nHier sind nochmal die Wörter mit den höchsten TF-IDF-Werten nach Klasse aufgelistet. Auch hier ist gut zu erkennen, dass bei hate speech vor allem rassistische, diskriminierende und sexistische Beleidigungen verwendet werden, während bei other scheinbar wahllos Wörter auftauchen.\n\n\n\n\n\nShow the code\ntweets4 &lt;- hate2 %&gt;% dplyr::select(classc, textclean) %&gt;% unnest_tokens(bigram, textclean, token = \"ngrams\", n = 2)\n\nbi_sep &lt;- tweets4 %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), sep = \" \")\n\nbi_filt &lt;- bi_sep %&gt;%\n  filter(!word1 %in% stop_words$word) %&gt;%\n  filter(!word2 %in% stop_words$word)\n\n# for later\nbigram_counts &lt;- bi_filt %&gt;%\n  count(word1, word2, sort = TRUE)\n\ntweets4 &lt;- bi_filt %&gt;%\n  unite(bigram, word1, word2, sep = \" \")\n\nt2_tf_idf &lt;- tweets4 %&gt;%\n  count(classc, bigram) %&gt;%\n  bind_tf_idf(bigram, classc, n) %&gt;%\n  arrange(desc(tf_idf))\n\nt2_tf_idf %&gt;%\n  arrange(desc(tf_idf)) %&gt;%\n  mutate(bigram = factor(bigram, levels = rev(unique(bigram)))) %&gt;%\n  group_by(classc) %&gt;%\n  top_n(10, tf_idf) %&gt;%\n  ungroup() %&gt;%  \n  ggplot(aes(bigram, tf_idf, fill = classc)) +\n  geom_col() +\n  labs(x = NULL, y = \"TF-IDF values\") +\n  theme(legend.position = \"none\") +\n  facet_wrap(~ classc, ncol = 3, scales = \"free\") +\n  coord_flip() +\n  theme_minimal() +\n  scale_fill_manual(values = colorsn)\n\n\n\n\n\nAuch bei den TF-IDF-Werte für die Bigramme ist eindeutig zu essen, wie relevant Beleidigungen zur Erkennung von hate speech sind. Oftmals wurden hier einfach nur Beleidigungen kombiniert, während bei other entweder über Personen oder auch assiatische Massagen geredet wird.\n\n\n\n\n\nShow the code\nbigram_graph &lt;- bigram_counts %&gt;%\n  filter(n &gt; 6) %&gt;%\n  graph_from_data_frame()\n\n\nWarning in graph_from_data_frame(.): In `d' `NA' elements were replaced with\nstring \"NA\"\n\n\nShow the code\nset.seed(1234)\n\na &lt;- grid::arrow(type = \"closed\", length = unit(.1, \"inches\"))\n\nggraph(bigram_graph, layout = \"fr\") +\n  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,\n                 arrow = a, end_cap = circle(.07, 'inches')) +\n  geom_node_point(color = \"#94D0C0FF\", size = 3) +\n  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +\n  theme_void()\n\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\ni Please use `linewidth` in the `default_aes` field and elsewhere instead.\n\n\n\n\n\nDieses Netz ist ein sehr gutes Beispiel um zu zeigen, wie manche scheinbar harmlose Wörter in Verbindungen mit anderen eine negative Bedeutung annehmen können. Bestes Beispiel ist hier trash: redet man über trash cans, dann mag es vielleicht nur um die Müllentsorgung gehen, während trash in Verbindung mit black eine starke Beleidigung gegenüber einer Bevölkerungsgruppe ist.\n\n\n\n\n\nShow the code\nbi_sep &lt;- hate2 %&gt;%\n  dplyr::select(classc, textclean) %&gt;%\n  unnest_tokens(bigram, textclean, token = \"ngrams\", n = 2) %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), sep = \" \")\n\np1 &lt;- bi_sep %&gt;%\n  filter(word1 == \"not\") %&gt;%\n  inner_join(get_sentiments(\"bing\"), by = c(word2 = \"word\")) %&gt;%\n  count(word1, word2, sentiment, sort = TRUE) %&gt;%\n  ungroup() %&gt;%\n  arrange(desc(abs(n))) %&gt;%\n  head(15) %&gt;%\n  mutate(n = if_else(sentiment == \"positive\", n, -n)) %&gt;% \n  mutate(word2 = reorder(word2, n)) %&gt;%\n  ggplot(aes(word2, n, fill = sentiment)) +\n  geom_col(show.legend = TRUE) +\n  xlab(\"\") +\n  ylab(\"Number of occurrences\") +\n  coord_flip() +\n  theme(plot.title = element_text(size=11)) +\n  ggtitle(\"Alle Klassen - Wörter, bei denen 'not' davorsteht\") +\n  scale_fill_manual(values = c(\"#E04F6C\", \"#5E8A67FF\")) +\n  theme_minimal()\nprint(p1)\n\n\n\n\n\nAnscheinend gibt es mehr negative Wörter, die mit einem ‘not’ verneint wurden. Interessanterweise wird das Wort funny auch als negativ gewertet, was nicht wirklich Sinn macht. Im Zusammenhang mit ‘not’ ist es natürlich sinnvoll, es als negativ einzuordnen.\n\n\nShow the code\np2 &lt;- bi_sep %&gt;%\n  filter(classc == \"other\") %&gt;%\n  filter(word1 == \"not\") %&gt;%\n  inner_join(get_sentiments(\"bing\"), by = c(word2 = \"word\")) %&gt;%\n  count(word1, word2, sentiment, sort = TRUE) %&gt;%\n  ungroup() %&gt;%\n  arrange(desc(abs(n))) %&gt;%\n  head(15) %&gt;%\n  mutate(n = if_else(sentiment == \"positive\", n, -n)) %&gt;% \n  mutate(word2 = reorder(word2, n)) %&gt;%\n  ggplot(aes(word2, n, fill = sentiment)) +\n  geom_col(show.legend = TRUE) +\n  xlab(\"\") +\n  ylab(\"Sentiment score * number of occurrences\") +\n  coord_flip() +\n  theme(plot.title = element_text(size=11)) +\n  ggtitle(\"other - Wörter, bei denen 'not' davorsteht\")  +\n  scale_fill_manual(values = c(\"#E04F6C\", \"#5E8A67FF\")) +\n  theme_minimal()\nprint(p2)\n\n\n\n\n\nAuch in der Klasse other gibt es mehr negative als positive Wörter. Dies war uns ja schon vorher aus der Sentimentanalyse bewusst, deswegen ist es hier nocheinmal interessant zu sehen, dass die negative Bedeutung dieser Wörter durch das ‘not’ aufgehoben wird. Zudem taucht auch hier das Wort trash auf.\n\n\nShow the code\np3 &lt;- bi_sep %&gt;%\n  filter(classc == \"hate speech\") %&gt;%\n  filter(word1 == \"not\") %&gt;%\n  inner_join(get_sentiments(\"bing\"), by = c(word2 = \"word\")) %&gt;%\n  count(word1, word2, sentiment, sort = TRUE) %&gt;%\n  ungroup() %&gt;%\n  arrange(desc(abs(n))) %&gt;%\n  head(15) %&gt;%\n  mutate(n = if_else(sentiment == \"positive\", n, -n)) %&gt;% \n  mutate(word2 = reorder(word2, n)) %&gt;%\n  ggplot(aes(word2, n, fill = sentiment)) +\n  geom_col(show.legend = TRUE) +\n  xlab(\"\") +\n  ylab(\"Sentiment score * number of occurrences\") +\n  coord_flip() +\n  theme(plot.title = element_text(size=11)) +\n  ggtitle(\"hate speech - Wörter, bei denen 'not' davorsteht\")  +\n  scale_fill_manual(values = c(\"#E04F6C\", \"#5E8A67FF\")) +\n  theme_minimal()\n\nprint(p3)\n\n\n\n\n\nFür die Klasse hate speech gibt es auch mehr negative als positive Wörter. Dies war uns ebenfalls schon vorher aus der Sentimentanalyse bewusst, deswegen ist es hier nocheinmal interessant zu sehen, dass die negative Bedeutung dieser Wörter durch das ‘not’ aufgehoben wird. Was hier aber auffällt, vor allem im Vergleich zur anderen Klasse, ist dass hier viele negativen Wörter gar nicht so schlimm sind, also z.B. afraid oder bitter. In der anderen Klasse gab es dagegen die Wörter kill, jealous und cripple. Also wurden dort schlimmere Wörter durch ein ‘not’ aufgehoben, während bei hate speech nur meiner Meinung nach schwach negative Begriffe negiert werden.\n\n\n\n\nfreq &lt;-tweets %&gt;%\n  count(id, word)\n\nt1_tm &lt;- cast_dtm(freq, id, word, n)\nt1_tm\n\n&lt;&lt;DocumentTermMatrix (documents: 5592, terms: 12768)&gt;&gt;\nNon-/sparse entries: 39386/71359270\nSparsity           : 100%\nMaximal term length: 81\nWeighting          : term frequency (tf)\n\nt1_lda &lt;- LDA(t1_tm, k = 15, control = list(seed = 1234))\n\nt1_topics &lt;- tidy(t1_lda, matrix = \"beta\")\n\nt1_topics %&gt;%\n  group_by(topic) %&gt;%\n  top_n(5, beta) %&gt;%\n  ungroup() %&gt;%\n  arrange(topic, -beta) %&gt;%\n  mutate(term = reorder(term, beta)) %&gt;%\n  ggplot(aes(term, beta, fill = factor(topic))) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ topic, scales = \"free\", ncol = 5)  +\n  coord_flip() +\n  scale_fill_manual(values = colorsn) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\nDie Themenfelder lassen sich hier in Beleidigungen und zufällige Themen einteilen. Gerade unter den Beleidigungen gibt es nochmal Abstufungen zwischen “allgemeinen” Beleidigungen und rassistischen. Bei den allgemeinen Themen geht es unter anderem um die yankees, positive Gefühle und Vögel. So wirklich etwas aussagen tut aber keiner dieser Themenfelder, dafür sind sie sich gerade bei den Beleidigungen einfach viel zu ähnlich.\n\n\n\n\n\n\nVerschiedene Rezepte mit unterschiedlicher Vorverarbeitung, um am Ende das beste zu finden.\n\n# Rezept 1\nrec1 &lt;-\n  recipe(class ~ ., data = train) |&gt; \n  update_role(id, new_role = \"id\")  |&gt; \n  update_role(tweet, new_role = \"ignore\") |&gt; \n  step_text_normalization(tweet) |&gt; \n  step_mutate(n_schimpf = get_sentiment(tweet,  \n                                    method = \"custom\",\n                                    lexicon = Insults)) |&gt; \n  step_mutate(n_emo = get_sentiment(tweet, \n                                    method = \"nrc\",\n                                    language = \"english\"))  |&gt;\n  step_tokenize(tweet) %&gt;%\n  step_stopwords(tweet, language = \"en\", stopword_source = \"snowball\", keep = FALSE) |&gt; \n  step_tokenfilter(tweet, max_tokens = 1e2)\n\ntidy(rec1)\n\n\n\n  \n\n\nd_baked1 &lt;- prep(rec1) |&gt; bake(new_data = NULL)\nsum(is.na(d_baked1))\n\n[1] 0\n\n# Rezept 2\nrec2 &lt;-\n  recipe(class ~ ., data = train) |&gt; \n  update_role(id, new_role = \"id\")  |&gt; \n  update_role(tweet, new_role = \"ignore\") |&gt; \n  step_text_normalization(tweet) |&gt; \n  step_mutate(n_schimpf = get_sentiment(tweet,  # aus `syuzhet`\n                                    method = \"custom\",\n                                    lexicon = Insults)) |&gt; \n  step_mutate(n_emo = get_sentiment(tweet,  # aus `syuzhet`\n                                    method = \"nrc\",\n                                    language = \"englisch\"))  |&gt; \n  step_tokenize(tweet) %&gt;%\n  step_stopwords(tweet, language = \"en\", stopword_source = \"snowball\", keep = FALSE) |&gt; \n  step_tokenfilter(tweet, max_tokens = 1e3) |&gt; \n  step_tfidf(tweet) \n\ntidy(rec2)\n\n\n\n  \n\n\nd_baked2 &lt;- prep(rec2) |&gt; bake(new_data = NULL)\nsum(is.na(d_baked2))\n\n[1] 0\n\n\n\n\n\n\nset.seed(42)\ncv_scheme &lt;- vfold_cv(train,\n  v = 5, \n  repeats = 2,\n  strata = class)\n\n\n\n\n\n# Baum\nmod_tree &lt;-\n  decision_tree(cost_complexity = tune(),\n  tree_depth = tune(),\n  mode = \"classification\")\n\n# Random Forest\nmod_rf &lt;-\n  rand_forest(mtry = tune(),\n  min_n = tune(),\n  trees = 1000,\n  mode = \"classification\") %&gt;% \n  set_engine(\"ranger\", num.threads = 4)\n\n# XGBoost\n\nmod_boost &lt;- boost_tree(\n  mode = \"classification\",\n  engine = \"xgboost\",\n  mtry = tune(),\n  trees = tune(),\n  min_n = tune()\n)\n\n\n# logistische Regression\nmod_logreg &lt;- logistic_reg(\n              mode = \"classification\",\n              engine = \"glm\",\n              penalty = 1)\n\n\n\n\nDie Zahlenbenennung der Workflows ist immer die Kombination aus welchem Modell (1-4) und welches Rezept (1-2) Ich habe mich gezielt gegen Workflowsets entschieden, da die Rechenzeit für meinen Computer dafür immer sehr lange dauert.\n\n# Rezept 1 mit decision tree\nworkflow11 &lt;-\n  workflow() |&gt; \n  add_model(mod_tree) |&gt; \n  add_recipe(rec1)\n\n# Rezept 2 mit decision tree\nworkflow12 &lt;-\n  workflow() |&gt; \n  add_model(mod_tree) |&gt; \n  add_recipe(rec2)\n\n# Rezept 1 mit random forest\nworkflow21 &lt;-\n  workflow() |&gt; \n  add_model(mod_rf) |&gt; \n  add_recipe(rec1)\n\n# Rezept 2 mit random forest (dauert viel zu lange)\n# workflow22 &lt;-\n  #workflow() |&gt; \n  #add_model(mod_rf) |&gt; \n  #add_recipe(rec2)\n\n# Rezept 1 mit xgboost\nworkflow31 &lt;-\n  workflow() |&gt; \n  add_model(mod_boost) |&gt; \n  add_recipe(rec1)\n\n# Rezept 2 mit xgboost (dauert viel zu lange)\n#workflow32 &lt;-\n  #workflow() |&gt; \n  #add_model(mod_boost) |&gt; \n  #add_recipe(rec2)\n\n# Rezept 1 mit logistischer Regression\nworkflow41 &lt;-\n  workflow() |&gt; \n  add_model(mod_logreg) |&gt; \n  add_recipe(rec1)\n\n# Rezept 2 mit logistischer Regression (Modell läuft leider nicht)\n#workflow42 &lt;-\n  #workflow() |&gt; \n  #add_model(mod_logreg) |&gt; \n  #add_recipe(rec2)\n\n\n\n\nBestes Workflowset\n\n# tune11\nset.seed(42)\ntic()\ntune11 &lt;-\n  tune_grid(object = workflow11,\n            resamples = cv_scheme,\n            grid = 10,\n            control = control_grid(save_workflow = TRUE))\ntoc()\n\n493.11 sec elapsed\n\n# tune12\nset.seed(42)\ntic()\ntune12 &lt;-\n  tune_grid(object = workflow12,\n            resamples = cv_scheme,\n            grid = 10,\n            control = control_grid(save_workflow = TRUE))\ntoc()\n\n971.25 sec elapsed\n\n# tune21\nset.seed(42)\ntic()\ntune21 &lt;-\n  tune_grid(object = workflow21,\n            resamples = cv_scheme,\n            grid = 10,\n            control = control_grid(save_workflow = TRUE))\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\ntoc()\n\n456.7 sec elapsed\n\n#tune31\nset.seed(42)\ntic()\ntune31 &lt;-\n  tune_grid(object = workflow31,\n            resamples = cv_scheme,\n            grid = 10,\n            control = control_grid(save_workflow = TRUE))\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\ntoc()\n\n569.36 sec elapsed\n\n#tune41\nset.seed(42)\ntic()\ntune41 &lt;-\n  tune_grid(object = workflow41,\n            resamples = cv_scheme,\n            grid = 10,\n            control = control_grid(save_workflow = TRUE))\n\nWarning: No tuning parameters have been detected, performance will be evaluated\nusing the resamples with no tuning. Did you want to [tune()] parameters?\n\ntoc()\n\n133.95 sec elapsed\n\n\n\n\n\n\n# mit Rezept 6\ntune11 |&gt; collect_metrics()\n\n\n\n  \n\n\nautoplot(tune11)\n\n\n\ntune12 |&gt; collect_metrics()\n\n\n\n  \n\n\nautoplot(tune12)\n\n\n\ntune21 |&gt; collect_metrics()\n\n\n\n  \n\n\nautoplot(tune21)\n\n\n\ntune31 |&gt; collect_metrics()\n\n\n\n  \n\n\nautoplot(tune31)\n\n\n\ntune41 |&gt; collect_metrics()\n\n\n\n  \n\n\n\n\n\n\n\nbest_model31 &lt;-\n  fit_best(tune31)\n\n\nfinal_preds31 &lt;- \n  best_model31 %&gt;% \n  predict(new_data = test) %&gt;% \n  bind_cols(test)\n\n\n\n\nAnhand dem eigenen train-sample wird die roc-auc Kurve dargestellt.\n\ntest2 &lt;- final_preds31 |&gt; \n  mutate(class = as.numeric(class))\nfinal_preds31 &lt;- final_preds31 |&gt; \n  mutate(pred = as.numeric(.pred_class))\nrocobj &lt;- roc(test2$class, final_preds31$pred)\n\nSetting levels: control = 1, case = 2\n\n\nSetting direction: controls &lt; cases\n\n#define object to plot and calculate AUC\nrocobj &lt;- roc(test2$class, final_preds31$pred)\n\nSetting levels: control = 1, case = 2\nSetting direction: controls &lt; cases\n\nauc &lt;- round(auc(test2$class, final_preds31$pred),4)\n\nSetting levels: control = 1, case = 2\nSetting direction: controls &lt; cases\n\n#create ROC plot\nggroc(rocobj, colour = 'cyan', size = 1) +\n  ggtitle(paste0('ROC Curve ', '(AUC = ', auc, ')')) +\n  theme_minimal()\n\n\n\n\nDas Modell ist in der Lage, die positiven Fälle von den negativen Fällen mit einer Wahrscheinlichkeit von ca. 59 % zu unterscheiden. Es kann also nur etwas besser als der Zufall entscheiden.\nEs ist wichtig zu beachten, dass der ROC AUC-Wert nur ein Maß für die Fähigkeit eines Modells ist, die positiven Fälle von den negativen Fällen zu unterscheiden. Er sagt nichts darüber aus, wie gut das Modell die tatsächlichen Werte der positiven Fälle vorhersagt.\n\n\n\n\n\nShow the code\nfinal_preds312 &lt;-\n  final_preds31 |&gt; \n  bind_cols(test)\n\n\nNew names:\n* `id` -&gt; `id...2`\n* `tweet` -&gt; `tweet...3`\n* `class` -&gt; `class...4`\n* `id` -&gt; `id...6`\n* `tweet` -&gt; `tweet...7`\n* `class` -&gt; `class...8`\n\n\nShow the code\nconfusion_matrix &lt;- confusionMatrix(final_preds31$class, final_preds31$.pred_class)\nprint(confusion_matrix)\n\n\nConfusion Matrix and Statistics\n\n             Reference\nPrediction    hate speech other\n  hate speech          52   234\n  other                14   819\n                                          \n               Accuracy : 0.7784          \n                 95% CI : (0.7529, 0.8024)\n    No Information Rate : 0.941           \n    P-Value [Acc &gt; NIR] : 1               \n                                          \n                  Kappa : 0.2208          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.78788         \n            Specificity : 0.77778         \n         Pos Pred Value : 0.18182         \n         Neg Pred Value : 0.98319         \n             Prevalence : 0.05898         \n         Detection Rate : 0.04647         \n   Detection Prevalence : 0.25559         \n      Balanced Accuracy : 0.78283         \n                                          \n       'Positive' Class : hate speech     \n                                          \n\n\nShow the code\nsensitivity1 &lt;- confusion_matrix[[\"byClass\"]][[\"Sensitivity\"]]\nsensitivityp1 &lt;- round(sensitivity1*100, digits = 2)\nspecificity1 &lt;- confusion_matrix[[\"byClass\"]][[\"Specificity\"]]\nspecificityp1 &lt;- round(specificity1*100, digits = 2)\naccuracy1 &lt;- confusion_matrix[[\"overall\"]][[\"Accuracy\"]]\naccuracyp1 &lt;- round(accuracy1*100, digits = 2)\n\n\n\n\nShow the code\nglue('Die Accuracy gibt an, wie viele der insgesamt vorhergesagten Klassen mit den tatsächlichen Klassen übereinstimmen, gemessen als Anteil der korrekt klassifizierten Instanzen an der Gesamtzahl der Instanzen im Datensatz. Bei diesem Modell liegt die Accuracy bei {accuracy1}, d.h. es wurden {accuracyp1} % der Fälle richtig klassifiziert.\n\nDie Sensitivität ist ein Maß dafür, wie gut das Modell positive Fälle (hate speech) erkennt. In diesem Fall ist die Sensitivität von {sensitivity1} gut. Das Modell erkennt {sensitivityp1} % der positiven Fälle korrekt.\n\nDie Spezifität ist ein Maß dafür, wie gut das Modell negative Fälle (other) erkennt. In diesem Fall ist die Spezifität von {specificity1} auch gut. Das Modell erkennt {specificityp1} % der negativen Fälle korrekt.')\n\n\nDie Accuracy gibt an, wie viele der insgesamt vorhergesagten Klassen mit den tatsächlichen Klassen übereinstimmen, gemessen als Anteil der korrekt klassifizierten Instanzen an der Gesamtzahl der Instanzen im Datensatz. Bei diesem Modell liegt die Accuracy bei 0.778373547810545, d.h. es wurden 77.84 % der Fälle richtig klassifiziert.\n\nDie Sensitivität ist ein Maß dafür, wie gut das Modell positive Fälle (hate speech) erkennt. In diesem Fall ist die Sensitivität von 0.787878787878788 gut. Das Modell erkennt 78.79 % der positiven Fälle korrekt.\n\nDie Spezifität ist ein Maß dafür, wie gut das Modell negative Fälle (other) erkennt. In diesem Fall ist die Spezifität von 0.777777777777778 auch gut. Das Modell erkennt 77.78 % der negativen Fälle korrekt.\n\n\n\n\n\n\n\n\n\nlibrary(reticulate)\n\nuse_virtualenv(\"~/Blog/Blogecmb/ds2venv\")\n\n\n\n\n\nimport tensorflow\n\nWARNING:tensorflow:From C:\\Users\\EMILIA~1\\OneDrive\\DOKUME~1\\Blog\\Blogecmb\\ds2venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n\nfrom transformers import pipeline\n\nclassifier = pipeline(\"text-classification\", model=\"facebook/roberta-hate-speech-dynabench-r4-target\")\n\n\n\n\n\ntweetsonly &lt;- test$tweet\n\n\ntweets = r.tweetsonly\n\nresult = classifier(tweets)\n\n\nresult &lt;- py$result\ntest3 &lt;- test\n\nlabels &lt;- map(result, \"label\")\n\n\nif (nrow(test3) == length(labels)) {\n  test3$hatespeech &lt;- unlist(labels)\n} else {\n  print(\"Error!\")\n}\n\ntest3 &lt;-\n  test3|&gt; \n  mutate(hatespeech = factor(hatespeech),\n         hatespeech = case_when(hatespeech == \"nothate\" ~ \"other\",\n                          hatespeech == \"hate\" ~ \"hate speech\"),\n         hatespeech = factor(hatespeech))\n\n\n\n\n\n\nShow the code\nmy_metrics2 &lt;- metric_set(accuracy, f_meas)\nmy_metrics2(test3,\n           truth = class,\n           estimate = hatespeech)\n\n\n\n\n  \n\n\n\n\n\nShow the code\nconfusion_matrix2 &lt;- confusionMatrix(test3$class, test3$hatespeech)\nprint(confusion_matrix2)\n\n\nConfusion Matrix and Statistics\n\n             Reference\nPrediction    hate speech other\n  hate speech         266    20\n  other                96   737\n                                         \n               Accuracy : 0.8963         \n                 95% CI : (0.877, 0.9136)\n    No Information Rate : 0.6765         \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16      \n                                         \n                  Kappa : 0.7494         \n                                         \n Mcnemar's Test P-Value : 3.317e-12      \n                                         \n            Sensitivity : 0.7348         \n            Specificity : 0.9736         \n         Pos Pred Value : 0.9301         \n         Neg Pred Value : 0.8848         \n             Prevalence : 0.3235         \n         Detection Rate : 0.2377         \n   Detection Prevalence : 0.2556         \n      Balanced Accuracy : 0.8542         \n                                         \n       'Positive' Class : hate speech    \n                                         \n\n\nShow the code\nsensitivity2 &lt;- confusion_matrix2[[\"byClass\"]][[\"Sensitivity\"]]\nsensitivityp2 &lt;- round(sensitivity2*100, digits = 2)\nspecificity2 &lt;- confusion_matrix2[[\"byClass\"]][[\"Specificity\"]]\nspecificityp2 &lt;- round(specificity2*100, digits = 2)\naccuracy2 &lt;- confusion_matrix2[[\"overall\"]][[\"Accuracy\"]]\naccuracyp2 &lt;- round(accuracy2*100, digits = 2)\n\n\n\n\nShow the code\nglue('Die Accuracy gibt an, wie viele der insgesamt vorhergesagten Klassen mit den tatsächlichen Klassen übereinstimmen, gemessen als Anteil der korrekt klassifizierten Instanzen an der Gesamtzahl der Instanzen im Datensatz. Bei diesem Modell liegt die Accuracy bei {accuracy2}, d.h. es wurden {accuracyp2} % der Fälle richtig klassifiziert.\n\nDie Sensitivität ist ein Maß dafür, wie gut das Modell positive Fälle (hate speech) erkennt. In diesem Fall ist die Sensitivität von {sensitivity2} gut. Das Modell erkennt {sensitivityp2} % der positiven Fälle korrekt.\n\nDie Spezifität ist ein Maß dafür, wie gut das Modell negative Fälle (other) erkennt. In diesem Fall ist die Spezifität von {specificity2} auch gut. Das Modell erkennt {specificityp2} % der negativen Fälle korrekt.')\n\n\nDie Accuracy gibt an, wie viele der insgesamt vorhergesagten Klassen mit den tatsächlichen Klassen übereinstimmen, gemessen als Anteil der korrekt klassifizierten Instanzen an der Gesamtzahl der Instanzen im Datensatz. Bei diesem Modell liegt die Accuracy bei 0.896336014298481, d.h. es wurden 89.63 % der Fälle richtig klassifiziert.\n\nDie Sensitivität ist ein Maß dafür, wie gut das Modell positive Fälle (hate speech) erkennt. In diesem Fall ist die Sensitivität von 0.734806629834254 gut. Das Modell erkennt 73.48 % der positiven Fälle korrekt.\n\nDie Spezifität ist ein Maß dafür, wie gut das Modell negative Fälle (other) erkennt. In diesem Fall ist die Spezifität von 0.973579920739762 auch gut. Das Modell erkennt 97.36 % der negativen Fälle korrekt.\n\n\n\n\n\n\nIm Vergleich schneidet das hugging face Modell deutlich besser ab als das tidymodels-Modell, was aber natürlich auch an meiner Vorverarbeitung liegen kann.\nDurch die EDA ist ganz klar die Relevanz von Schimpfwörtern zur Erkennung von hate speech hervorgestochen, weswegen es auch wichtig für das tidymodels Rezept war. Leider hat mit tidymodels nicht alles ganz so gut funktioniert, was oft auch an der sehr hohen Rechenzeit war, weswegen hier vielleicht nicht das volle Potenzial ausgeschöpft wurde.\nAlles in allem, konnte man durch die EDA sehr viele Rückschlüsse ziehen, wobei für mich vor allem das Bigram-Netz interessant war. Hier konnte man nämlich sehr gut erkennen, wie wichtig der Kontext für die Verwendung von bestimmten Wörtern ist, denn so kann die Bedeutung ganz schnell von einer neutralen Beschreibung zu einer Beleidigung wechseln.\n\n\n\n\nsessionInfo()\n\nR version 4.1.3 (2022-03-10)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   \n[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                   \n[5] LC_TIME=German_Germany.1252    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] reticulate_1.28           ranger_0.14.1            \n [3] rpart_4.1.16              stopwords_2.3            \n [5] stringi_1.7.6             glue_1.6.2               \n [7] topicmodels_0.2-14        readxl_1.3.1             \n [9] ggraph_2.1.0              igraph_1.4.2             \n[11] sentimentr_2.9.0          quanteda.textstats_0.96.1\n[13] beepr_1.3                 syuzhet_1.0.7            \n[15] tokenizers_0.3.0          remoji_0.1.0             \n[17] fastrtext_0.3.4           naivebayes_0.9.7         \n[19] lsa_0.73.3                SnowballC_0.7.0          \n[21] textrecipes_1.0.3         tidytext_0.4.1           \n[23] wordcloud_2.6             RColorBrewer_1.1-3       \n[25] tm_0.7-11                 NLP_0.2-1                \n[27] pROC_1.18.0               caret_6.0-94             \n[29] lattice_0.20-45           car_3.1-2                \n[31] carData_3.0-5             rstanarm_2.21.4          \n[33] Rcpp_1.0.8                klaR_1.7-3               \n[35] MASS_7.3-55               ggthemes_5.0.0           \n[37] discrim_1.0.1             rlang_1.1.2              \n[39] cowplot_1.1.2             xgboost_1.6.0.1          \n[41] tictoc_1.2                glmnet_4.1-7             \n[43] Matrix_1.5-4              see_0.8.1                \n[45] report_0.5.7              parameters_0.21.0        \n[47] performance_0.10.3        modelbased_0.8.6         \n[49] insight_0.19.2            effectsize_0.8.3         \n[51] datawizard_0.7.1          correlation_0.8.4        \n[53] bayestestR_0.13.1         easystats_0.6.0          \n[55] yardstick_1.1.0           workflowsets_1.0.1       \n[57] workflows_1.1.3           tune_1.1.2               \n[59] rsample_1.2.0             recipes_1.0.9            \n[61] parsnip_1.0.4             modeldata_1.2.0          \n[63] infer_1.0.5               dials_1.2.0              \n[65] scales_1.2.1              broom_1.0.5              \n[67] tidymodels_1.0.0          forcats_0.5.1            \n[69] stringr_1.5.0             dplyr_1.1.2              \n[71] purrr_1.0.1               readr_2.1.2              \n[73] tidyr_1.2.0               tibble_3.2.1             \n[75] ggplot2_3.4.4             tidyverse_1.3.1          \n\nloaded via a namespace (and not attached):\n  [1] ModelMetrics_1.2.2.2 visdat_0.6.0         bit64_4.0.5         \n  [4] knitr_1.37           dygraphs_1.1.1.6     data.table_1.14.8   \n  [7] inline_0.3.19        hardhat_1.3.0        generics_0.1.3      \n [10] GPfit_1.0-8          qdapRegex_0.7.8      combinat_0.0-8      \n [13] proxy_0.4-27         future_1.33.0        nsyllable_1.0.1     \n [16] bit_4.0.5            tzdb_0.3.0           xml2_1.3.3          \n [19] lubridate_1.8.0      httpuv_1.6.6         StanHeaders_2.21.0-7\n [22] assertthat_0.2.1     viridis_0.6.4        gower_1.0.1         \n [25] xfun_0.39            hms_1.1.3            bayesplot_1.10.0    \n [28] evaluate_0.23        promises_1.2.0.1     fansi_1.0.2         \n [31] dbplyr_2.3.2         DBI_1.1.3            htmlwidgets_1.6.2   \n [34] stats4_4.1.3         ellipsis_0.3.2       crosstalk_1.2.1     \n [37] backports_1.4.1      markdown_1.12        RcppParallel_5.1.7  \n [40] vctrs_0.6.1          here_1.0.1           abind_1.4-5         \n [43] withr_2.5.2          ggforce_0.4.1        vroom_1.6.1         \n [46] xts_0.13.1           crayon_1.5.2         labeling_0.4.3      \n [49] pkgconfig_2.0.3      slam_0.1-50          tweenr_2.0.2        \n [52] nlme_3.1-155         nnet_7.3-17          globals_0.16.2      \n [55] questionr_0.7.8      lifecycle_1.0.4      miniUI_0.1.1.1      \n [58] colourpicker_1.3.0   lexicon_1.2.1        modelr_0.1.11       \n [61] rprojroot_2.0.4      cellranger_1.1.0     polyclip_1.10-4     \n [64] matrixStats_0.63.0   loo_2.6.0            boot_1.3-28         \n [67] zoo_1.8-12           reprex_2.0.2         base64enc_0.1-3     \n [70] png_0.1-8            viridisLite_0.4.2    shape_1.4.6         \n [73] parallelly_1.36.0    shinystan_2.6.0      magrittr_2.0.2      \n [76] plyr_1.8.8           audio_0.1-10         threejs_0.3.3       \n [79] compiler_4.1.3       rstantools_2.3.1.1   lme4_1.1-32         \n [82] cli_3.6.0            DiceDesign_1.9       listenv_0.9.0       \n [85] janeaustenr_1.0.0    tidyselect_1.2.0     highr_0.10          \n [88] yaml_2.3.5           ggrepel_0.9.3        grid_4.1.3          \n [91] fastmatch_1.1-3      tools_4.1.3          future.apply_1.11.0 \n [94] parallel_4.1.3       rstudioapi_0.15.0    foreach_1.5.2       \n [97] quanteda_3.3.0       gridExtra_2.3        prodlim_2023.03.31  \n[100] farver_2.1.1         digest_0.6.29        shiny_1.7.2         \n[103] lava_1.7.3           later_1.3.0          httr_1.4.7          \n[106] colorspace_2.0-3     rvest_1.0.3          fs_1.5.2            \n[109] splines_4.1.3        graphlayouts_0.8.4   shinythemes_1.2.0   \n[112] xtable_1.8-4         jsonlite_1.8.4       nloptr_2.0.3        \n[115] tidygraph_1.2.3      timeDate_4032.109    rstan_2.21.7        \n[118] modeltools_0.2-23    ipred_0.9-14         R6_2.5.1            \n[121] lhs_1.1.6            pillar_1.9.0         htmltools_0.5.5     \n[124] mime_0.12            fastmap_1.1.0        minqa_1.2.5         \n[127] DT_0.31              class_7.3-20         codetools_0.2-18    \n[130] pkgbuild_1.4.3       furrr_0.3.1          utf8_1.2.2          \n[133] gtools_3.9.4         shinyjs_2.1.0        survival_3.2-13     \n[136] textclean_0.9.3      rmarkdown_2.25       munsell_0.5.0       \n[139] e1071_1.7-13         iterators_1.0.14     labelled_2.12.0     \n[142] haven_2.4.3          reshape2_1.4.4       gtable_0.3.4"
  },
  {
    "objectID": "posts/Data Science 2/DS2.html#forschungsfrage",
    "href": "posts/Data Science 2/DS2.html#forschungsfrage",
    "title": "Hate Speech Klassifikation",
    "section": "",
    "text": "Die Klassifizierung von Hate Speech in Tweets ist ein bedeutendes Thema im Bereich der digitalen Kommunikation und sozialen Medien. Angesichts der zunehmenden Verbreitung von Hassrede im Internet ist es von entscheidender Bedeutung, effektive Methoden zu entwickeln, um solche Inhalte zu erkennen und einzudämmen.\nWarum könnte eine Klassifikation von Hate Speech interessieren?\n\n\nSchutz der Nutzer: Die Identifizierung von Hate Speech ermöglicht es Plattformen und Behörden, Maßnahmen zum Schutz der Nutzer vor Belästigung, Diskriminierung und Gewalt zu ergreifen.\nFörderung der digitalen Sicherheit: Die Bekämpfung von Hassrede trägt zur Schaffung einer sichereren und respektvolleren Online-Umgebung bei, die die digitale Sicherheit und das Wohlbefinden fördert.\nEindämmung von sozialen Konflikten: Durch die frühzeitige Erkennung und Entfernung von Hate Speech kann die Eskalation sozialer Konflikte verhindert und die Förderung eines harmonischen sozialen Zusammenlebens unterstützt werden."
  },
  {
    "objectID": "posts/Data Science 2/DS2.html#vorbereitung",
    "href": "posts/Data Science 2/DS2.html#vorbereitung",
    "title": "Hate Speech Klassifikation",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(easystats)\nlibrary(glmnet)\nlibrary(tictoc)\nlibrary(xgboost)\nlibrary(cowplot)\nlibrary(rlang)\nlibrary(purrr)\nlibrary(discrim)\nlibrary(ggthemes)\nlibrary(klaR)\nlibrary(rstanarm)\nlibrary(car)\nlibrary(caret)\nlibrary(pROC)\nlibrary(tm)\nlibrary(wordcloud)\nlibrary(tidytext)  \nlibrary(textrecipes)  \nlibrary(lsa)  \nlibrary(naivebayes)\nlibrary(fastrtext)  \nlibrary(remoji)  \nlibrary(tokenizers)  \nlibrary(syuzhet)\nlibrary(beepr)\nlibrary(quanteda.textstats)\nlibrary(sentimentr)\nlibrary(igraph)\nlibrary(ggraph)\nlibrary(readxl)\nlibrary(topicmodels)\nlibrary(glue)\n\n\n\n\n\nd_hate &lt;- read_csv(path_data)\n\nInsults &lt;- read_excel(insult_path)\nnew_colnames &lt;- \"word\"\ncolnames(Insults) &lt;- new_colnames\nInsults$value &lt;- 1\n\ndata(\"nrc_emotions\")\n\ncolorsn &lt;- c(\"#8175AAFF\", \"#6FB899FF\", \"#5E8A67FF\", \"#E87A90FF\", \"#A39FC9FF\", \"#94D0C0FF\", \"#AA7584\", \"#90B58B\", \"#027B8EFF\",  \"#E04F6C\", \"#028E5B\", \"#7A4FE0\", \"#B8996F\", \"#8E027B\",  \"#B8756F\" )\n\nDas Schimpfwörterlexikon stammt von der Seite https://www.insult.wiki/.\n\n\n\n\nhate2 &lt;- d_hate |&gt; \n  mutate(textclean = tweet)\nhate2$textclean &lt;-  gsub(\"https\\\\S*\", \"\", hate2$textclean)\nhate2$textclean &lt;-  gsub(\"@\\\\S*\", \"\", hate2$textclean) \nhate2$textclean  &lt;-  gsub(\"amp\", \"\", hate2$textclean) \nhate2$textclean  &lt;-  gsub(\"[\\r\\n]\", \"\", hate2$textclean)\nhate2$textclean  &lt;-  gsub(\"[[:punct:]]\", \"\", hate2$textclean)\nhate2$textclean &lt;- gsub(\"(RT|via)((?:\\\\b\\\\w*@\\\\w+)+)\",\"\", hate2$textclean)\n\nhate2 &lt;- hate2 %&gt;%\n  mutate(classc = as.factor(class))\n\n\n\n\nUm overfitting zu vermeiden werden die Daten vor dem Trainieren der Modelle noch in Train und Testdaten aufgeteilt.\n\nset.seed(42)\nd_hate2 &lt;- d_hate |&gt; \n  mutate(class = factor(class))\nd_split &lt;- initial_split(d_hate2, prop = .8, strata = class)\ntrain &lt;- training(d_split)\ntest &lt;- testing(d_split)"
  },
  {
    "objectID": "posts/Data Science 2/DS2.html#explorative-datenanalyse",
    "href": "posts/Data Science 2/DS2.html#explorative-datenanalyse",
    "title": "Hate Speech Klassifikation",
    "section": "",
    "text": "Ein Großteil der explorativen Datenanalyse orientiert sich an der Treemap House of Horror, welche wiederum auf dem tidyverse Packet basiert.\n\n\n\nsum(is.na(d_hate))\n\n[1] 0\n\nvisdat::vis_dat(d_hate, warn_large_data = FALSE)\n\n\n\n\nIm Datensatz gibt es keine fehlenden Werte. Sowohl tweet als auch class sind character-Variablen. Für die Klassifikation würde es eventuell Sinn machen class in eine factor Variable umzuwandeln.\n\n\n\n\n\nShow the code\nggplot(d_hate, aes(x = class, fill = class)) +\n  geom_bar() +\n  labs(title = \"Verteilung der Klassen\") +\n  scale_fill_tableau(\"Nuriel Stone\") +\n  theme_minimal()\n\n\n\n\n\nShow the code\nd_hate |&gt; \n  count(class == \"other\") |&gt; \n  mutate(Anteil = n/sum(n))\n\n\n\n\n  \n\n\n\nCa. 25 % der Daten sind der Klasse hate speech zugeordnet. Zum Trainieren der Modelle wäre ein höherer Anteil möglicherweise besser, aber diese Verteilung ist auf jeden Fall realistischer.\n\n\n\n\ntweets &lt;- hate2 %&gt;%\n  unnest_tokens(word, textclean)\ntweets &lt;- tweets %&gt;%\n  anti_join(stop_words)\n\nJoining with `by = join_by(word)`\n\n\nEntfernen des Worts “rt”, welches für retweet steht.\n\n# Das zu entfernende Wort\nword_to_remove &lt;- \"rt\"\n\ntweets3 &lt;- anti_join(tweets, data.frame(word = word_to_remove), by = \"word\")\n\n\n\n\n\n\nShow the code\ntweets3 %&gt;% \n  count(word, sort = TRUE) %&gt;%\n  top_n(15) %&gt;%\n  mutate(word = reorder(word, n)) %&gt;%\n  ggplot(aes(x = word, y = n)) +\n  geom_col(fill = \"#A39FC9FF\") +\n  xlab(NULL) +\n  coord_flip() +\n  labs(y = \"Count\",\n       x = \"Unique words\",\n       title = \"Most frequent words found in the tweets\",\n       subtitle = \"Stop words removed from the list\") +\n  theme_minimal()\n\n\nSelecting by n\n\n\n\n\n\nDas mit Abstand am häufigsten verwendete Wort ist trash. Dieses kommt fast 800 Mal in den Daten vor, was vielleicht darauf zu schließen ist, dass es sowohl im negativen, neutralen als auch im hate speech Kontext vorkommen kann. Es könnte nämlich dabei um trash cans, trash talking oder um trash als Beleidung für Personen gehen.\n\n\n\n\n\nShow the code\nset.seed(42)\nwordcloud(tweets3$word, max.words = 200, min.freq=5, scale=c(2.2, 1), random.order=FALSE, rot.per=0.35, colors = colorsn)\n\n\n\n\n\nAuch in der Wortwolke sieht man nochmal, dass trash das am häufigsten verwendete Wort ist, wobei einige Wörter vom plot darüber hier nicht auftauchen.\n\n\n\n\n\nShow the code\n# Converting tweets to ASCII to trackle strange characters\ntweets2 &lt;- iconv(tweets, from=\"UTF-8\", to=\"ASCII\", sub=\"\")\n# removing retweets, in case needed \ntweets2 &lt;-gsub(\"(RT|via)((?:\\\\b\\\\w*@\\\\w+)+)\",\"\",tweets)\n# removing mentions, in case needed\ntweets2 &lt;-gsub(\"@\\\\w+\",\"\",tweets)\new_sentiment&lt;-get_nrc_sentiment((tweets2))\nsentimentscores&lt;-data.frame(colSums(ew_sentiment[,]))\nnames(sentimentscores) &lt;- \"Score\"\nsentimentscores &lt;- cbind(\"sentiment\"=rownames(sentimentscores),sentimentscores)\nrownames(sentimentscores) &lt;- NULL\nggplot(data=sentimentscores,aes(x=sentiment,y=Score))+\n  geom_bar(aes(fill=sentiment),stat = \"identity\")+\n  theme(legend.position=\"none\")+\n  xlab(\"Sentiments\")+ylab(\"Scores\")+\n  ggtitle(\"Total sentiment based on scores\")+\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = colorsn)\n\n\n\n\n\nEs gibt mehr negativ gestimmte Tweets als positive, aber der Unterschied ist nicht so hoch. Die stärkste Stimmung scheint trust, also Vertrauen, zu sein, dicht gefolgt von fear. Das niedrigste Sentiment ist suprise. Jetzt wäre es noch interessant zu wissen wie sich die Sentimentanalyse noch jeweils für die beiden Klassen unterscheidet.\nFÜr die Klasse hate speech:\n\n\nShow the code\ntweetsh &lt;- tweets |&gt; \n  filter(classc == \"hate speech\")\n\n\ntweetsh1 &lt;- iconv(tweetsh, from=\"UTF-8\", to=\"ASCII\", sub=\"\")\ntweetsh1 &lt;-gsub(\"(RT|via)((?:\\\\b\\\\w*@\\\\w+)+)\",\"\",tweetsh)\ntweetsh1 &lt;-gsub(\"@\\\\w+\",\"\",tweetsh)\new_sentimenth&lt;-get_nrc_sentiment((tweetsh1))\nsentimentscoresh&lt;-data.frame(colSums(ew_sentimenth[,]))\nnames(sentimentscoresh) &lt;- \"Score\"\nsentimentscoresh &lt;- cbind(\"sentiment\"=rownames(sentimentscoresh),sentimentscoresh)\nrownames(sentimentscoresh) &lt;- NULL\nggplot(data=sentimentscoresh,aes(x=sentiment,y=Score))+\n  geom_bar(aes(fill=sentiment),stat = \"identity\")+\n  theme(legend.position=\"none\")+\n  xlab(\"Sentiments\")+ylab(\"Scores\")+\n  ggtitle(\"Class `hate speech` sentiment based on scores\")+\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = colorsn)\n\n\n\n\n\nWie zu erwarten mehr negative als positive Sentiments, jedoch ist positive immer noch erstaunlich hoch dafür, dass es hate speech ist. Insgesamt sind die negativen Sentimente wie anger, fear, disgust und sadness höher als die positiven, jedoch hätte ich gerade was anger und distgust angeht viel höhere Werte im Vergleich erwartet.\n\n\nShow the code\ntweetso &lt;- tweets |&gt; \n  filter(classc == \"other\")\n\n\ntweetso1 &lt;- iconv(tweetso, from=\"UTF-8\", to=\"ASCII\", sub=\"\")\ntweetso1 &lt;-gsub(\"(RT|via)((?:\\\\b\\\\w*@\\\\w+)+)\",\"\",tweetso)\ntweetso1 &lt;-gsub(\"@\\\\w+\",\"\",tweetso)\new_sentimento&lt;-get_nrc_sentiment((tweetso1))\nsentimentscoreso&lt;-data.frame(colSums(ew_sentimento[,]))\nnames(sentimentscoreso) &lt;- \"Score\"\nsentimentscoreso &lt;- cbind(\"sentiment\"=rownames(sentimentscoreso),sentimentscoreso)\nrownames(sentimentscoreso) &lt;- NULL\nggplot(data=sentimentscoreso,aes(x=sentiment,y=Score))+\n  geom_bar(aes(fill=sentiment),stat = \"identity\")+\n  theme(legend.position=\"none\")+\n  xlab(\"Sentiments\")+ylab(\"Scores\")+\n  ggtitle(\"Class `Other` sentiment based on scores\")+\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = colorsn)\n\n\n\n\n\nAuch bei der Klasse other überwiegen negative Sentiments, jedoch nicht so stark. Den höchsten Score hat trust, dicht gefolgt von fear. Insgesamt ist die Verteilung sehr ähnlich zu den Scores von allen tweets.\n\n\nShow the code\nfoo &lt;- tweets3 %&gt;%\n  group_by(word, classc) %&gt;%\n  count()\n\nbar &lt;- tweets3 %&gt;%\n  group_by(word) %&gt;%\n  count() %&gt;%\n  rename(all = n)\n\nfoo %&gt;%\n  left_join(bar, by = \"word\") %&gt;%\n  arrange(desc(all)) %&gt;%\n  head(50) %&gt;%\n  ungroup() %&gt;%\n  ggplot(aes(reorder(word, all, FUN = min), n, fill = classc)) +\n  geom_col(witdh = 10) +\n  xlab(NULL) +\n  coord_flip() +\n  facet_wrap(~ classc) +\n  scale_fill_tableau(\"Nuriel Stone\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\nWarning in geom_col(witdh = 10): Ignoring unknown parameters: `witdh`\n\n\n\n\n\nHier wird das Vorkommen der häufigsten Wörter in den beiden Klassen verglichen. Gut zu sehen ist dabei, dass manche Wörter erst im Kontext eine negative Bedeutung bekommen, wie z.B. trash oder white. Diese können sowohl der sachlichen Beschreibung als auch zur Beleidigung dienen.\n\n\n\n\n\nShow the code\nhate1 &lt;-\n  d_hate |&gt; \n  mutate(text_length = str_length(tweet))\n\nggplot(hate1, aes(x = class, y = text_length, color = class)) +\n  geom_point() +\n  labs(title = \"Datensatz Visualisierung\",\n       x = \"Class\",\n       y = \"Textlänge\",\n       color = \"Class\") +\n  scale_color_tableau(\"Nuriel Stone\") +\n  theme_minimal()\n\n\n\n\n\nDie Klasse other besitzt mehr Ausreißer nach oben hin, aber sonst scheint es keine großen Unterschiede zwischen beiden Klassen zu geben.\n\n\n\n\n\nShow the code\nggplot(hate1, aes(x = text_length)) +\n  geom_histogram(binwidth = 5, fill = \"#6FB899FF\", ) +\n  scale_fill_tableau(\"Nuriel Stone\") +\n  labs(title = \"Histogramm der Textlängen\", \n       x = \"Textlänge\", \n       y = \"Häufigkeit\") +\n  theme_minimal()\n\n\n\n\n\nDie Textlänge ist etwas linkschief verteilt, wobei ein Großteil der tweets unter 150 Zeichen hat. Die meisten Tweets wurden jedoch mit knapp 150 Zeichen verfasst. Dies lässt sich möglicherweise durch das Alter der Daten erklären, denn bis 2017 waren Tweets auf 140 Zeichen begrenzt und danach waren erst mehr (aktuell 280) erlaubt.\n\n\n\n\n\nShow the code\nggplot(hate1, aes(x = class, y = text_length, fill = class)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot der Textlängen nach Klasse\", x = \"class\", y = \"Textlänge\", fill = \"class\")+\n  scale_fill_tableau(\"Nuriel Stone\") +\n  theme_minimal()\n\n\n\n\n\nShow the code\nhate1 |&gt; \n  group_by(class) |&gt; \n  summarise(mean(text_length))\n\n\n\n\n  \n\n\n\nWie man zuvor schon sehen konnte, ist die Verteilung der beiden Klassen ungefähr gleich, jedoch liegt bei other die durchschnittliche Textlänge etwas höher und auch die Ausreißer haben eine höhere Textlänge. ### 3.10 TF-IDF\n\n\nShow the code\nfrequency2 &lt;-tweets3 %&gt;%\n  count(classc, word)\n\ntf_idf &lt;- frequency2 %&gt;%\n  bind_tf_idf(word, classc, n)\n\ntf_idf %&gt;%\n  arrange(desc(tf_idf)) %&gt;%\n  mutate(word = factor(word, levels = rev(unique(word)))) %&gt;%\n  top_n(30, tf_idf) %&gt;%\n  ggplot(aes(word, tf_idf, fill = classc)) +\n  geom_col() +\n  labs(x = NULL, y = \"TF-IDF values\") +\n  theme(legend.position = \"top\", axis.text.x  = element_text(angle=45, hjust=1, vjust=0.9)) +\n  scale_fill_manual(values = colorsn)\n\n\n\n\n\nTF-IDF gibt die Häufigkeit eines Wortes in einem spezifischen Kontext (also einer Klasse) innerhalb einer größeren Textsammlung (also alle Klassen) an. Dies ermöglicht es uns, Wörter zu identifizieren, die charakteristisch für eine bestimmte Klasse sind.\nFür die Klassifizierung von hate speech sind vor allem Beleidigungen wichtig, während other scheinbar neutrale Wörter enthält.\n\n\nShow the code\ntf_idf %&gt;%\n  arrange(desc(tf_idf)) %&gt;%\n  mutate(word = factor(word, levels = rev(unique(word)))) %&gt;%\n  group_by(classc) %&gt;%\n  top_n(20, tf_idf) %&gt;%\n  ungroup() %&gt;%  \n  ggplot(aes(word, tf_idf, fill = classc)) +\n  geom_col() +\n  labs(x = NULL, y = \"tf-idf\") +\n  theme(legend.position = \"none\") +\n  facet_wrap(~ classc, ncol = 3, scales = \"free\") +\n  coord_flip() +\n  labs(y = \"TF-IDF values\") +\n  scale_fill_manual(values = colorsn)\n\n\n\n\n\nHier sind nochmal die Wörter mit den höchsten TF-IDF-Werten nach Klasse aufgelistet. Auch hier ist gut zu erkennen, dass bei hate speech vor allem rassistische, diskriminierende und sexistische Beleidigungen verwendet werden, während bei other scheinbar wahllos Wörter auftauchen.\n\n\n\n\n\nShow the code\ntweets4 &lt;- hate2 %&gt;% dplyr::select(classc, textclean) %&gt;% unnest_tokens(bigram, textclean, token = \"ngrams\", n = 2)\n\nbi_sep &lt;- tweets4 %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), sep = \" \")\n\nbi_filt &lt;- bi_sep %&gt;%\n  filter(!word1 %in% stop_words$word) %&gt;%\n  filter(!word2 %in% stop_words$word)\n\n# for later\nbigram_counts &lt;- bi_filt %&gt;%\n  count(word1, word2, sort = TRUE)\n\ntweets4 &lt;- bi_filt %&gt;%\n  unite(bigram, word1, word2, sep = \" \")\n\nt2_tf_idf &lt;- tweets4 %&gt;%\n  count(classc, bigram) %&gt;%\n  bind_tf_idf(bigram, classc, n) %&gt;%\n  arrange(desc(tf_idf))\n\nt2_tf_idf %&gt;%\n  arrange(desc(tf_idf)) %&gt;%\n  mutate(bigram = factor(bigram, levels = rev(unique(bigram)))) %&gt;%\n  group_by(classc) %&gt;%\n  top_n(10, tf_idf) %&gt;%\n  ungroup() %&gt;%  \n  ggplot(aes(bigram, tf_idf, fill = classc)) +\n  geom_col() +\n  labs(x = NULL, y = \"TF-IDF values\") +\n  theme(legend.position = \"none\") +\n  facet_wrap(~ classc, ncol = 3, scales = \"free\") +\n  coord_flip() +\n  theme_minimal() +\n  scale_fill_manual(values = colorsn)\n\n\n\n\n\nAuch bei den TF-IDF-Werte für die Bigramme ist eindeutig zu essen, wie relevant Beleidigungen zur Erkennung von hate speech sind. Oftmals wurden hier einfach nur Beleidigungen kombiniert, während bei other entweder über Personen oder auch assiatische Massagen geredet wird.\n\n\n\n\n\nShow the code\nbigram_graph &lt;- bigram_counts %&gt;%\n  filter(n &gt; 6) %&gt;%\n  graph_from_data_frame()\n\n\nWarning in graph_from_data_frame(.): In `d' `NA' elements were replaced with\nstring \"NA\"\n\n\nShow the code\nset.seed(1234)\n\na &lt;- grid::arrow(type = \"closed\", length = unit(.1, \"inches\"))\n\nggraph(bigram_graph, layout = \"fr\") +\n  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,\n                 arrow = a, end_cap = circle(.07, 'inches')) +\n  geom_node_point(color = \"#94D0C0FF\", size = 3) +\n  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +\n  theme_void()\n\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\ni Please use `linewidth` in the `default_aes` field and elsewhere instead.\n\n\n\n\n\nDieses Netz ist ein sehr gutes Beispiel um zu zeigen, wie manche scheinbar harmlose Wörter in Verbindungen mit anderen eine negative Bedeutung annehmen können. Bestes Beispiel ist hier trash: redet man über trash cans, dann mag es vielleicht nur um die Müllentsorgung gehen, während trash in Verbindung mit black eine starke Beleidigung gegenüber einer Bevölkerungsgruppe ist.\n\n\n\n\n\nShow the code\nbi_sep &lt;- hate2 %&gt;%\n  dplyr::select(classc, textclean) %&gt;%\n  unnest_tokens(bigram, textclean, token = \"ngrams\", n = 2) %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), sep = \" \")\n\np1 &lt;- bi_sep %&gt;%\n  filter(word1 == \"not\") %&gt;%\n  inner_join(get_sentiments(\"bing\"), by = c(word2 = \"word\")) %&gt;%\n  count(word1, word2, sentiment, sort = TRUE) %&gt;%\n  ungroup() %&gt;%\n  arrange(desc(abs(n))) %&gt;%\n  head(15) %&gt;%\n  mutate(n = if_else(sentiment == \"positive\", n, -n)) %&gt;% \n  mutate(word2 = reorder(word2, n)) %&gt;%\n  ggplot(aes(word2, n, fill = sentiment)) +\n  geom_col(show.legend = TRUE) +\n  xlab(\"\") +\n  ylab(\"Number of occurrences\") +\n  coord_flip() +\n  theme(plot.title = element_text(size=11)) +\n  ggtitle(\"Alle Klassen - Wörter, bei denen 'not' davorsteht\") +\n  scale_fill_manual(values = c(\"#E04F6C\", \"#5E8A67FF\")) +\n  theme_minimal()\nprint(p1)\n\n\n\n\n\nAnscheinend gibt es mehr negative Wörter, die mit einem ‘not’ verneint wurden. Interessanterweise wird das Wort funny auch als negativ gewertet, was nicht wirklich Sinn macht. Im Zusammenhang mit ‘not’ ist es natürlich sinnvoll, es als negativ einzuordnen.\n\n\nShow the code\np2 &lt;- bi_sep %&gt;%\n  filter(classc == \"other\") %&gt;%\n  filter(word1 == \"not\") %&gt;%\n  inner_join(get_sentiments(\"bing\"), by = c(word2 = \"word\")) %&gt;%\n  count(word1, word2, sentiment, sort = TRUE) %&gt;%\n  ungroup() %&gt;%\n  arrange(desc(abs(n))) %&gt;%\n  head(15) %&gt;%\n  mutate(n = if_else(sentiment == \"positive\", n, -n)) %&gt;% \n  mutate(word2 = reorder(word2, n)) %&gt;%\n  ggplot(aes(word2, n, fill = sentiment)) +\n  geom_col(show.legend = TRUE) +\n  xlab(\"\") +\n  ylab(\"Sentiment score * number of occurrences\") +\n  coord_flip() +\n  theme(plot.title = element_text(size=11)) +\n  ggtitle(\"other - Wörter, bei denen 'not' davorsteht\")  +\n  scale_fill_manual(values = c(\"#E04F6C\", \"#5E8A67FF\")) +\n  theme_minimal()\nprint(p2)\n\n\n\n\n\nAuch in der Klasse other gibt es mehr negative als positive Wörter. Dies war uns ja schon vorher aus der Sentimentanalyse bewusst, deswegen ist es hier nocheinmal interessant zu sehen, dass die negative Bedeutung dieser Wörter durch das ‘not’ aufgehoben wird. Zudem taucht auch hier das Wort trash auf.\n\n\nShow the code\np3 &lt;- bi_sep %&gt;%\n  filter(classc == \"hate speech\") %&gt;%\n  filter(word1 == \"not\") %&gt;%\n  inner_join(get_sentiments(\"bing\"), by = c(word2 = \"word\")) %&gt;%\n  count(word1, word2, sentiment, sort = TRUE) %&gt;%\n  ungroup() %&gt;%\n  arrange(desc(abs(n))) %&gt;%\n  head(15) %&gt;%\n  mutate(n = if_else(sentiment == \"positive\", n, -n)) %&gt;% \n  mutate(word2 = reorder(word2, n)) %&gt;%\n  ggplot(aes(word2, n, fill = sentiment)) +\n  geom_col(show.legend = TRUE) +\n  xlab(\"\") +\n  ylab(\"Sentiment score * number of occurrences\") +\n  coord_flip() +\n  theme(plot.title = element_text(size=11)) +\n  ggtitle(\"hate speech - Wörter, bei denen 'not' davorsteht\")  +\n  scale_fill_manual(values = c(\"#E04F6C\", \"#5E8A67FF\")) +\n  theme_minimal()\n\nprint(p3)\n\n\n\n\n\nFür die Klasse hate speech gibt es auch mehr negative als positive Wörter. Dies war uns ebenfalls schon vorher aus der Sentimentanalyse bewusst, deswegen ist es hier nocheinmal interessant zu sehen, dass die negative Bedeutung dieser Wörter durch das ‘not’ aufgehoben wird. Was hier aber auffällt, vor allem im Vergleich zur anderen Klasse, ist dass hier viele negativen Wörter gar nicht so schlimm sind, also z.B. afraid oder bitter. In der anderen Klasse gab es dagegen die Wörter kill, jealous und cripple. Also wurden dort schlimmere Wörter durch ein ‘not’ aufgehoben, während bei hate speech nur meiner Meinung nach schwach negative Begriffe negiert werden.\n\n\n\n\nfreq &lt;-tweets %&gt;%\n  count(id, word)\n\nt1_tm &lt;- cast_dtm(freq, id, word, n)\nt1_tm\n\n&lt;&lt;DocumentTermMatrix (documents: 5592, terms: 12768)&gt;&gt;\nNon-/sparse entries: 39386/71359270\nSparsity           : 100%\nMaximal term length: 81\nWeighting          : term frequency (tf)\n\nt1_lda &lt;- LDA(t1_tm, k = 15, control = list(seed = 1234))\n\nt1_topics &lt;- tidy(t1_lda, matrix = \"beta\")\n\nt1_topics %&gt;%\n  group_by(topic) %&gt;%\n  top_n(5, beta) %&gt;%\n  ungroup() %&gt;%\n  arrange(topic, -beta) %&gt;%\n  mutate(term = reorder(term, beta)) %&gt;%\n  ggplot(aes(term, beta, fill = factor(topic))) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ topic, scales = \"free\", ncol = 5)  +\n  coord_flip() +\n  scale_fill_manual(values = colorsn) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\nDie Themenfelder lassen sich hier in Beleidigungen und zufällige Themen einteilen. Gerade unter den Beleidigungen gibt es nochmal Abstufungen zwischen “allgemeinen” Beleidigungen und rassistischen. Bei den allgemeinen Themen geht es unter anderem um die yankees, positive Gefühle und Vögel. So wirklich etwas aussagen tut aber keiner dieser Themenfelder, dafür sind sie sich gerade bei den Beleidigungen einfach viel zu ähnlich."
  },
  {
    "objectID": "posts/Data Science 2/DS2.html#tidymodels",
    "href": "posts/Data Science 2/DS2.html#tidymodels",
    "title": "Hate Speech Klassifikation",
    "section": "",
    "text": "Verschiedene Rezepte mit unterschiedlicher Vorverarbeitung, um am Ende das beste zu finden.\n\n# Rezept 1\nrec1 &lt;-\n  recipe(class ~ ., data = train) |&gt; \n  update_role(id, new_role = \"id\")  |&gt; \n  update_role(tweet, new_role = \"ignore\") |&gt; \n  step_text_normalization(tweet) |&gt; \n  step_mutate(n_schimpf = get_sentiment(tweet,  \n                                    method = \"custom\",\n                                    lexicon = Insults)) |&gt; \n  step_mutate(n_emo = get_sentiment(tweet, \n                                    method = \"nrc\",\n                                    language = \"english\"))  |&gt;\n  step_tokenize(tweet) %&gt;%\n  step_stopwords(tweet, language = \"en\", stopword_source = \"snowball\", keep = FALSE) |&gt; \n  step_tokenfilter(tweet, max_tokens = 1e2)\n\ntidy(rec1)\n\n\n\n  \n\n\nd_baked1 &lt;- prep(rec1) |&gt; bake(new_data = NULL)\nsum(is.na(d_baked1))\n\n[1] 0\n\n# Rezept 2\nrec2 &lt;-\n  recipe(class ~ ., data = train) |&gt; \n  update_role(id, new_role = \"id\")  |&gt; \n  update_role(tweet, new_role = \"ignore\") |&gt; \n  step_text_normalization(tweet) |&gt; \n  step_mutate(n_schimpf = get_sentiment(tweet,  # aus `syuzhet`\n                                    method = \"custom\",\n                                    lexicon = Insults)) |&gt; \n  step_mutate(n_emo = get_sentiment(tweet,  # aus `syuzhet`\n                                    method = \"nrc\",\n                                    language = \"englisch\"))  |&gt; \n  step_tokenize(tweet) %&gt;%\n  step_stopwords(tweet, language = \"en\", stopword_source = \"snowball\", keep = FALSE) |&gt; \n  step_tokenfilter(tweet, max_tokens = 1e3) |&gt; \n  step_tfidf(tweet) \n\ntidy(rec2)\n\n\n\n  \n\n\nd_baked2 &lt;- prep(rec2) |&gt; bake(new_data = NULL)\nsum(is.na(d_baked2))\n\n[1] 0\n\n\n\n\n\n\nset.seed(42)\ncv_scheme &lt;- vfold_cv(train,\n  v = 5, \n  repeats = 2,\n  strata = class)\n\n\n\n\n\n# Baum\nmod_tree &lt;-\n  decision_tree(cost_complexity = tune(),\n  tree_depth = tune(),\n  mode = \"classification\")\n\n# Random Forest\nmod_rf &lt;-\n  rand_forest(mtry = tune(),\n  min_n = tune(),\n  trees = 1000,\n  mode = \"classification\") %&gt;% \n  set_engine(\"ranger\", num.threads = 4)\n\n# XGBoost\n\nmod_boost &lt;- boost_tree(\n  mode = \"classification\",\n  engine = \"xgboost\",\n  mtry = tune(),\n  trees = tune(),\n  min_n = tune()\n)\n\n\n# logistische Regression\nmod_logreg &lt;- logistic_reg(\n              mode = \"classification\",\n              engine = \"glm\",\n              penalty = 1)\n\n\n\n\nDie Zahlenbenennung der Workflows ist immer die Kombination aus welchem Modell (1-4) und welches Rezept (1-2) Ich habe mich gezielt gegen Workflowsets entschieden, da die Rechenzeit für meinen Computer dafür immer sehr lange dauert.\n\n# Rezept 1 mit decision tree\nworkflow11 &lt;-\n  workflow() |&gt; \n  add_model(mod_tree) |&gt; \n  add_recipe(rec1)\n\n# Rezept 2 mit decision tree\nworkflow12 &lt;-\n  workflow() |&gt; \n  add_model(mod_tree) |&gt; \n  add_recipe(rec2)\n\n# Rezept 1 mit random forest\nworkflow21 &lt;-\n  workflow() |&gt; \n  add_model(mod_rf) |&gt; \n  add_recipe(rec1)\n\n# Rezept 2 mit random forest (dauert viel zu lange)\n# workflow22 &lt;-\n  #workflow() |&gt; \n  #add_model(mod_rf) |&gt; \n  #add_recipe(rec2)\n\n# Rezept 1 mit xgboost\nworkflow31 &lt;-\n  workflow() |&gt; \n  add_model(mod_boost) |&gt; \n  add_recipe(rec1)\n\n# Rezept 2 mit xgboost (dauert viel zu lange)\n#workflow32 &lt;-\n  #workflow() |&gt; \n  #add_model(mod_boost) |&gt; \n  #add_recipe(rec2)\n\n# Rezept 1 mit logistischer Regression\nworkflow41 &lt;-\n  workflow() |&gt; \n  add_model(mod_logreg) |&gt; \n  add_recipe(rec1)\n\n# Rezept 2 mit logistischer Regression (Modell läuft leider nicht)\n#workflow42 &lt;-\n  #workflow() |&gt; \n  #add_model(mod_logreg) |&gt; \n  #add_recipe(rec2)\n\n\n\n\nBestes Workflowset\n\n# tune11\nset.seed(42)\ntic()\ntune11 &lt;-\n  tune_grid(object = workflow11,\n            resamples = cv_scheme,\n            grid = 10,\n            control = control_grid(save_workflow = TRUE))\ntoc()\n\n493.11 sec elapsed\n\n# tune12\nset.seed(42)\ntic()\ntune12 &lt;-\n  tune_grid(object = workflow12,\n            resamples = cv_scheme,\n            grid = 10,\n            control = control_grid(save_workflow = TRUE))\ntoc()\n\n971.25 sec elapsed\n\n# tune21\nset.seed(42)\ntic()\ntune21 &lt;-\n  tune_grid(object = workflow21,\n            resamples = cv_scheme,\n            grid = 10,\n            control = control_grid(save_workflow = TRUE))\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\ntoc()\n\n456.7 sec elapsed\n\n#tune31\nset.seed(42)\ntic()\ntune31 &lt;-\n  tune_grid(object = workflow31,\n            resamples = cv_scheme,\n            grid = 10,\n            control = control_grid(save_workflow = TRUE))\n\ni Creating pre-processing data to finalize unknown parameter: mtry\n\ntoc()\n\n569.36 sec elapsed\n\n#tune41\nset.seed(42)\ntic()\ntune41 &lt;-\n  tune_grid(object = workflow41,\n            resamples = cv_scheme,\n            grid = 10,\n            control = control_grid(save_workflow = TRUE))\n\nWarning: No tuning parameters have been detected, performance will be evaluated\nusing the resamples with no tuning. Did you want to [tune()] parameters?\n\ntoc()\n\n133.95 sec elapsed\n\n\n\n\n\n\n# mit Rezept 6\ntune11 |&gt; collect_metrics()\n\n\n\n  \n\n\nautoplot(tune11)\n\n\n\ntune12 |&gt; collect_metrics()\n\n\n\n  \n\n\nautoplot(tune12)\n\n\n\ntune21 |&gt; collect_metrics()\n\n\n\n  \n\n\nautoplot(tune21)\n\n\n\ntune31 |&gt; collect_metrics()\n\n\n\n  \n\n\nautoplot(tune31)\n\n\n\ntune41 |&gt; collect_metrics()\n\n\n\n  \n\n\n\n\n\n\n\nbest_model31 &lt;-\n  fit_best(tune31)\n\n\nfinal_preds31 &lt;- \n  best_model31 %&gt;% \n  predict(new_data = test) %&gt;% \n  bind_cols(test)\n\n\n\n\nAnhand dem eigenen train-sample wird die roc-auc Kurve dargestellt.\n\ntest2 &lt;- final_preds31 |&gt; \n  mutate(class = as.numeric(class))\nfinal_preds31 &lt;- final_preds31 |&gt; \n  mutate(pred = as.numeric(.pred_class))\nrocobj &lt;- roc(test2$class, final_preds31$pred)\n\nSetting levels: control = 1, case = 2\n\n\nSetting direction: controls &lt; cases\n\n#define object to plot and calculate AUC\nrocobj &lt;- roc(test2$class, final_preds31$pred)\n\nSetting levels: control = 1, case = 2\nSetting direction: controls &lt; cases\n\nauc &lt;- round(auc(test2$class, final_preds31$pred),4)\n\nSetting levels: control = 1, case = 2\nSetting direction: controls &lt; cases\n\n#create ROC plot\nggroc(rocobj, colour = 'cyan', size = 1) +\n  ggtitle(paste0('ROC Curve ', '(AUC = ', auc, ')')) +\n  theme_minimal()\n\n\n\n\nDas Modell ist in der Lage, die positiven Fälle von den negativen Fällen mit einer Wahrscheinlichkeit von ca. 59 % zu unterscheiden. Es kann also nur etwas besser als der Zufall entscheiden.\nEs ist wichtig zu beachten, dass der ROC AUC-Wert nur ein Maß für die Fähigkeit eines Modells ist, die positiven Fälle von den negativen Fällen zu unterscheiden. Er sagt nichts darüber aus, wie gut das Modell die tatsächlichen Werte der positiven Fälle vorhersagt.\n\n\n\n\n\nShow the code\nfinal_preds312 &lt;-\n  final_preds31 |&gt; \n  bind_cols(test)\n\n\nNew names:\n* `id` -&gt; `id...2`\n* `tweet` -&gt; `tweet...3`\n* `class` -&gt; `class...4`\n* `id` -&gt; `id...6`\n* `tweet` -&gt; `tweet...7`\n* `class` -&gt; `class...8`\n\n\nShow the code\nconfusion_matrix &lt;- confusionMatrix(final_preds31$class, final_preds31$.pred_class)\nprint(confusion_matrix)\n\n\nConfusion Matrix and Statistics\n\n             Reference\nPrediction    hate speech other\n  hate speech          52   234\n  other                14   819\n                                          \n               Accuracy : 0.7784          \n                 95% CI : (0.7529, 0.8024)\n    No Information Rate : 0.941           \n    P-Value [Acc &gt; NIR] : 1               \n                                          \n                  Kappa : 0.2208          \n                                          \n Mcnemar's Test P-Value : &lt;2e-16          \n                                          \n            Sensitivity : 0.78788         \n            Specificity : 0.77778         \n         Pos Pred Value : 0.18182         \n         Neg Pred Value : 0.98319         \n             Prevalence : 0.05898         \n         Detection Rate : 0.04647         \n   Detection Prevalence : 0.25559         \n      Balanced Accuracy : 0.78283         \n                                          \n       'Positive' Class : hate speech     \n                                          \n\n\nShow the code\nsensitivity1 &lt;- confusion_matrix[[\"byClass\"]][[\"Sensitivity\"]]\nsensitivityp1 &lt;- round(sensitivity1*100, digits = 2)\nspecificity1 &lt;- confusion_matrix[[\"byClass\"]][[\"Specificity\"]]\nspecificityp1 &lt;- round(specificity1*100, digits = 2)\naccuracy1 &lt;- confusion_matrix[[\"overall\"]][[\"Accuracy\"]]\naccuracyp1 &lt;- round(accuracy1*100, digits = 2)\n\n\n\n\nShow the code\nglue('Die Accuracy gibt an, wie viele der insgesamt vorhergesagten Klassen mit den tatsächlichen Klassen übereinstimmen, gemessen als Anteil der korrekt klassifizierten Instanzen an der Gesamtzahl der Instanzen im Datensatz. Bei diesem Modell liegt die Accuracy bei {accuracy1}, d.h. es wurden {accuracyp1} % der Fälle richtig klassifiziert.\n\nDie Sensitivität ist ein Maß dafür, wie gut das Modell positive Fälle (hate speech) erkennt. In diesem Fall ist die Sensitivität von {sensitivity1} gut. Das Modell erkennt {sensitivityp1} % der positiven Fälle korrekt.\n\nDie Spezifität ist ein Maß dafür, wie gut das Modell negative Fälle (other) erkennt. In diesem Fall ist die Spezifität von {specificity1} auch gut. Das Modell erkennt {specificityp1} % der negativen Fälle korrekt.')\n\n\nDie Accuracy gibt an, wie viele der insgesamt vorhergesagten Klassen mit den tatsächlichen Klassen übereinstimmen, gemessen als Anteil der korrekt klassifizierten Instanzen an der Gesamtzahl der Instanzen im Datensatz. Bei diesem Modell liegt die Accuracy bei 0.778373547810545, d.h. es wurden 77.84 % der Fälle richtig klassifiziert.\n\nDie Sensitivität ist ein Maß dafür, wie gut das Modell positive Fälle (hate speech) erkennt. In diesem Fall ist die Sensitivität von 0.787878787878788 gut. Das Modell erkennt 78.79 % der positiven Fälle korrekt.\n\nDie Spezifität ist ein Maß dafür, wie gut das Modell negative Fälle (other) erkennt. In diesem Fall ist die Spezifität von 0.777777777777778 auch gut. Das Modell erkennt 77.78 % der negativen Fälle korrekt."
  },
  {
    "objectID": "posts/Data Science 2/DS2.html#hugging-face-modell",
    "href": "posts/Data Science 2/DS2.html#hugging-face-modell",
    "title": "Hate Speech Klassifikation",
    "section": "",
    "text": "library(reticulate)\n\nuse_virtualenv(\"~/Blog/Blogecmb/ds2venv\")\n\n\n\n\n\nimport tensorflow\n\nWARNING:tensorflow:From C:\\Users\\EMILIA~1\\OneDrive\\DOKUME~1\\Blog\\Blogecmb\\ds2venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n\nfrom transformers import pipeline\n\nclassifier = pipeline(\"text-classification\", model=\"facebook/roberta-hate-speech-dynabench-r4-target\")\n\n\n\n\n\ntweetsonly &lt;- test$tweet\n\n\ntweets = r.tweetsonly\n\nresult = classifier(tweets)\n\n\nresult &lt;- py$result\ntest3 &lt;- test\n\nlabels &lt;- map(result, \"label\")\n\n\nif (nrow(test3) == length(labels)) {\n  test3$hatespeech &lt;- unlist(labels)\n} else {\n  print(\"Error!\")\n}\n\ntest3 &lt;-\n  test3|&gt; \n  mutate(hatespeech = factor(hatespeech),\n         hatespeech = case_when(hatespeech == \"nothate\" ~ \"other\",\n                          hatespeech == \"hate\" ~ \"hate speech\"),\n         hatespeech = factor(hatespeech))\n\n\n\n\n\n\nShow the code\nmy_metrics2 &lt;- metric_set(accuracy, f_meas)\nmy_metrics2(test3,\n           truth = class,\n           estimate = hatespeech)\n\n\n\n\n  \n\n\n\n\n\nShow the code\nconfusion_matrix2 &lt;- confusionMatrix(test3$class, test3$hatespeech)\nprint(confusion_matrix2)\n\n\nConfusion Matrix and Statistics\n\n             Reference\nPrediction    hate speech other\n  hate speech         266    20\n  other                96   737\n                                         \n               Accuracy : 0.8963         \n                 95% CI : (0.877, 0.9136)\n    No Information Rate : 0.6765         \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16      \n                                         \n                  Kappa : 0.7494         \n                                         \n Mcnemar's Test P-Value : 3.317e-12      \n                                         \n            Sensitivity : 0.7348         \n            Specificity : 0.9736         \n         Pos Pred Value : 0.9301         \n         Neg Pred Value : 0.8848         \n             Prevalence : 0.3235         \n         Detection Rate : 0.2377         \n   Detection Prevalence : 0.2556         \n      Balanced Accuracy : 0.8542         \n                                         \n       'Positive' Class : hate speech    \n                                         \n\n\nShow the code\nsensitivity2 &lt;- confusion_matrix2[[\"byClass\"]][[\"Sensitivity\"]]\nsensitivityp2 &lt;- round(sensitivity2*100, digits = 2)\nspecificity2 &lt;- confusion_matrix2[[\"byClass\"]][[\"Specificity\"]]\nspecificityp2 &lt;- round(specificity2*100, digits = 2)\naccuracy2 &lt;- confusion_matrix2[[\"overall\"]][[\"Accuracy\"]]\naccuracyp2 &lt;- round(accuracy2*100, digits = 2)\n\n\n\n\nShow the code\nglue('Die Accuracy gibt an, wie viele der insgesamt vorhergesagten Klassen mit den tatsächlichen Klassen übereinstimmen, gemessen als Anteil der korrekt klassifizierten Instanzen an der Gesamtzahl der Instanzen im Datensatz. Bei diesem Modell liegt die Accuracy bei {accuracy2}, d.h. es wurden {accuracyp2} % der Fälle richtig klassifiziert.\n\nDie Sensitivität ist ein Maß dafür, wie gut das Modell positive Fälle (hate speech) erkennt. In diesem Fall ist die Sensitivität von {sensitivity2} gut. Das Modell erkennt {sensitivityp2} % der positiven Fälle korrekt.\n\nDie Spezifität ist ein Maß dafür, wie gut das Modell negative Fälle (other) erkennt. In diesem Fall ist die Spezifität von {specificity2} auch gut. Das Modell erkennt {specificityp2} % der negativen Fälle korrekt.')\n\n\nDie Accuracy gibt an, wie viele der insgesamt vorhergesagten Klassen mit den tatsächlichen Klassen übereinstimmen, gemessen als Anteil der korrekt klassifizierten Instanzen an der Gesamtzahl der Instanzen im Datensatz. Bei diesem Modell liegt die Accuracy bei 0.896336014298481, d.h. es wurden 89.63 % der Fälle richtig klassifiziert.\n\nDie Sensitivität ist ein Maß dafür, wie gut das Modell positive Fälle (hate speech) erkennt. In diesem Fall ist die Sensitivität von 0.734806629834254 gut. Das Modell erkennt 73.48 % der positiven Fälle korrekt.\n\nDie Spezifität ist ein Maß dafür, wie gut das Modell negative Fälle (other) erkennt. In diesem Fall ist die Spezifität von 0.973579920739762 auch gut. Das Modell erkennt 97.36 % der negativen Fälle korrekt."
  },
  {
    "objectID": "posts/Data Science 2/DS2.html#fazit",
    "href": "posts/Data Science 2/DS2.html#fazit",
    "title": "Hate Speech Klassifikation",
    "section": "",
    "text": "Im Vergleich schneidet das hugging face Modell deutlich besser ab als das tidymodels-Modell, was aber natürlich auch an meiner Vorverarbeitung liegen kann.\nDurch die EDA ist ganz klar die Relevanz von Schimpfwörtern zur Erkennung von hate speech hervorgestochen, weswegen es auch wichtig für das tidymodels Rezept war. Leider hat mit tidymodels nicht alles ganz so gut funktioniert, was oft auch an der sehr hohen Rechenzeit war, weswegen hier vielleicht nicht das volle Potenzial ausgeschöpft wurde.\nAlles in allem, konnte man durch die EDA sehr viele Rückschlüsse ziehen, wobei für mich vor allem das Bigram-Netz interessant war. Hier konnte man nämlich sehr gut erkennen, wie wichtig der Kontext für die Verwendung von bestimmten Wörtern ist, denn so kann die Bedeutung ganz schnell von einer neutralen Beschreibung zu einer Beleidigung wechseln."
  },
  {
    "objectID": "posts/Data Science 2/DS2.html#quellen",
    "href": "posts/Data Science 2/DS2.html#quellen",
    "title": "Hate Speech Klassifikation",
    "section": "",
    "text": "sessionInfo()\n\nR version 4.1.3 (2022-03-10)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   \n[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                   \n[5] LC_TIME=German_Germany.1252    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] reticulate_1.28           ranger_0.14.1            \n [3] rpart_4.1.16              stopwords_2.3            \n [5] stringi_1.7.6             glue_1.6.2               \n [7] topicmodels_0.2-14        readxl_1.3.1             \n [9] ggraph_2.1.0              igraph_1.4.2             \n[11] sentimentr_2.9.0          quanteda.textstats_0.96.1\n[13] beepr_1.3                 syuzhet_1.0.7            \n[15] tokenizers_0.3.0          remoji_0.1.0             \n[17] fastrtext_0.3.4           naivebayes_0.9.7         \n[19] lsa_0.73.3                SnowballC_0.7.0          \n[21] textrecipes_1.0.3         tidytext_0.4.1           \n[23] wordcloud_2.6             RColorBrewer_1.1-3       \n[25] tm_0.7-11                 NLP_0.2-1                \n[27] pROC_1.18.0               caret_6.0-94             \n[29] lattice_0.20-45           car_3.1-2                \n[31] carData_3.0-5             rstanarm_2.21.4          \n[33] Rcpp_1.0.8                klaR_1.7-3               \n[35] MASS_7.3-55               ggthemes_5.0.0           \n[37] discrim_1.0.1             rlang_1.1.2              \n[39] cowplot_1.1.2             xgboost_1.6.0.1          \n[41] tictoc_1.2                glmnet_4.1-7             \n[43] Matrix_1.5-4              see_0.8.1                \n[45] report_0.5.7              parameters_0.21.0        \n[47] performance_0.10.3        modelbased_0.8.6         \n[49] insight_0.19.2            effectsize_0.8.3         \n[51] datawizard_0.7.1          correlation_0.8.4        \n[53] bayestestR_0.13.1         easystats_0.6.0          \n[55] yardstick_1.1.0           workflowsets_1.0.1       \n[57] workflows_1.1.3           tune_1.1.2               \n[59] rsample_1.2.0             recipes_1.0.9            \n[61] parsnip_1.0.4             modeldata_1.2.0          \n[63] infer_1.0.5               dials_1.2.0              \n[65] scales_1.2.1              broom_1.0.5              \n[67] tidymodels_1.0.0          forcats_0.5.1            \n[69] stringr_1.5.0             dplyr_1.1.2              \n[71] purrr_1.0.1               readr_2.1.2              \n[73] tidyr_1.2.0               tibble_3.2.1             \n[75] ggplot2_3.4.4             tidyverse_1.3.1          \n\nloaded via a namespace (and not attached):\n  [1] ModelMetrics_1.2.2.2 visdat_0.6.0         bit64_4.0.5         \n  [4] knitr_1.37           dygraphs_1.1.1.6     data.table_1.14.8   \n  [7] inline_0.3.19        hardhat_1.3.0        generics_0.1.3      \n [10] GPfit_1.0-8          qdapRegex_0.7.8      combinat_0.0-8      \n [13] proxy_0.4-27         future_1.33.0        nsyllable_1.0.1     \n [16] bit_4.0.5            tzdb_0.3.0           xml2_1.3.3          \n [19] lubridate_1.8.0      httpuv_1.6.6         StanHeaders_2.21.0-7\n [22] assertthat_0.2.1     viridis_0.6.4        gower_1.0.1         \n [25] xfun_0.39            hms_1.1.3            bayesplot_1.10.0    \n [28] evaluate_0.23        promises_1.2.0.1     fansi_1.0.2         \n [31] dbplyr_2.3.2         DBI_1.1.3            htmlwidgets_1.6.2   \n [34] stats4_4.1.3         ellipsis_0.3.2       crosstalk_1.2.1     \n [37] backports_1.4.1      markdown_1.12        RcppParallel_5.1.7  \n [40] vctrs_0.6.1          here_1.0.1           abind_1.4-5         \n [43] withr_2.5.2          ggforce_0.4.1        vroom_1.6.1         \n [46] xts_0.13.1           crayon_1.5.2         labeling_0.4.3      \n [49] pkgconfig_2.0.3      slam_0.1-50          tweenr_2.0.2        \n [52] nlme_3.1-155         nnet_7.3-17          globals_0.16.2      \n [55] questionr_0.7.8      lifecycle_1.0.4      miniUI_0.1.1.1      \n [58] colourpicker_1.3.0   lexicon_1.2.1        modelr_0.1.11       \n [61] rprojroot_2.0.4      cellranger_1.1.0     polyclip_1.10-4     \n [64] matrixStats_0.63.0   loo_2.6.0            boot_1.3-28         \n [67] zoo_1.8-12           reprex_2.0.2         base64enc_0.1-3     \n [70] png_0.1-8            viridisLite_0.4.2    shape_1.4.6         \n [73] parallelly_1.36.0    shinystan_2.6.0      magrittr_2.0.2      \n [76] plyr_1.8.8           audio_0.1-10         threejs_0.3.3       \n [79] compiler_4.1.3       rstantools_2.3.1.1   lme4_1.1-32         \n [82] cli_3.6.0            DiceDesign_1.9       listenv_0.9.0       \n [85] janeaustenr_1.0.0    tidyselect_1.2.0     highr_0.10          \n [88] yaml_2.3.5           ggrepel_0.9.3        grid_4.1.3          \n [91] fastmatch_1.1-3      tools_4.1.3          future.apply_1.11.0 \n [94] parallel_4.1.3       rstudioapi_0.15.0    foreach_1.5.2       \n [97] quanteda_3.3.0       gridExtra_2.3        prodlim_2023.03.31  \n[100] farver_2.1.1         digest_0.6.29        shiny_1.7.2         \n[103] lava_1.7.3           later_1.3.0          httr_1.4.7          \n[106] colorspace_2.0-3     rvest_1.0.3          fs_1.5.2            \n[109] splines_4.1.3        graphlayouts_0.8.4   shinythemes_1.2.0   \n[112] xtable_1.8-4         jsonlite_1.8.4       nloptr_2.0.3        \n[115] tidygraph_1.2.3      timeDate_4032.109    rstan_2.21.7        \n[118] modeltools_0.2-23    ipred_0.9-14         R6_2.5.1            \n[121] lhs_1.1.6            pillar_1.9.0         htmltools_0.5.5     \n[124] mime_0.12            fastmap_1.1.0        minqa_1.2.5         \n[127] DT_0.31              class_7.3-20         codetools_0.2-18    \n[130] pkgbuild_1.4.3       furrr_0.3.1          utf8_1.2.2          \n[133] gtools_3.9.4         shinyjs_2.1.0        survival_3.2-13     \n[136] textclean_0.9.3      rmarkdown_2.25       munsell_0.5.0       \n[139] e1071_1.7-13         iterators_1.0.14     labelled_2.12.0     \n[142] haven_2.4.3          reshape2_1.4.4       gtable_0.3.4"
  },
  {
    "objectID": "posts/Miniprojekt/Miniprojekt_tidymodels_EmiliaBraun.html",
    "href": "posts/Miniprojekt/Miniprojekt_tidymodels_EmiliaBraun.html",
    "title": "Klassifikation von Hate Speech",
    "section": "",
    "text": "Textanalyse zur Klassifikation von Hatespeech\nlibrary(tidyverse)\nlibrary(easystats)\nlibrary(tidymodels)\nlibrary(tidytext)  \nlibrary(textrecipes)  \nlibrary(lsa)  \nlibrary(discrim)  \nlibrary(naivebayes)\nlibrary(tictoc)  \nlibrary(fastrtext)  \nlibrary(remoji)  \nlibrary(tokenizers)  \nlibrary(syuzhet)\nlibrary(pradadata)\nlibrary(beepr)\nlibrary(quanteda.textstats)\nlibrary(ggthemes)"
  },
  {
    "objectID": "posts/Miniprojekt/Miniprojekt_tidymodels_EmiliaBraun.html#textlänge-in-abhängigkeit-von-c2-kategorie",
    "href": "posts/Miniprojekt/Miniprojekt_tidymodels_EmiliaBraun.html#textlänge-in-abhängigkeit-von-c2-kategorie",
    "title": "Klassifikation von Hate Speech",
    "section": "Textlänge in Abhängigkeit von c2 Kategorie",
    "text": "Textlänge in Abhängigkeit von c2 Kategorie\n\n\nShow the code\ntrain1 &lt;-\n  germeval_train |&gt; \n  mutate(text_length = str_length(text))\n\nggplot(train1, aes(x = c1, y = text_length, color = c2)) +\n  geom_point() +\n  labs(title = \"Germeval 2018 Datensatz Visualisierung\",\n       x = \"c1\",\n       y = \"Textlänge\",\n       color = \"c2\") +\n  scale_color_tableau(\"Nuriel Stone\")"
  },
  {
    "objectID": "posts/Miniprojekt/Miniprojekt_tidymodels_EmiliaBraun.html#histogramm-der-textlänge",
    "href": "posts/Miniprojekt/Miniprojekt_tidymodels_EmiliaBraun.html#histogramm-der-textlänge",
    "title": "Klassifikation von Hate Speech",
    "section": "Histogramm der Textlänge",
    "text": "Histogramm der Textlänge\n\n\nShow the code\nggplot(train1, aes(x = text_length)) +\n  geom_histogram(binwidth = 5, fill = \"#94d0c0\", color = \"white\") +\n  labs(title = \"Histogramm der Textlängen\", x = \"Textlänge\", y = \"Häufigkeit\")"
  },
  {
    "objectID": "posts/Miniprojekt/Miniprojekt_tidymodels_EmiliaBraun.html#boxplot-für-verschiedene-kateforien",
    "href": "posts/Miniprojekt/Miniprojekt_tidymodels_EmiliaBraun.html#boxplot-für-verschiedene-kateforien",
    "title": "Klassifikation von Hate Speech",
    "section": "Boxplot für verschiedene Kateforien",
    "text": "Boxplot für verschiedene Kateforien\n\n\nShow the code\nggplot(train1, aes(x = c1, y = text_length, fill = c2)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot der Textlängen nach c1\", x = \"c1\", y = \"Textlänge\", fill = \"c2\")+\n  scale_fill_tableau(\"Nuriel Stone\")"
  },
  {
    "objectID": "posts/Miniprojekt/Miniprojekt_tidymodels_EmiliaBraun.html#model-folds",
    "href": "posts/Miniprojekt/Miniprojekt_tidymodels_EmiliaBraun.html#model-folds",
    "title": "Klassifikation von Hate Speech",
    "section": "Model & Folds",
    "text": "Model & Folds\n\n# model:\nmod1 &lt;-\n  rand_forest(mode = \"classification\")\n\n\n# cv:\nset.seed(42)\nrsmpl &lt;- vfold_cv(germeval_train, v = 5)"
  },
  {
    "objectID": "posts/Miniprojekt/Miniprojekt_tidymodels_EmiliaBraun.html#recipe",
    "href": "posts/Miniprojekt/Miniprojekt_tidymodels_EmiliaBraun.html#recipe",
    "title": "Klassifikation von Hate Speech",
    "section": "recipe:",
    "text": "recipe:\n\nrec 1\n\nd_train &lt;-\n  germeval_train |&gt; \n  select(id, c1, text)\n\n\nrec1 &lt;-\n  recipe(c1 ~ ., data = d_train) |&gt; \n  update_role(id, new_role = \"id\")  |&gt; \n  update_role(text, new_role = \"ignore\") |&gt; \n  step_mutate(n_schimpf = get_sentiment(text,  # aus `syuzhet`\n                                    method = \"custom\",\n                                    lexicon = schimpfwoerter)) |&gt; \n  step_mutate(n_emo = get_sentiment(text,  # aus `syuzhet`\n                                    method = \"custom\",\n                                    lexicon = sentiws))  |&gt;\n  step_tokenize(text) %&gt;%\n  step_stopwords(text, keep = FALSE) \n\nrec1_prepped &lt;- prep(rec1)\n\nd_rec1 &lt;- bake(rec1_prepped, new_data = NULL)\n\nhead(d_rec1)\n\n\n\n  \n\n\n\n\n\nrec2\n\nrec2 &lt;-\n  recipe(c1 ~ ., data = d_train) |&gt; \n  update_role(id, new_role = \"id\")  |&gt; \n  update_role(text, new_role = \"ignore\") |&gt; \n  step_mutate(n_schimpf = get_sentiment(text,  # aus `syuzhet`\n                                    method = \"custom\",\n                                    lexicon = schimpfwoerter)) |&gt; \n  step_mutate(n_emo = get_sentiment(text,  # aus `syuzhet`\n                                    method = \"custom\",\n                                    lexicon = sentiws))  |&gt; \n  step_tokenize(text) %&gt;%\n  step_stopwords(text, keep = FALSE) |&gt; \n  step_tokenfilter(text, max_tokens = 1e3) |&gt; \n  step_tfidf(text) \n\n\n\nrec2_prepped &lt;- prep(rec2)\n\nd_rec2 &lt;- bake(rec2_prepped, new_data = NULL)\n\nhead(d_rec2)"
  },
  {
    "objectID": "posts/Miniprojekt/Miniprojekt_tidymodels_EmiliaBraun.html#workflow",
    "href": "posts/Miniprojekt/Miniprojekt_tidymodels_EmiliaBraun.html#workflow",
    "title": "Klassifikation von Hate Speech",
    "section": "workflow:",
    "text": "workflow:\n\nwf1\n\nwf1 &lt;-\n  workflow() %&gt;% \n  add_model(mod1) %&gt;% \n  add_recipe(rec1)\n\n\n\nwf2\n\nwf2 &lt;-\n  workflow() %&gt;% \n  add_model(mod1) %&gt;% \n  add_recipe(rec2)"
  },
  {
    "objectID": "posts/Miniprojekt/Miniprojekt_tidymodels_EmiliaBraun.html#fit1",
    "href": "posts/Miniprojekt/Miniprojekt_tidymodels_EmiliaBraun.html#fit1",
    "title": "Klassifikation von Hate Speech",
    "section": "Fit1",
    "text": "Fit1\n\ntic()\nfit1 &lt;-\n  fit(wf1,\n      data = germeval_train)\ntoc()\n\n35.39 sec elapsed\n\nbeep(3)"
  },
  {
    "objectID": "posts/Miniprojekt/Miniprojekt_tidymodels_EmiliaBraun.html#fit-2",
    "href": "posts/Miniprojekt/Miniprojekt_tidymodels_EmiliaBraun.html#fit-2",
    "title": "Klassifikation von Hate Speech",
    "section": "Fit 2",
    "text": "Fit 2\n\ntic()\nfit2 &lt;-\n  fit(wf2,\n      data = germeval_train)\ntoc()\n\n111.2 sec elapsed\n\nbeep(3)"
  },
  {
    "objectID": "posts/Miniprojekt/Miniprojekt_tidymodels_EmiliaBraun.html#pred1",
    "href": "posts/Miniprojekt/Miniprojekt_tidymodels_EmiliaBraun.html#pred1",
    "title": "Klassifikation von Hate Speech",
    "section": "pred1",
    "text": "pred1\n\ntic()\npreds &lt;-\n  predict(fit1, new_data = germeval_test)\ntoc()\n\n22.39 sec elapsed"
  },
  {
    "objectID": "posts/Miniprojekt/Miniprojekt_tidymodels_EmiliaBraun.html#pred2",
    "href": "posts/Miniprojekt/Miniprojekt_tidymodels_EmiliaBraun.html#pred2",
    "title": "Klassifikation von Hate Speech",
    "section": "pred2",
    "text": "pred2\n\ntic()\npreds2 &lt;-\n  predict(fit2, new_data = germeval_test)\ntoc()\n\n22.19 sec elapsed\n\n\n\nd_test &lt;-\n  germeval_test |&gt; \n  bind_cols(preds) |&gt; \n  mutate(c1 = as.factor(c1))\n\nd_test2 &lt;-\n  germeval_test |&gt; \n  bind_cols(preds2) |&gt; \n  mutate(c1 = as.factor(c1))\n\n\nmy_metrics &lt;- metric_set(accuracy, f_meas)\nmy_metrics(d_test,\n           truth = c1,\n           estimate = .pred_class)\n\n\n\n  \n\n\nmy_metrics &lt;- metric_set(accuracy, f_meas)\nmy_metrics(d_test2,\n           truth = c1,\n           estimate = .pred_class)"
  }
]
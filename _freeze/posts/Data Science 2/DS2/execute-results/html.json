{
  "hash": "6c6de8c0fc100c0319f0a5b6090f8462",
  "result": {
    "markdown": "---\ntitle: \"Hate Speech Klassifikation\"\nauthor: \"Emilia Braun\"\ndate: \"2024-02-09\"\nimage: \"hatespeech.jpeg\"\ncategories: [Textanalyse, Tidymodels, Klassifikation, Transformers, Neuronale Netze]\nformat:\n  html:\n    embed-resources: true\n---\n\n\n# Hate Speech Klassifikation\n\nVerschiedene Tweets sollen auf Hate Speech überprüft und klassifiziert werden\n\n## 1. Forschungsfrage\n\nDie Klassifizierung von Hate Speech in Tweets ist ein bedeutendes Thema im Bereich der digitalen Kommunikation und sozialen Medien. Angesichts der zunehmenden Verbreitung von Hassrede im Internet ist es von entscheidender Bedeutung, effektive Methoden zu entwickeln, um solche Inhalte zu erkennen und einzudämmen.\n\nWarum könnte eine Klassifikation von Hate Speech interessieren?\n\n------------------------------------------------------------------------\n\n-   Schutz der Nutzer: Die Identifizierung von Hate Speech ermöglicht es Plattformen und Behörden, Maßnahmen zum Schutz der Nutzer vor Belästigung, Diskriminierung und Gewalt zu ergreifen.\n-   Förderung der digitalen Sicherheit: Die Bekämpfung von Hassrede trägt zur Schaffung einer sichereren und respektvolleren Online-Umgebung bei, die die digitale Sicherheit und das Wohlbefinden fördert.\n-   Eindämmung von sozialen Konflikten: Durch die frühzeitige Erkennung und Entfernung von Hate Speech kann die Eskalation sozialer Konflikte verhindert und die Förderung eines harmonischen sozialen Zusammenlebens unterstützt werden.\n\n## 2. Vorbereitung\n\n### 2.1 Pakete laden\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(easystats)\nlibrary(glmnet)\nlibrary(tictoc)\nlibrary(xgboost)\nlibrary(cowplot)\nlibrary(rlang)\nlibrary(purrr)\nlibrary(discrim)\nlibrary(ggthemes)\nlibrary(klaR)\nlibrary(rstanarm)\nlibrary(car)\nlibrary(caret)\nlibrary(pROC)\nlibrary(tm)\nlibrary(wordcloud)\nlibrary(tidytext)  \nlibrary(textrecipes)  \nlibrary(lsa)  \nlibrary(naivebayes)\nlibrary(fastrtext)  \nlibrary(remoji)  \nlibrary(tokenizers)  \nlibrary(syuzhet)\nlibrary(beepr)\nlibrary(quanteda.textstats)\nlibrary(sentimentr)\nlibrary(igraph)\nlibrary(ggraph)\nlibrary(readxl)\nlibrary(topicmodels)\nlibrary(glue)\n```\n:::\n\n\n### 2.2 Daten laden\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd_hate <- read_csv(path_data)\n\nInsults <- read_excel(insult_path)\nnew_colnames <- \"word\"\ncolnames(Insults) <- new_colnames\nInsults$value <- 1\n\ndata(\"nrc_emotions\")\n\ncolorsn <- c(\"#8175AAFF\", \"#6FB899FF\", \"#5E8A67FF\", \"#E87A90FF\", \"#A39FC9FF\", \"#94D0C0FF\", \"#AA7584\", \"#90B58B\", \"#027B8EFF\",  \"#E04F6C\", \"#028E5B\", \"#7A4FE0\", \"#B8996F\", \"#8E027B\",  \"#B8756F\" )\n```\n:::\n\n\nDas Schimpfwörterlexikon stammt von der Seite https://www.insult.wiki/.\n\n### 2.3 Data Cleaning\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhate2 <- d_hate |> \n  mutate(textclean = tweet)\nhate2$textclean <-  gsub(\"https\\\\S*\", \"\", hate2$textclean)\nhate2$textclean <-  gsub(\"@\\\\S*\", \"\", hate2$textclean) \nhate2$textclean  <-  gsub(\"amp\", \"\", hate2$textclean) \nhate2$textclean  <-  gsub(\"[\\r\\n]\", \"\", hate2$textclean)\nhate2$textclean  <-  gsub(\"[[:punct:]]\", \"\", hate2$textclean)\nhate2$textclean <- gsub(\"(RT|via)((?:\\\\b\\\\w*@\\\\w+)+)\",\"\", hate2$textclean)\n\nhate2 <- hate2 %>%\n  mutate(classc = as.factor(class))\n```\n:::\n\n\n### 2.4 Aufteilung in Train & Testdaten:\n\nUm overfitting zu vermeiden werden die Daten vor dem Trainieren der Modelle noch in Train und Testdaten aufgeteilt.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\nd_hate2 <- d_hate |> \n  mutate(class = factor(class))\nd_split <- initial_split(d_hate2, prop = .8, strata = class)\ntrain <- training(d_split)\ntest <- testing(d_split)\n```\n:::\n\n\n## 3. Explorative Datenanalyse\n\nEin Großteil der explorativen Datenanalyse orientiert sich an der [Treemap House of Horror](https://www.kaggle.com/code/headsortails/treemap-house-of-horror-spooky-eda-lda-features/report#shocking-sentiments), welche wiederum auf dem [tidyverse](https://www.tidyverse.org/) Packet basiert.\n\n### 3.1 Überprüfen\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsum(is.na(d_hate))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n\n```{.r .cell-code}\nvisdat::vis_dat(d_hate, warn_large_data = FALSE)\n```\n\n::: {.cell-output-display}\n![](DS2_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nIm Datensatz gibt es keine fehlenden Werte. Sowohl `tweet` als auch `class` sind character-Variablen. Für die Klassifikation würde es eventuell Sinn machen `class` in eine factor Variable umzuwandeln.\n\n### 3.3 Anteile der Faktorstufen der AV betrachten\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nggplot(d_hate, aes(x = class, fill = class)) +\n  geom_bar() +\n  labs(title = \"Verteilung der Klassen\") +\n  scale_fill_tableau(\"Nuriel Stone\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](DS2_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nd_hate |> \n  count(class == \"other\") |> \n  mutate(Anteil = n/sum(n))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"class == \\\"other\\\"\"],\"name\":[1],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"Anteil\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"FALSE\",\"2\":\"1430\",\"3\":\"0.2556767\"},{\"1\":\"TRUE\",\"2\":\"4163\",\"3\":\"0.7443233\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nCa. 25 % der Daten sind der Klasse hate speech zugeordnet. Zum Trainieren der Modelle wäre ein höherer Anteil möglicherweise besser, aber diese Verteilung ist auf jeden Fall realistischer.\n\n### 3.2 Tokenisierung\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntweets <- hate2 %>%\n  unnest_tokens(word, textclean)\ntweets <- tweets %>%\n  anti_join(stop_words)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(word)`\n```\n:::\n:::\n\n\nEntfernen des Worts \"rt\", welches für retweet steht.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Das zu entfernende Wort\nword_to_remove <- \"rt\"\n\ntweets3 <- anti_join(tweets, data.frame(word = word_to_remove), by = \"word\")\n```\n:::\n\n\n### 3.3 Häufigste Wörter\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\ntweets3 %>% \n  count(word, sort = TRUE) %>%\n  top_n(15) %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(x = word, y = n)) +\n  geom_col(fill = \"#A39FC9FF\") +\n  xlab(NULL) +\n  coord_flip() +\n  labs(y = \"Count\",\n       x = \"Unique words\",\n       title = \"Most frequent words found in the tweets\",\n       subtitle = \"Stop words removed from the list\") +\n  theme_minimal()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSelecting by n\n```\n:::\n\n::: {.cell-output-display}\n![](DS2_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nDas mit Abstand am häufigsten verwendete Wort ist trash. Dieses kommt fast 800 Mal in den Daten vor, was vielleicht darauf zu schließen ist, dass es sowohl im negativen, neutralen als auch im hate speech Kontext vorkommen kann. Es könnte nämlich dabei um trash cans, trash talking oder um trash als Beleidung für Personen gehen.\n\n### 3.4 Wortwolken\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nset.seed(42)\nwordcloud(tweets3$word, max.words = 200, min.freq=5, scale=c(2.2, 1), random.order=FALSE, rot.per=0.35, colors = colorsn)\n```\n\n::: {.cell-output-display}\n![](DS2_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\nAuch in der Wortwolke sieht man nochmal, dass trash das am häufigsten verwendete Wort ist, wobei einige Wörter vom plot darüber hier nicht auftauchen.\n\n### 3.5 Sentimentanalyse\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\n# Converting tweets to ASCII to trackle strange characters\ntweets2 <- iconv(tweets, from=\"UTF-8\", to=\"ASCII\", sub=\"\")\n# removing retweets, in case needed \ntweets2 <-gsub(\"(RT|via)((?:\\\\b\\\\w*@\\\\w+)+)\",\"\",tweets)\n# removing mentions, in case needed\ntweets2 <-gsub(\"@\\\\w+\",\"\",tweets)\new_sentiment<-get_nrc_sentiment((tweets2))\nsentimentscores<-data.frame(colSums(ew_sentiment[,]))\nnames(sentimentscores) <- \"Score\"\nsentimentscores <- cbind(\"sentiment\"=rownames(sentimentscores),sentimentscores)\nrownames(sentimentscores) <- NULL\nggplot(data=sentimentscores,aes(x=sentiment,y=Score))+\n  geom_bar(aes(fill=sentiment),stat = \"identity\")+\n  theme(legend.position=\"none\")+\n  xlab(\"Sentiments\")+ylab(\"Scores\")+\n  ggtitle(\"Total sentiment based on scores\")+\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = colorsn)\n```\n\n::: {.cell-output-display}\n![](DS2_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\nEs gibt mehr negativ gestimmte Tweets als positive, aber der Unterschied ist nicht so hoch. Die stärkste Stimmung scheint `trust`, also Vertrauen, zu sein, dicht gefolgt von `fear`. Das niedrigste Sentiment ist `suprise`. Jetzt wäre es noch interessant zu wissen wie sich die Sentimentanalyse noch jeweils für die beiden Klassen unterscheidet.\n\nFÜr die Klasse hate speech:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\ntweetsh <- tweets |> \n  filter(classc == \"hate speech\")\n\n\ntweetsh1 <- iconv(tweetsh, from=\"UTF-8\", to=\"ASCII\", sub=\"\")\ntweetsh1 <-gsub(\"(RT|via)((?:\\\\b\\\\w*@\\\\w+)+)\",\"\",tweetsh)\ntweetsh1 <-gsub(\"@\\\\w+\",\"\",tweetsh)\new_sentimenth<-get_nrc_sentiment((tweetsh1))\nsentimentscoresh<-data.frame(colSums(ew_sentimenth[,]))\nnames(sentimentscoresh) <- \"Score\"\nsentimentscoresh <- cbind(\"sentiment\"=rownames(sentimentscoresh),sentimentscoresh)\nrownames(sentimentscoresh) <- NULL\nggplot(data=sentimentscoresh,aes(x=sentiment,y=Score))+\n  geom_bar(aes(fill=sentiment),stat = \"identity\")+\n  theme(legend.position=\"none\")+\n  xlab(\"Sentiments\")+ylab(\"Scores\")+\n  ggtitle(\"Class `hate speech` sentiment based on scores\")+\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = colorsn)\n```\n\n::: {.cell-output-display}\n![](DS2_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\nWie zu erwarten mehr negative als positive Sentiments, jedoch ist `positive` immer noch erstaunlich hoch dafür, dass es hate speech ist. Insgesamt sind die negativen Sentimente wie `anger`, `fear`, `disgust` und `sadness` höher als die positiven, jedoch hätte ich gerade was `anger` und `distgust` angeht viel höhere Werte im Vergleich erwartet.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\ntweetso <- tweets |> \n  filter(classc == \"other\")\n\n\ntweetso1 <- iconv(tweetso, from=\"UTF-8\", to=\"ASCII\", sub=\"\")\ntweetso1 <-gsub(\"(RT|via)((?:\\\\b\\\\w*@\\\\w+)+)\",\"\",tweetso)\ntweetso1 <-gsub(\"@\\\\w+\",\"\",tweetso)\new_sentimento<-get_nrc_sentiment((tweetso1))\nsentimentscoreso<-data.frame(colSums(ew_sentimento[,]))\nnames(sentimentscoreso) <- \"Score\"\nsentimentscoreso <- cbind(\"sentiment\"=rownames(sentimentscoreso),sentimentscoreso)\nrownames(sentimentscoreso) <- NULL\nggplot(data=sentimentscoreso,aes(x=sentiment,y=Score))+\n  geom_bar(aes(fill=sentiment),stat = \"identity\")+\n  theme(legend.position=\"none\")+\n  xlab(\"Sentiments\")+ylab(\"Scores\")+\n  ggtitle(\"Class `Other` sentiment based on scores\")+\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = colorsn)\n```\n\n::: {.cell-output-display}\n![](DS2_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\nAuch bei der Klasse other überwiegen negative Sentiments, jedoch nicht so stark. Den höchsten Score hat `trust`, dicht gefolgt von `fear`. Insgesamt ist die Verteilung sehr ähnlich zu den Scores von allen tweets.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nfoo <- tweets3 %>%\n  group_by(word, classc) %>%\n  count()\n\nbar <- tweets3 %>%\n  group_by(word) %>%\n  count() %>%\n  rename(all = n)\n\nfoo %>%\n  left_join(bar, by = \"word\") %>%\n  arrange(desc(all)) %>%\n  head(50) %>%\n  ungroup() %>%\n  ggplot(aes(reorder(word, all, FUN = min), n, fill = classc)) +\n  geom_col(witdh = 10) +\n  xlab(NULL) +\n  coord_flip() +\n  facet_wrap(~ classc) +\n  scale_fill_tableau(\"Nuriel Stone\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in geom_col(witdh = 10): Ignoring unknown parameters: `witdh`\n```\n:::\n\n::: {.cell-output-display}\n![](DS2_files/figure-html/unnamed-chunk-30-1.png){width=672}\n:::\n:::\n\n\nHier wird das Vorkommen der häufigsten Wörter in den beiden Klassen verglichen. Gut zu sehen ist dabei, dass manche Wörter erst im Kontext eine negative Bedeutung bekommen, wie z.B. trash oder white. Diese können sowohl der sachlichen Beschreibung als auch zur Beleidigung dienen.\n\n### 3.7 Textlänge in Abhängigkeit der Klasse\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nhate1 <-\n  d_hate |> \n  mutate(text_length = str_length(tweet))\n\nggplot(hate1, aes(x = class, y = text_length, color = class)) +\n  geom_point() +\n  labs(title = \"Datensatz Visualisierung\",\n       x = \"Class\",\n       y = \"Textlänge\",\n       color = \"Class\") +\n  scale_color_tableau(\"Nuriel Stone\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](DS2_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n\nDie Klasse `other` besitzt mehr Ausreißer nach oben hin, aber sonst scheint es keine großen Unterschiede zwischen beiden Klassen zu geben.\n\n### 3.8 Histogramm der Textlänge\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nggplot(hate1, aes(x = text_length)) +\n  geom_histogram(binwidth = 5, fill = \"#6FB899FF\", ) +\n  scale_fill_tableau(\"Nuriel Stone\") +\n  labs(title = \"Histogramm der Textlängen\", \n       x = \"Textlänge\", \n       y = \"Häufigkeit\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](DS2_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n\nDie Textlänge ist etwas linkschief verteilt, wobei ein Großteil der tweets unter 150 Zeichen hat. Die meisten Tweets wurden jedoch mit knapp 150 Zeichen verfasst. Dies lässt sich möglicherweise durch das Alter der Daten erklären, denn bis 2017 waren Tweets auf 140 Zeichen begrenzt und danach waren erst mehr (aktuell 280) erlaubt.\n\n### 3.9 Boxplot\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nggplot(hate1, aes(x = class, y = text_length, fill = class)) +\n  geom_boxplot() +\n  labs(title = \"Boxplot der Textlängen nach Klasse\", x = \"class\", y = \"Textlänge\", fill = \"class\")+\n  scale_fill_tableau(\"Nuriel Stone\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](DS2_files/figure-html/unnamed-chunk-36-1.png){width=672}\n:::\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nhate1 |> \n  group_by(class) |> \n  summarise(mean(text_length))\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"class\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"mean(text_length)\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"hate speech\",\"2\":\"84.58671\"},{\"1\":\"other\",\"2\":\"94.85011\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nWie man zuvor schon sehen konnte, ist die Verteilung der beiden Klassen ungefähr gleich, jedoch liegt bei other die durchschnittliche Textlänge etwas höher und auch die Ausreißer haben eine höhere Textlänge. \\### 3.10 TF-IDF\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nfrequency2 <-tweets3 %>%\n  count(classc, word)\n\ntf_idf <- frequency2 %>%\n  bind_tf_idf(word, classc, n)\n\ntf_idf %>%\n  arrange(desc(tf_idf)) %>%\n  mutate(word = factor(word, levels = rev(unique(word)))) %>%\n  top_n(30, tf_idf) %>%\n  ggplot(aes(word, tf_idf, fill = classc)) +\n  geom_col() +\n  labs(x = NULL, y = \"TF-IDF values\") +\n  theme(legend.position = \"top\", axis.text.x  = element_text(angle=45, hjust=1, vjust=0.9)) +\n  scale_fill_manual(values = colorsn)\n```\n\n::: {.cell-output-display}\n![](DS2_files/figure-html/unnamed-chunk-38-1.png){width=672}\n:::\n:::\n\n\nTF-IDF gibt die Häufigkeit eines Wortes in einem spezifischen Kontext (also einer Klasse) innerhalb einer größeren Textsammlung (also alle Klassen) an. Dies ermöglicht es uns, Wörter zu identifizieren, die charakteristisch für eine bestimmte Klasse sind.\n\nFür die Klassifizierung von hate speech sind vor allem Beleidigungen wichtig, während other scheinbar neutrale Wörter enthält.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\ntf_idf %>%\n  arrange(desc(tf_idf)) %>%\n  mutate(word = factor(word, levels = rev(unique(word)))) %>%\n  group_by(classc) %>%\n  top_n(20, tf_idf) %>%\n  ungroup() %>%  \n  ggplot(aes(word, tf_idf, fill = classc)) +\n  geom_col() +\n  labs(x = NULL, y = \"tf-idf\") +\n  theme(legend.position = \"none\") +\n  facet_wrap(~ classc, ncol = 3, scales = \"free\") +\n  coord_flip() +\n  labs(y = \"TF-IDF values\") +\n  scale_fill_manual(values = colorsn)\n```\n\n::: {.cell-output-display}\n![](DS2_files/figure-html/unnamed-chunk-40-1.png){width=672}\n:::\n:::\n\n\nHier sind nochmal die Wörter mit den höchsten TF-IDF-Werten nach Klasse aufgelistet. Auch hier ist gut zu erkennen, dass bei hate speech vor allem rassistische, diskriminierende und sexistische Beleidigungen verwendet werden, während bei other scheinbar wahllos Wörter auftauchen.\n\n### 3.11 Bigrams\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\ntweets4 <- hate2 %>% dplyr::select(classc, textclean) %>% unnest_tokens(bigram, textclean, token = \"ngrams\", n = 2)\n\nbi_sep <- tweets4 %>%\n  separate(bigram, c(\"word1\", \"word2\"), sep = \" \")\n\nbi_filt <- bi_sep %>%\n  filter(!word1 %in% stop_words$word) %>%\n  filter(!word2 %in% stop_words$word)\n\n# for later\nbigram_counts <- bi_filt %>%\n  count(word1, word2, sort = TRUE)\n\ntweets4 <- bi_filt %>%\n  unite(bigram, word1, word2, sep = \" \")\n\nt2_tf_idf <- tweets4 %>%\n  count(classc, bigram) %>%\n  bind_tf_idf(bigram, classc, n) %>%\n  arrange(desc(tf_idf))\n\nt2_tf_idf %>%\n  arrange(desc(tf_idf)) %>%\n  mutate(bigram = factor(bigram, levels = rev(unique(bigram)))) %>%\n  group_by(classc) %>%\n  top_n(10, tf_idf) %>%\n  ungroup() %>%  \n  ggplot(aes(bigram, tf_idf, fill = classc)) +\n  geom_col() +\n  labs(x = NULL, y = \"TF-IDF values\") +\n  theme(legend.position = \"none\") +\n  facet_wrap(~ classc, ncol = 3, scales = \"free\") +\n  coord_flip() +\n  theme_minimal() +\n  scale_fill_manual(values = colorsn)\n```\n\n::: {.cell-output-display}\n![](DS2_files/figure-html/unnamed-chunk-42-1.png){width=672}\n:::\n:::\n\n\nAuch bei den TF-IDF-Werte für die Bigramme ist eindeutig zu essen, wie relevant Beleidigungen zur Erkennung von hate speech sind. Oftmals wurden hier einfach nur Beleidigungen kombiniert, während bei other entweder über Personen oder auch assiatische Massagen geredet wird.\n\n### 3.12 Bigram-Netz\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nbigram_graph <- bigram_counts %>%\n  filter(n > 6) %>%\n  graph_from_data_frame()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in graph_from_data_frame(.): In `d' `NA' elements were replaced with\nstring \"NA\"\n```\n:::\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nset.seed(1234)\n\na <- grid::arrow(type = \"closed\", length = unit(.1, \"inches\"))\n\nggraph(bigram_graph, layout = \"fr\") +\n  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,\n                 arrow = a, end_cap = circle(.07, 'inches')) +\n  geom_node_point(color = \"#94D0C0FF\", size = 3) +\n  geom_node_text(aes(label = name), vjust = 1, hjust = 1) +\n  theme_void()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\ni Please use `linewidth` in the `default_aes` field and elsewhere instead.\n```\n:::\n\n::: {.cell-output-display}\n![](DS2_files/figure-html/unnamed-chunk-44-1.png){width=672}\n:::\n:::\n\n\nDieses Netz ist ein sehr gutes Beispiel um zu zeigen, wie manche scheinbar harmlose Wörter in Verbindungen mit anderen eine negative Bedeutung annehmen können. Bestes Beispiel ist hier trash: redet man über trash cans, dann mag es vielleicht nur um die Müllentsorgung gehen, während trash in Verbindung mit black eine starke Beleidigung gegenüber einer Bevölkerungsgruppe ist.\n\n### 3.13 Negierte Begriffe\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nbi_sep <- hate2 %>%\n  dplyr::select(classc, textclean) %>%\n  unnest_tokens(bigram, textclean, token = \"ngrams\", n = 2) %>%\n  separate(bigram, c(\"word1\", \"word2\"), sep = \" \")\n\np1 <- bi_sep %>%\n  filter(word1 == \"not\") %>%\n  inner_join(get_sentiments(\"bing\"), by = c(word2 = \"word\")) %>%\n  count(word1, word2, sentiment, sort = TRUE) %>%\n  ungroup() %>%\n  arrange(desc(abs(n))) %>%\n  head(15) %>%\n  mutate(n = if_else(sentiment == \"positive\", n, -n)) %>% \n  mutate(word2 = reorder(word2, n)) %>%\n  ggplot(aes(word2, n, fill = sentiment)) +\n  geom_col(show.legend = TRUE) +\n  xlab(\"\") +\n  ylab(\"Number of occurrences\") +\n  coord_flip() +\n  theme(plot.title = element_text(size=11)) +\n  ggtitle(\"Alle Klassen - Wörter, bei denen 'not' davorsteht\") +\n  scale_fill_manual(values = c(\"#E04F6C\", \"#5E8A67FF\")) +\n  theme_minimal()\nprint(p1)\n```\n\n::: {.cell-output-display}\n![](DS2_files/figure-html/unnamed-chunk-46-1.png){width=672}\n:::\n:::\n\n\nAnscheinend gibt es mehr negative Wörter, die mit einem 'not' verneint wurden. Interessanterweise wird das Wort funny auch als negativ gewertet, was nicht wirklich Sinn macht. Im Zusammenhang mit 'not' ist es natürlich sinnvoll, es als negativ einzuordnen.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\np2 <- bi_sep %>%\n  filter(classc == \"other\") %>%\n  filter(word1 == \"not\") %>%\n  inner_join(get_sentiments(\"bing\"), by = c(word2 = \"word\")) %>%\n  count(word1, word2, sentiment, sort = TRUE) %>%\n  ungroup() %>%\n  arrange(desc(abs(n))) %>%\n  head(15) %>%\n  mutate(n = if_else(sentiment == \"positive\", n, -n)) %>% \n  mutate(word2 = reorder(word2, n)) %>%\n  ggplot(aes(word2, n, fill = sentiment)) +\n  geom_col(show.legend = TRUE) +\n  xlab(\"\") +\n  ylab(\"Sentiment score * number of occurrences\") +\n  coord_flip() +\n  theme(plot.title = element_text(size=11)) +\n  ggtitle(\"other - Wörter, bei denen 'not' davorsteht\")  +\n  scale_fill_manual(values = c(\"#E04F6C\", \"#5E8A67FF\")) +\n  theme_minimal()\nprint(p2)\n```\n\n::: {.cell-output-display}\n![](DS2_files/figure-html/unnamed-chunk-48-1.png){width=672}\n:::\n:::\n\n\nAuch in der Klasse other gibt es mehr negative als positive Wörter. Dies war uns ja schon vorher aus der Sentimentanalyse bewusst, deswegen ist es hier nocheinmal interessant zu sehen, dass die negative Bedeutung dieser Wörter durch das 'not' aufgehoben wird. Zudem taucht auch hier das Wort trash auf.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\np3 <- bi_sep %>%\n  filter(classc == \"hate speech\") %>%\n  filter(word1 == \"not\") %>%\n  inner_join(get_sentiments(\"bing\"), by = c(word2 = \"word\")) %>%\n  count(word1, word2, sentiment, sort = TRUE) %>%\n  ungroup() %>%\n  arrange(desc(abs(n))) %>%\n  head(15) %>%\n  mutate(n = if_else(sentiment == \"positive\", n, -n)) %>% \n  mutate(word2 = reorder(word2, n)) %>%\n  ggplot(aes(word2, n, fill = sentiment)) +\n  geom_col(show.legend = TRUE) +\n  xlab(\"\") +\n  ylab(\"Sentiment score * number of occurrences\") +\n  coord_flip() +\n  theme(plot.title = element_text(size=11)) +\n  ggtitle(\"hate speech - Wörter, bei denen 'not' davorsteht\")  +\n  scale_fill_manual(values = c(\"#E04F6C\", \"#5E8A67FF\")) +\n  theme_minimal()\n\nprint(p3)\n```\n\n::: {.cell-output-display}\n![](DS2_files/figure-html/unnamed-chunk-50-1.png){width=672}\n:::\n:::\n\n\nFür die Klasse hate speech gibt es auch mehr negative als positive Wörter. Dies war uns ebenfalls schon vorher aus der Sentimentanalyse bewusst, deswegen ist es hier nocheinmal interessant zu sehen, dass die negative Bedeutung dieser Wörter durch das 'not' aufgehoben wird. Was hier aber auffällt, vor allem im Vergleich zur anderen Klasse, ist dass hier viele negativen Wörter gar nicht so schlimm sind, also z.B. afraid oder bitter. In der anderen Klasse gab es dagegen die Wörter kill, jealous und cripple. Also wurden dort schlimmere Wörter durch ein 'not' aufgehoben, während bei hate speech nur meiner Meinung nach schwach negative Begriffe negiert werden.\n\n### 3.14 Themenanalyse\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfreq <-tweets %>%\n  count(id, word)\n\nt1_tm <- cast_dtm(freq, id, word, n)\nt1_tm\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<<DocumentTermMatrix (documents: 5592, terms: 12768)>>\nNon-/sparse entries: 39386/71359270\nSparsity           : 100%\nMaximal term length: 81\nWeighting          : term frequency (tf)\n```\n:::\n\n```{.r .cell-code}\nt1_lda <- LDA(t1_tm, k = 15, control = list(seed = 1234))\n\nt1_topics <- tidy(t1_lda, matrix = \"beta\")\n\nt1_topics %>%\n  group_by(topic) %>%\n  top_n(5, beta) %>%\n  ungroup() %>%\n  arrange(topic, -beta) %>%\n  mutate(term = reorder(term, beta)) %>%\n  ggplot(aes(term, beta, fill = factor(topic))) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ topic, scales = \"free\", ncol = 5)  +\n  coord_flip() +\n  scale_fill_manual(values = colorsn) +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](DS2_files/figure-html/unnamed-chunk-52-1.png){width=672}\n:::\n:::\n\n\nDie Themenfelder lassen sich hier in Beleidigungen und zufällige Themen einteilen. Gerade unter den Beleidigungen gibt es nochmal Abstufungen zwischen \"allgemeinen\" Beleidigungen und rassistischen. Bei den allgemeinen Themen geht es unter anderem um die yankees, positive Gefühle und Vögel. So wirklich etwas aussagen tut aber keiner dieser Themenfelder, dafür sind sie sich gerade bei den Beleidigungen einfach viel zu ähnlich.\n\n## 4. tidymodels\n\n### 4.1 Rezept erstellen\n\nVerschiedene Rezepte mit unterschiedlicher Vorverarbeitung, um am Ende das beste zu finden.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Rezept 1\nrec1 <-\n  recipe(class ~ ., data = train) |> \n  update_role(id, new_role = \"id\")  |> \n  update_role(tweet, new_role = \"ignore\") |> \n  step_text_normalization(tweet) |> \n  step_mutate(n_schimpf = get_sentiment(tweet,  \n                                    method = \"custom\",\n                                    lexicon = Insults)) |> \n  step_mutate(n_emo = get_sentiment(tweet, \n                                    method = \"nrc\",\n                                    language = \"english\"))  |>\n  step_tokenize(tweet) %>%\n  step_stopwords(tweet, language = \"en\", stopword_source = \"snowball\", keep = FALSE) |> \n  step_tokenfilter(tweet, max_tokens = 1e2)\n\ntidy(rec1)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"number\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"operation\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"type\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"trained\"],\"name\":[4],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"skip\"],\"name\":[5],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"id\"],\"name\":[6],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"1\",\"2\":\"step\",\"3\":\"text_normalization\",\"4\":\"FALSE\",\"5\":\"FALSE\",\"6\":\"text_normalization_eD6Uv\"},{\"1\":\"2\",\"2\":\"step\",\"3\":\"mutate\",\"4\":\"FALSE\",\"5\":\"FALSE\",\"6\":\"mutate_w2lrd\"},{\"1\":\"3\",\"2\":\"step\",\"3\":\"mutate\",\"4\":\"FALSE\",\"5\":\"FALSE\",\"6\":\"mutate_SoVUR\"},{\"1\":\"4\",\"2\":\"step\",\"3\":\"tokenize\",\"4\":\"FALSE\",\"5\":\"FALSE\",\"6\":\"tokenize_a3i8t\"},{\"1\":\"5\",\"2\":\"step\",\"3\":\"stopwords\",\"4\":\"FALSE\",\"5\":\"FALSE\",\"6\":\"stopwords_ylt9c\"},{\"1\":\"6\",\"2\":\"step\",\"3\":\"tokenfilter\",\"4\":\"FALSE\",\"5\":\"FALSE\",\"6\":\"tokenfilter_9UjlV\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nd_baked1 <- prep(rec1) |> bake(new_data = NULL)\nsum(is.na(d_baked1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n\n```{.r .cell-code}\n# Rezept 2\nrec2 <-\n  recipe(class ~ ., data = train) |> \n  update_role(id, new_role = \"id\")  |> \n  update_role(tweet, new_role = \"ignore\") |> \n  step_text_normalization(tweet) |> \n  step_mutate(n_schimpf = get_sentiment(tweet,  # aus `syuzhet`\n                                    method = \"custom\",\n                                    lexicon = Insults)) |> \n  step_mutate(n_emo = get_sentiment(tweet,  # aus `syuzhet`\n                                    method = \"nrc\",\n                                    language = \"englisch\"))  |> \n  step_tokenize(tweet) %>%\n  step_stopwords(tweet, language = \"en\", stopword_source = \"snowball\", keep = FALSE) |> \n  step_tokenfilter(tweet, max_tokens = 1e3) |> \n  step_tfidf(tweet) \n\ntidy(rec2)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"number\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"operation\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"type\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"trained\"],\"name\":[4],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"skip\"],\"name\":[5],\"type\":[\"lgl\"],\"align\":[\"right\"]},{\"label\":[\"id\"],\"name\":[6],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"1\",\"2\":\"step\",\"3\":\"text_normalization\",\"4\":\"FALSE\",\"5\":\"FALSE\",\"6\":\"text_normalization_gs6RE\"},{\"1\":\"2\",\"2\":\"step\",\"3\":\"mutate\",\"4\":\"FALSE\",\"5\":\"FALSE\",\"6\":\"mutate_qv0pp\"},{\"1\":\"3\",\"2\":\"step\",\"3\":\"mutate\",\"4\":\"FALSE\",\"5\":\"FALSE\",\"6\":\"mutate_OnGoL\"},{\"1\":\"4\",\"2\":\"step\",\"3\":\"tokenize\",\"4\":\"FALSE\",\"5\":\"FALSE\",\"6\":\"tokenize_uBwNq\"},{\"1\":\"5\",\"2\":\"step\",\"3\":\"stopwords\",\"4\":\"FALSE\",\"5\":\"FALSE\",\"6\":\"stopwords_8JLze\"},{\"1\":\"6\",\"2\":\"step\",\"3\":\"tokenfilter\",\"4\":\"FALSE\",\"5\":\"FALSE\",\"6\":\"tokenfilter_aHBDr\"},{\"1\":\"7\",\"2\":\"step\",\"3\":\"tfidf\",\"4\":\"FALSE\",\"5\":\"FALSE\",\"6\":\"tfidf_dctft\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nd_baked2 <- prep(rec2) |> bake(new_data = NULL)\nsum(is.na(d_baked2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n:::\n\n\n### 4.2 Kreuzvalidierung\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\ncv_scheme <- vfold_cv(train,\n  v = 5, \n  repeats = 2,\n  strata = class)\n```\n:::\n\n\n### 4.3 Modelle\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Baum\nmod_tree <-\n  decision_tree(cost_complexity = tune(),\n  tree_depth = tune(),\n  mode = \"classification\")\n\n# Random Forest\nmod_rf <-\n  rand_forest(mtry = tune(),\n  min_n = tune(),\n  trees = 1000,\n  mode = \"classification\") %>% \n  set_engine(\"ranger\", num.threads = 4)\n\n# XGBoost\n\nmod_boost <- boost_tree(\n  mode = \"classification\",\n  engine = \"xgboost\",\n  mtry = tune(),\n  trees = tune(),\n  min_n = tune()\n)\n\n\n# logistische Regression\nmod_logreg <- logistic_reg(\n              mode = \"classification\",\n              engine = \"glm\",\n              penalty = 1)\n```\n:::\n\n\n### 4.4 Workflows erstellen\n\nDie Zahlenbenennung der Workflows ist immer die Kombination aus welchem Modell (1-4) und welches Rezept (1-2) Ich habe mich gezielt gegen Workflowsets entschieden, da die Rechenzeit für meinen Computer dafür immer sehr lange dauert.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Rezept 1 mit decision tree\nworkflow11 <-\n  workflow() |> \n  add_model(mod_tree) |> \n  add_recipe(rec1)\n\n# Rezept 2 mit decision tree\nworkflow12 <-\n  workflow() |> \n  add_model(mod_tree) |> \n  add_recipe(rec2)\n\n# Rezept 1 mit random forest\nworkflow21 <-\n  workflow() |> \n  add_model(mod_rf) |> \n  add_recipe(rec1)\n\n# Rezept 2 mit random forest (dauert viel zu lange)\n# workflow22 <-\n  #workflow() |> \n  #add_model(mod_rf) |> \n  #add_recipe(rec2)\n\n# Rezept 1 mit xgboost\nworkflow31 <-\n  workflow() |> \n  add_model(mod_boost) |> \n  add_recipe(rec1)\n\n# Rezept 2 mit xgboost (dauert viel zu lange)\n#workflow32 <-\n  #workflow() |> \n  #add_model(mod_boost) |> \n  #add_recipe(rec2)\n\n# Rezept 1 mit logistischer Regression\nworkflow41 <-\n  workflow() |> \n  add_model(mod_logreg) |> \n  add_recipe(rec1)\n\n# Rezept 2 mit logistischer Regression (Modell läuft leider nicht)\n#workflow42 <-\n  #workflow() |> \n  #add_model(mod_logreg) |> \n  #add_recipe(rec2)\n```\n:::\n\n\n### 4.5 Tuning\n\nBestes Workflowset\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# tune11\nset.seed(42)\ntic()\ntune11 <-\n  tune_grid(object = workflow11,\n            resamples = cv_scheme,\n            grid = 10,\n            control = control_grid(save_workflow = TRUE))\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n493.11 sec elapsed\n```\n:::\n\n```{.r .cell-code}\n# tune12\nset.seed(42)\ntic()\ntune12 <-\n  tune_grid(object = workflow12,\n            resamples = cv_scheme,\n            grid = 10,\n            control = control_grid(save_workflow = TRUE))\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n971.25 sec elapsed\n```\n:::\n\n```{.r .cell-code}\n# tune21\nset.seed(42)\ntic()\ntune21 <-\n  tune_grid(object = workflow21,\n            resamples = cv_scheme,\n            grid = 10,\n            control = control_grid(save_workflow = TRUE))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\ni Creating pre-processing data to finalize unknown parameter: mtry\n```\n:::\n\n```{.r .cell-code}\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n456.7 sec elapsed\n```\n:::\n\n```{.r .cell-code}\n#tune31\nset.seed(42)\ntic()\ntune31 <-\n  tune_grid(object = workflow31,\n            resamples = cv_scheme,\n            grid = 10,\n            control = control_grid(save_workflow = TRUE))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\ni Creating pre-processing data to finalize unknown parameter: mtry\n```\n:::\n\n```{.r .cell-code}\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n569.36 sec elapsed\n```\n:::\n\n```{.r .cell-code}\n#tune41\nset.seed(42)\ntic()\ntune41 <-\n  tune_grid(object = workflow41,\n            resamples = cv_scheme,\n            grid = 10,\n            control = control_grid(save_workflow = TRUE))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: No tuning parameters have been detected, performance will be evaluated\nusing the resamples with no tuning. Did you want to [tune()] parameters?\n```\n:::\n\n```{.r .cell-code}\ntoc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n133.95 sec elapsed\n```\n:::\n:::\n\n\n### 4.6 Modellvergelich\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# mit Rezept 6\ntune11 |> collect_metrics()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"cost_complexity\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tree_depth\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\".metric\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"mean\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[6],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"std_err\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[8],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"1.442528e-10\",\"2\":\"1\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.7650865\",\"6\":\"10\",\"7\":\"0.001957094\",\"8\":\"Preprocessor1_Model01\"},{\"1\":\"1.442528e-10\",\"2\":\"1\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.5676181\",\"6\":\"10\",\"7\":\"0.003139741\",\"8\":\"Preprocessor1_Model01\"},{\"1\":\"1.532098e-02\",\"2\":\"12\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.7649748\",\"6\":\"10\",\"7\":\"0.001979662\",\"8\":\"Preprocessor1_Model02\"},{\"1\":\"1.532098e-02\",\"2\":\"12\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.5671869\",\"6\":\"10\",\"7\":\"0.003292674\",\"8\":\"Preprocessor1_Model02\"},{\"1\":\"1.027400e-05\",\"2\":\"13\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.7698930\",\"6\":\"10\",\"7\":\"0.001861094\",\"8\":\"Preprocessor1_Model03\"},{\"1\":\"1.027400e-05\",\"2\":\"13\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.6033445\",\"6\":\"10\",\"7\":\"0.006093747\",\"8\":\"Preprocessor1_Model03\"},{\"1\":\"5.884876e-07\",\"2\":\"4\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.7689989\",\"6\":\"10\",\"7\":\"0.001851399\",\"8\":\"Preprocessor1_Model04\"},{\"1\":\"5.884876e-07\",\"2\":\"4\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.6031124\",\"6\":\"10\",\"7\":\"0.006099248\",\"8\":\"Preprocessor1_Model04\"},{\"1\":\"8.136045e-08\",\"2\":\"10\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.7698930\",\"6\":\"10\",\"7\":\"0.001861094\",\"8\":\"Preprocessor1_Model05\"},{\"1\":\"8.136045e-08\",\"2\":\"10\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.6033445\",\"6\":\"10\",\"7\":\"0.006093747\",\"8\":\"Preprocessor1_Model05\"},{\"1\":\"1.223220e-03\",\"2\":\"8\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.7676569\",\"6\":\"10\",\"7\":\"0.002177065\",\"8\":\"Preprocessor1_Model06\"},{\"1\":\"1.223220e-03\",\"2\":\"8\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.5972670\",\"6\":\"10\",\"7\":\"0.005703059\",\"8\":\"Preprocessor1_Model06\"},{\"1\":\"2.610206e-05\",\"2\":\"3\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.7650867\",\"6\":\"10\",\"7\":\"0.002781714\",\"8\":\"Preprocessor1_Model07\"},{\"1\":\"2.610206e-05\",\"2\":\"3\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.5737839\",\"6\":\"10\",\"7\":\"0.005345210\",\"8\":\"Preprocessor1_Model07\"},{\"1\":\"1.878796e-09\",\"2\":\"14\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.7698930\",\"6\":\"10\",\"7\":\"0.001861094\",\"8\":\"Preprocessor1_Model08\"},{\"1\":\"1.878796e-09\",\"2\":\"14\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.6033445\",\"6\":\"10\",\"7\":\"0.006093747\",\"8\":\"Preprocessor1_Model08\"},{\"1\":\"2.494003e-03\",\"2\":\"6\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.7664276\",\"6\":\"10\",\"7\":\"0.002375390\",\"8\":\"Preprocessor1_Model09\"},{\"1\":\"2.494003e-03\",\"2\":\"6\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.5788168\",\"6\":\"10\",\"7\":\"0.006274832\",\"8\":\"Preprocessor1_Model09\"},{\"1\":\"4.641294e-08\",\"2\":\"8\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.7698930\",\"6\":\"10\",\"7\":\"0.001861094\",\"8\":\"Preprocessor1_Model10\"},{\"1\":\"4.641294e-08\",\"2\":\"8\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.6033445\",\"6\":\"10\",\"7\":\"0.006093747\",\"8\":\"Preprocessor1_Model10\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nautoplot(tune11)\n```\n\n::: {.cell-output-display}\n![](DS2_files/figure-html/unnamed-chunk-64-1.png){width=672}\n:::\n\n```{.r .cell-code}\ntune12 |> collect_metrics()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"cost_complexity\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"tree_depth\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\".metric\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"mean\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[6],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"std_err\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[8],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"1.442528e-10\",\"2\":\"1\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.7727999\",\"6\":\"10\",\"7\":\"0.001435910\",\"8\":\"Preprocessor1_Model01\"},{\"1\":\"1.442528e-10\",\"2\":\"1\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.5570256\",\"6\":\"10\",\"7\":\"0.002532790\",\"8\":\"Preprocessor1_Model01\"},{\"1\":\"1.532098e-02\",\"2\":\"12\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.8994172\",\"6\":\"10\",\"7\":\"0.002598859\",\"8\":\"Preprocessor1_Model02\"},{\"1\":\"1.532098e-02\",\"2\":\"12\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.8220543\",\"6\":\"10\",\"7\":\"0.004056502\",\"8\":\"Preprocessor1_Model02\"},{\"1\":\"1.027400e-05\",\"2\":\"13\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.9064576\",\"6\":\"10\",\"7\":\"0.002394464\",\"8\":\"Preprocessor1_Model03\"},{\"1\":\"1.027400e-05\",\"2\":\"13\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.8341085\",\"6\":\"10\",\"7\":\"0.003904672\",\"8\":\"Preprocessor1_Model03\"},{\"1\":\"5.884876e-07\",\"2\":\"4\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.8366118\",\"6\":\"10\",\"7\":\"0.002212503\",\"8\":\"Preprocessor1_Model04\"},{\"1\":\"5.884876e-07\",\"2\":\"4\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.6847367\",\"6\":\"10\",\"7\":\"0.003970916\",\"8\":\"Preprocessor1_Model04\"},{\"1\":\"8.136045e-08\",\"2\":\"10\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.8891361\",\"6\":\"10\",\"7\":\"0.002638451\",\"8\":\"Preprocessor1_Model05\"},{\"1\":\"8.136045e-08\",\"2\":\"10\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.8014597\",\"6\":\"10\",\"7\":\"0.004052625\",\"8\":\"Preprocessor1_Model05\"},{\"1\":\"1.223220e-03\",\"2\":\"8\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.8712553\",\"6\":\"10\",\"7\":\"0.002078352\",\"8\":\"Preprocessor1_Model06\"},{\"1\":\"1.223220e-03\",\"2\":\"8\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.7580001\",\"6\":\"10\",\"7\":\"0.003725191\",\"8\":\"Preprocessor1_Model06\"},{\"1\":\"2.610206e-05\",\"2\":\"3\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.8258842\",\"6\":\"10\",\"7\":\"0.002171924\",\"8\":\"Preprocessor1_Model07\"},{\"1\":\"2.610206e-05\",\"2\":\"3\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.6629694\",\"6\":\"10\",\"7\":\"0.003765719\",\"8\":\"Preprocessor1_Model07\"},{\"1\":\"1.878796e-09\",\"2\":\"14\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.9094748\",\"6\":\"10\",\"7\":\"0.002446306\",\"8\":\"Preprocessor1_Model08\"},{\"1\":\"1.878796e-09\",\"2\":\"14\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.8402050\",\"6\":\"10\",\"7\":\"0.004016522\",\"8\":\"Preprocessor1_Model08\"},{\"1\":\"2.494003e-03\",\"2\":\"6\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.8551625\",\"6\":\"10\",\"7\":\"0.001998347\",\"8\":\"Preprocessor1_Model09\"},{\"1\":\"2.494003e-03\",\"2\":\"6\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.7215544\",\"6\":\"10\",\"7\":\"0.003498782\",\"8\":\"Preprocessor1_Model09\"},{\"1\":\"4.641294e-08\",\"2\":\"8\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.8712553\",\"6\":\"10\",\"7\":\"0.002078352\",\"8\":\"Preprocessor1_Model10\"},{\"1\":\"4.641294e-08\",\"2\":\"8\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.7580001\",\"6\":\"10\",\"7\":\"0.003725191\",\"8\":\"Preprocessor1_Model10\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nautoplot(tune12)\n```\n\n::: {.cell-output-display}\n![](DS2_files/figure-html/unnamed-chunk-64-2.png){width=672}\n:::\n\n```{.r .cell-code}\ntune21 |> collect_metrics()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"mtry\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"min_n\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\".metric\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"mean\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[6],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"std_err\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[8],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"1\",\"2\":\"3\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.7688872\",\"6\":\"10\",\"7\":\"0.001849181\",\"8\":\"Preprocessor1_Model01\"},{\"1\":\"1\",\"2\":\"3\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.6557016\",\"6\":\"10\",\"7\":\"0.004389830\",\"8\":\"Preprocessor1_Model01\"},{\"1\":\"2\",\"2\":\"31\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.7693345\",\"6\":\"10\",\"7\":\"0.001707939\",\"8\":\"Preprocessor1_Model02\"},{\"1\":\"2\",\"2\":\"31\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.6548335\",\"6\":\"10\",\"7\":\"0.004495862\",\"8\":\"Preprocessor1_Model02\"},{\"1\":\"2\",\"2\":\"34\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.7701166\",\"6\":\"10\",\"7\":\"0.001901398\",\"8\":\"Preprocessor1_Model03\"},{\"1\":\"2\",\"2\":\"34\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.6550414\",\"6\":\"10\",\"7\":\"0.004505147\",\"8\":\"Preprocessor1_Model03\"},{\"1\":\"1\",\"2\":\"10\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.7691108\",\"6\":\"10\",\"7\":\"0.001880937\",\"8\":\"Preprocessor1_Model04\"},{\"1\":\"1\",\"2\":\"10\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.6555488\",\"6\":\"10\",\"7\":\"0.004423177\",\"8\":\"Preprocessor1_Model04\"},{\"1\":\"1\",\"2\":\"27\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.7689990\",\"6\":\"10\",\"7\":\"0.001849735\",\"8\":\"Preprocessor1_Model05\"},{\"1\":\"1\",\"2\":\"27\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.6549843\",\"6\":\"10\",\"7\":\"0.004308179\",\"8\":\"Preprocessor1_Model05\"},{\"1\":\"2\",\"2\":\"22\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.7691110\",\"6\":\"10\",\"7\":\"0.001623916\",\"8\":\"Preprocessor1_Model06\"},{\"1\":\"2\",\"2\":\"22\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.6547276\",\"6\":\"10\",\"7\":\"0.004465145\",\"8\":\"Preprocessor1_Model06\"},{\"1\":\"2\",\"2\":\"8\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.7689993\",\"6\":\"10\",\"7\":\"0.001596386\",\"8\":\"Preprocessor1_Model07\"},{\"1\":\"2\",\"2\":\"8\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.6553101\",\"6\":\"10\",\"7\":\"0.004620499\",\"8\":\"Preprocessor1_Model07\"},{\"1\":\"1\",\"2\":\"37\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.7691108\",\"6\":\"10\",\"7\":\"0.001880937\",\"8\":\"Preprocessor1_Model08\"},{\"1\":\"1\",\"2\":\"37\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.6551951\",\"6\":\"10\",\"7\":\"0.004201871\",\"8\":\"Preprocessor1_Model08\"},{\"1\":\"2\",\"2\":\"15\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.7698931\",\"6\":\"10\",\"7\":\"0.001836899\",\"8\":\"Preprocessor1_Model09\"},{\"1\":\"2\",\"2\":\"15\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.6553021\",\"6\":\"10\",\"7\":\"0.004510142\",\"8\":\"Preprocessor1_Model09\"},{\"1\":\"1\",\"2\":\"20\",\"3\":\"accuracy\",\"4\":\"binary\",\"5\":\"0.7682169\",\"6\":\"10\",\"7\":\"0.001590291\",\"8\":\"Preprocessor1_Model10\"},{\"1\":\"1\",\"2\":\"20\",\"3\":\"roc_auc\",\"4\":\"binary\",\"5\":\"0.6553008\",\"6\":\"10\",\"7\":\"0.004280172\",\"8\":\"Preprocessor1_Model10\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nautoplot(tune21)\n```\n\n::: {.cell-output-display}\n![](DS2_files/figure-html/unnamed-chunk-64-3.png){width=672}\n:::\n\n```{.r .cell-code}\ntune31 |> collect_metrics()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"mtry\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"trees\"],\"name\":[2],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"min_n\"],\"name\":[3],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\".metric\"],\"name\":[4],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[5],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"mean\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[7],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"std_err\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[9],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"1\",\"2\":\"100\",\"3\":\"4\",\"4\":\"accuracy\",\"5\":\"binary\",\"6\":\"0.7691109\",\"7\":\"10\",\"8\":\"0.001634340\",\"9\":\"Preprocessor1_Model01\"},{\"1\":\"1\",\"2\":\"100\",\"3\":\"4\",\"4\":\"roc_auc\",\"5\":\"binary\",\"6\":\"0.6536345\",\"7\":\"10\",\"8\":\"0.004181102\",\"9\":\"Preprocessor1_Model01\"},{\"1\":\"1\",\"2\":\"356\",\"3\":\"6\",\"4\":\"accuracy\",\"5\":\"binary\",\"6\":\"0.7704519\",\"7\":\"10\",\"8\":\"0.001842590\",\"9\":\"Preprocessor1_Model02\"},{\"1\":\"1\",\"2\":\"356\",\"3\":\"6\",\"4\":\"roc_auc\",\"5\":\"binary\",\"6\":\"0.6548667\",\"7\":\"10\",\"8\":\"0.004046726\",\"9\":\"Preprocessor1_Model02\"},{\"1\":\"1\",\"2\":\"1805\",\"3\":\"13\",\"4\":\"accuracy\",\"5\":\"binary\",\"6\":\"0.7704519\",\"7\":\"10\",\"8\":\"0.001842590\",\"9\":\"Preprocessor1_Model03\"},{\"1\":\"1\",\"2\":\"1805\",\"3\":\"13\",\"4\":\"roc_auc\",\"5\":\"binary\",\"6\":\"0.6546973\",\"7\":\"10\",\"8\":\"0.004356507\",\"9\":\"Preprocessor1_Model03\"},{\"1\":\"1\",\"2\":\"928\",\"3\":\"17\",\"4\":\"accuracy\",\"5\":\"binary\",\"6\":\"0.7682158\",\"7\":\"10\",\"8\":\"0.002788843\",\"9\":\"Preprocessor1_Model04\"},{\"1\":\"1\",\"2\":\"928\",\"3\":\"17\",\"4\":\"roc_auc\",\"5\":\"binary\",\"6\":\"0.6550690\",\"7\":\"10\",\"8\":\"0.004253556\",\"9\":\"Preprocessor1_Model04\"},{\"1\":\"1\",\"2\":\"1107\",\"3\":\"26\",\"4\":\"accuracy\",\"5\":\"binary\",\"6\":\"0.7669875\",\"7\":\"10\",\"8\":\"0.002381496\",\"9\":\"Preprocessor1_Model05\"},{\"1\":\"1\",\"2\":\"1107\",\"3\":\"26\",\"4\":\"roc_auc\",\"5\":\"binary\",\"6\":\"0.6538479\",\"7\":\"10\",\"8\":\"0.004128131\",\"9\":\"Preprocessor1_Model05\"},{\"1\":\"2\",\"2\":\"1259\",\"3\":\"19\",\"4\":\"accuracy\",\"5\":\"binary\",\"6\":\"0.7687751\",\"7\":\"10\",\"8\":\"0.002594250\",\"9\":\"Preprocessor1_Model06\"},{\"1\":\"2\",\"2\":\"1259\",\"3\":\"19\",\"4\":\"roc_auc\",\"5\":\"binary\",\"6\":\"0.6551848\",\"7\":\"10\",\"8\":\"0.004292609\",\"9\":\"Preprocessor1_Model06\"},{\"1\":\"2\",\"2\":\"1636\",\"3\":\"23\",\"4\":\"accuracy\",\"5\":\"binary\",\"6\":\"0.7669875\",\"7\":\"10\",\"8\":\"0.002381496\",\"9\":\"Preprocessor1_Model07\"},{\"1\":\"2\",\"2\":\"1636\",\"3\":\"23\",\"4\":\"roc_auc\",\"5\":\"binary\",\"6\":\"0.6548640\",\"7\":\"10\",\"8\":\"0.004421086\",\"9\":\"Preprocessor1_Model07\"},{\"1\":\"2\",\"2\":\"1499\",\"3\":\"32\",\"4\":\"accuracy\",\"5\":\"binary\",\"6\":\"0.7668758\",\"7\":\"10\",\"8\":\"0.002380936\",\"9\":\"Preprocessor1_Model08\"},{\"1\":\"2\",\"2\":\"1499\",\"3\":\"32\",\"4\":\"roc_auc\",\"5\":\"binary\",\"6\":\"0.6552766\",\"7\":\"10\",\"8\":\"0.004594280\",\"9\":\"Preprocessor1_Model08\"},{\"1\":\"2\",\"2\":\"462\",\"3\":\"35\",\"4\":\"accuracy\",\"5\":\"binary\",\"6\":\"0.7669875\",\"7\":\"10\",\"8\":\"0.002381496\",\"9\":\"Preprocessor1_Model09\"},{\"1\":\"2\",\"2\":\"462\",\"3\":\"35\",\"4\":\"roc_auc\",\"5\":\"binary\",\"6\":\"0.6558292\",\"7\":\"10\",\"8\":\"0.004631857\",\"9\":\"Preprocessor1_Model09\"},{\"1\":\"2\",\"2\":\"685\",\"3\":\"40\",\"4\":\"accuracy\",\"5\":\"binary\",\"6\":\"0.7669875\",\"7\":\"10\",\"8\":\"0.002381496\",\"9\":\"Preprocessor1_Model10\"},{\"1\":\"2\",\"2\":\"685\",\"3\":\"40\",\"4\":\"roc_auc\",\"5\":\"binary\",\"6\":\"0.6558732\",\"7\":\"10\",\"8\":\"0.004703790\",\"9\":\"Preprocessor1_Model10\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\nautoplot(tune31)\n```\n\n::: {.cell-output-display}\n![](DS2_files/figure-html/unnamed-chunk-64-4.png){width=672}\n:::\n\n```{.r .cell-code}\ntune41 |> collect_metrics()\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\".metric\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"mean\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"n\"],\"name\":[4],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"std_err\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\".config\"],\"name\":[6],\"type\":[\"chr\"],\"align\":[\"left\"]}],\"data\":[{\"1\":\"accuracy\",\"2\":\"binary\",\"3\":\"0.7679931\",\"4\":\"10\",\"5\":\"0.001459084\",\"6\":\"Preprocessor1_Model1\"},{\"1\":\"roc_auc\",\"2\":\"binary\",\"3\":\"0.6507851\",\"4\":\"10\",\"5\":\"0.003593218\",\"6\":\"Preprocessor1_Model1\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n### 4.7 Bestes Modell wählen\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbest_model31 <-\n  fit_best(tune31)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_preds31 <- \n  best_model31 %>% \n  predict(new_data = test) %>% \n  bind_cols(test)\n```\n:::\n\n\n### 4.8 ROC AUC-Kurve\n\nAnhand dem eigenen train-sample wird die roc-auc Kurve dargestellt.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntest2 <- final_preds31 |> \n  mutate(class = as.numeric(class))\nfinal_preds31 <- final_preds31 |> \n  mutate(pred = as.numeric(.pred_class))\nrocobj <- roc(test2$class, final_preds31$pred)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSetting levels: control = 1, case = 2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nSetting direction: controls < cases\n```\n:::\n\n```{.r .cell-code}\n#define object to plot and calculate AUC\nrocobj <- roc(test2$class, final_preds31$pred)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSetting levels: control = 1, case = 2\nSetting direction: controls < cases\n```\n:::\n\n```{.r .cell-code}\nauc <- round(auc(test2$class, final_preds31$pred),4)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSetting levels: control = 1, case = 2\nSetting direction: controls < cases\n```\n:::\n\n```{.r .cell-code}\n#create ROC plot\nggroc(rocobj, colour = 'cyan', size = 1) +\n  ggtitle(paste0('ROC Curve ', '(AUC = ', auc, ')')) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](DS2_files/figure-html/unnamed-chunk-70-1.png){width=672}\n:::\n:::\n\n\nDas Modell ist in der Lage, die positiven Fälle von den negativen Fällen mit einer Wahrscheinlichkeit von ca. 59 % zu unterscheiden. Es kann also nur etwas besser als der Zufall entscheiden.\n\nEs ist wichtig zu beachten, dass der ROC AUC-Wert nur ein Maß für die Fähigkeit eines Modells ist, die positiven Fälle von den negativen Fällen zu unterscheiden. Er sagt nichts darüber aus, wie gut das Modell die tatsächlichen Werte der positiven Fälle vorhersagt.\n\n### 4.9 Confusionsmatrix\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nfinal_preds312 <-\n  final_preds31 |> \n  bind_cols(test)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNew names:\n* `id` -> `id...2`\n* `tweet` -> `tweet...3`\n* `class` -> `class...4`\n* `id` -> `id...6`\n* `tweet` -> `tweet...7`\n* `class` -> `class...8`\n```\n:::\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nconfusion_matrix <- confusionMatrix(final_preds31$class, final_preds31$.pred_class)\nprint(confusion_matrix)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n             Reference\nPrediction    hate speech other\n  hate speech          52   234\n  other                14   819\n                                          \n               Accuracy : 0.7784          \n                 95% CI : (0.7529, 0.8024)\n    No Information Rate : 0.941           \n    P-Value [Acc > NIR] : 1               \n                                          \n                  Kappa : 0.2208          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.78788         \n            Specificity : 0.77778         \n         Pos Pred Value : 0.18182         \n         Neg Pred Value : 0.98319         \n             Prevalence : 0.05898         \n         Detection Rate : 0.04647         \n   Detection Prevalence : 0.25559         \n      Balanced Accuracy : 0.78283         \n                                          \n       'Positive' Class : hate speech     \n                                          \n```\n:::\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nsensitivity1 <- confusion_matrix[[\"byClass\"]][[\"Sensitivity\"]]\nsensitivityp1 <- round(sensitivity1*100, digits = 2)\nspecificity1 <- confusion_matrix[[\"byClass\"]][[\"Specificity\"]]\nspecificityp1 <- round(specificity1*100, digits = 2)\naccuracy1 <- confusion_matrix[[\"overall\"]][[\"Accuracy\"]]\naccuracyp1 <- round(accuracy1*100, digits = 2)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nglue('Die Accuracy gibt an, wie viele der insgesamt vorhergesagten Klassen mit den tatsächlichen Klassen übereinstimmen, gemessen als Anteil der korrekt klassifizierten Instanzen an der Gesamtzahl der Instanzen im Datensatz. Bei diesem Modell liegt die Accuracy bei {accuracy1}, d.h. es wurden {accuracyp1} % der Fälle richtig klassifiziert.\n\nDie Sensitivität ist ein Maß dafür, wie gut das Modell positive Fälle (hate speech) erkennt. In diesem Fall ist die Sensitivität von {sensitivity1} gut. Das Modell erkennt {sensitivityp1} % der positiven Fälle korrekt.\n\nDie Spezifität ist ein Maß dafür, wie gut das Modell negative Fälle (other) erkennt. In diesem Fall ist die Spezifität von {specificity1} auch gut. Das Modell erkennt {specificityp1} % der negativen Fälle korrekt.')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDie Accuracy gibt an, wie viele der insgesamt vorhergesagten Klassen mit den tatsächlichen Klassen übereinstimmen, gemessen als Anteil der korrekt klassifizierten Instanzen an der Gesamtzahl der Instanzen im Datensatz. Bei diesem Modell liegt die Accuracy bei 0.778373547810545, d.h. es wurden 77.84 % der Fälle richtig klassifiziert.\n\nDie Sensitivität ist ein Maß dafür, wie gut das Modell positive Fälle (hate speech) erkennt. In diesem Fall ist die Sensitivität von 0.787878787878788 gut. Das Modell erkennt 78.79 % der positiven Fälle korrekt.\n\nDie Spezifität ist ein Maß dafür, wie gut das Modell negative Fälle (other) erkennt. In diesem Fall ist die Spezifität von 0.777777777777778 auch gut. Das Modell erkennt 77.78 % der negativen Fälle korrekt.\n```\n:::\n:::\n\n\n## 5. hugging face Modell\n\n### 5.1 Virtual Environment\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(reticulate)\n\nuse_virtualenv(\"~/Blog/Blogecmb/ds2venv\")\n```\n:::\n\n\n### 5.2 Modell festlegen\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport tensorflow\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWARNING:tensorflow:From C:\\Users\\EMILIA~1\\OneDrive\\DOKUME~1\\Blog\\Blogecmb\\ds2venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n```\n:::\n\n```{.python .cell-code}\nfrom transformers import pipeline\n\nclassifier = pipeline(\"text-classification\", model=\"facebook/roberta-hate-speech-dynabench-r4-target\")\n```\n:::\n\n\n### 5.3 Klassifizieren\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntweetsonly <- test$tweet\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\ntweets = r.tweetsonly\n\nresult = classifier(tweets)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nresult <- py$result\ntest3 <- test\n\nlabels <- map(result, \"label\")\n\n\nif (nrow(test3) == length(labels)) {\n  test3$hatespeech <- unlist(labels)\n} else {\n  print(\"Error!\")\n}\n\ntest3 <-\n  test3|> \n  mutate(hatespeech = factor(hatespeech),\n         hatespeech = case_when(hatespeech == \"nothate\" ~ \"other\",\n                          hatespeech == \"hate\" ~ \"hate speech\"),\n         hatespeech = factor(hatespeech))\n```\n:::\n\n\n### 5.4 Ergebnis\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nmy_metrics2 <- metric_set(accuracy, f_meas)\nmy_metrics2(test3,\n           truth = class,\n           estimate = hatespeech)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\".metric\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimator\"],\"name\":[2],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\".estimate\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"accuracy\",\"2\":\"binary\",\"3\":\"0.8963360\"},{\"1\":\"f_meas\",\"2\":\"binary\",\"3\":\"0.8209877\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nconfusion_matrix2 <- confusionMatrix(test3$class, test3$hatespeech)\nprint(confusion_matrix2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n             Reference\nPrediction    hate speech other\n  hate speech         266    20\n  other                96   737\n                                         \n               Accuracy : 0.8963         \n                 95% CI : (0.877, 0.9136)\n    No Information Rate : 0.6765         \n    P-Value [Acc > NIR] : < 2.2e-16      \n                                         \n                  Kappa : 0.7494         \n                                         \n Mcnemar's Test P-Value : 3.317e-12      \n                                         \n            Sensitivity : 0.7348         \n            Specificity : 0.9736         \n         Pos Pred Value : 0.9301         \n         Neg Pred Value : 0.8848         \n             Prevalence : 0.3235         \n         Detection Rate : 0.2377         \n   Detection Prevalence : 0.2556         \n      Balanced Accuracy : 0.8542         \n                                         \n       'Positive' Class : hate speech    \n                                         \n```\n:::\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nsensitivity2 <- confusion_matrix2[[\"byClass\"]][[\"Sensitivity\"]]\nsensitivityp2 <- round(sensitivity2*100, digits = 2)\nspecificity2 <- confusion_matrix2[[\"byClass\"]][[\"Specificity\"]]\nspecificityp2 <- round(specificity2*100, digits = 2)\naccuracy2 <- confusion_matrix2[[\"overall\"]][[\"Accuracy\"]]\naccuracyp2 <- round(accuracy2*100, digits = 2)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\nglue('Die Accuracy gibt an, wie viele der insgesamt vorhergesagten Klassen mit den tatsächlichen Klassen übereinstimmen, gemessen als Anteil der korrekt klassifizierten Instanzen an der Gesamtzahl der Instanzen im Datensatz. Bei diesem Modell liegt die Accuracy bei {accuracy2}, d.h. es wurden {accuracyp2} % der Fälle richtig klassifiziert.\n\nDie Sensitivität ist ein Maß dafür, wie gut das Modell positive Fälle (hate speech) erkennt. In diesem Fall ist die Sensitivität von {sensitivity2} gut. Das Modell erkennt {sensitivityp2} % der positiven Fälle korrekt.\n\nDie Spezifität ist ein Maß dafür, wie gut das Modell negative Fälle (other) erkennt. In diesem Fall ist die Spezifität von {specificity2} auch gut. Das Modell erkennt {specificityp2} % der negativen Fälle korrekt.')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDie Accuracy gibt an, wie viele der insgesamt vorhergesagten Klassen mit den tatsächlichen Klassen übereinstimmen, gemessen als Anteil der korrekt klassifizierten Instanzen an der Gesamtzahl der Instanzen im Datensatz. Bei diesem Modell liegt die Accuracy bei 0.896336014298481, d.h. es wurden 89.63 % der Fälle richtig klassifiziert.\n\nDie Sensitivität ist ein Maß dafür, wie gut das Modell positive Fälle (hate speech) erkennt. In diesem Fall ist die Sensitivität von 0.734806629834254 gut. Das Modell erkennt 73.48 % der positiven Fälle korrekt.\n\nDie Spezifität ist ein Maß dafür, wie gut das Modell negative Fälle (other) erkennt. In diesem Fall ist die Spezifität von 0.973579920739762 auch gut. Das Modell erkennt 97.36 % der negativen Fälle korrekt.\n```\n:::\n:::\n\n\n## 6. Fazit\n\nIm Vergleich schneidet das hugging face Modell deutlich besser ab als das tidymodels-Modell, was aber natürlich auch an meiner Vorverarbeitung liegen kann.\n\nDurch die EDA ist ganz klar die Relevanz von Schimpfwörtern zur Erkennung von hate speech hervorgestochen, weswegen es auch wichtig für das tidymodels Rezept war. Leider hat mit tidymodels nicht alles ganz so gut funktioniert, was oft auch an der sehr hohen Rechenzeit war, weswegen hier vielleicht nicht das volle Potenzial ausgeschöpft wurde.\n\nAlles in allem, konnte man durch die EDA sehr viele Rückschlüsse ziehen, wobei für mich vor allem das Bigram-Netz interessant war. Hier konnte man nämlich sehr gut erkennen, wie wichtig der Kontext für die Verwendung von bestimmten Wörtern ist, denn so kann die Bedeutung ganz schnell von einer neutralen Beschreibung zu einer Beleidigung wechseln.\n\n## 7. Quellen\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR version 4.1.3 (2022-03-10)\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\nlocale:\n[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252   \n[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C                   \n[5] LC_TIME=German_Germany.1252    \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] reticulate_1.28           ranger_0.14.1            \n [3] rpart_4.1.16              stopwords_2.3            \n [5] stringi_1.7.6             glue_1.6.2               \n [7] topicmodels_0.2-14        readxl_1.3.1             \n [9] ggraph_2.1.0              igraph_1.4.2             \n[11] sentimentr_2.9.0          quanteda.textstats_0.96.1\n[13] beepr_1.3                 syuzhet_1.0.7            \n[15] tokenizers_0.3.0          remoji_0.1.0             \n[17] fastrtext_0.3.4           naivebayes_0.9.7         \n[19] lsa_0.73.3                SnowballC_0.7.0          \n[21] textrecipes_1.0.3         tidytext_0.4.1           \n[23] wordcloud_2.6             RColorBrewer_1.1-3       \n[25] tm_0.7-11                 NLP_0.2-1                \n[27] pROC_1.18.0               caret_6.0-94             \n[29] lattice_0.20-45           car_3.1-2                \n[31] carData_3.0-5             rstanarm_2.21.4          \n[33] Rcpp_1.0.8                klaR_1.7-3               \n[35] MASS_7.3-55               ggthemes_5.0.0           \n[37] discrim_1.0.1             rlang_1.1.2              \n[39] cowplot_1.1.2             xgboost_1.6.0.1          \n[41] tictoc_1.2                glmnet_4.1-7             \n[43] Matrix_1.5-4              see_0.8.1                \n[45] report_0.5.7              parameters_0.21.0        \n[47] performance_0.10.3        modelbased_0.8.6         \n[49] insight_0.19.2            effectsize_0.8.3         \n[51] datawizard_0.7.1          correlation_0.8.4        \n[53] bayestestR_0.13.1         easystats_0.6.0          \n[55] yardstick_1.1.0           workflowsets_1.0.1       \n[57] workflows_1.1.3           tune_1.1.2               \n[59] rsample_1.2.0             recipes_1.0.9            \n[61] parsnip_1.0.4             modeldata_1.2.0          \n[63] infer_1.0.5               dials_1.2.0              \n[65] scales_1.2.1              broom_1.0.5              \n[67] tidymodels_1.0.0          forcats_0.5.1            \n[69] stringr_1.5.0             dplyr_1.1.2              \n[71] purrr_1.0.1               readr_2.1.2              \n[73] tidyr_1.2.0               tibble_3.2.1             \n[75] ggplot2_3.4.4             tidyverse_1.3.1          \n\nloaded via a namespace (and not attached):\n  [1] ModelMetrics_1.2.2.2 visdat_0.6.0         bit64_4.0.5         \n  [4] knitr_1.37           dygraphs_1.1.1.6     data.table_1.14.8   \n  [7] inline_0.3.19        hardhat_1.3.0        generics_0.1.3      \n [10] GPfit_1.0-8          qdapRegex_0.7.8      combinat_0.0-8      \n [13] proxy_0.4-27         future_1.33.0        nsyllable_1.0.1     \n [16] bit_4.0.5            tzdb_0.3.0           xml2_1.3.3          \n [19] lubridate_1.8.0      httpuv_1.6.6         StanHeaders_2.21.0-7\n [22] assertthat_0.2.1     viridis_0.6.4        gower_1.0.1         \n [25] xfun_0.39            hms_1.1.3            bayesplot_1.10.0    \n [28] evaluate_0.23        promises_1.2.0.1     fansi_1.0.2         \n [31] dbplyr_2.3.2         DBI_1.1.3            htmlwidgets_1.6.2   \n [34] stats4_4.1.3         ellipsis_0.3.2       crosstalk_1.2.1     \n [37] backports_1.4.1      markdown_1.12        RcppParallel_5.1.7  \n [40] vctrs_0.6.1          here_1.0.1           abind_1.4-5         \n [43] withr_2.5.2          ggforce_0.4.1        vroom_1.6.1         \n [46] xts_0.13.1           crayon_1.5.2         labeling_0.4.3      \n [49] pkgconfig_2.0.3      slam_0.1-50          tweenr_2.0.2        \n [52] nlme_3.1-155         nnet_7.3-17          globals_0.16.2      \n [55] questionr_0.7.8      lifecycle_1.0.4      miniUI_0.1.1.1      \n [58] colourpicker_1.3.0   lexicon_1.2.1        modelr_0.1.11       \n [61] rprojroot_2.0.4      cellranger_1.1.0     polyclip_1.10-4     \n [64] matrixStats_0.63.0   loo_2.6.0            boot_1.3-28         \n [67] zoo_1.8-12           reprex_2.0.2         base64enc_0.1-3     \n [70] png_0.1-8            viridisLite_0.4.2    shape_1.4.6         \n [73] parallelly_1.36.0    shinystan_2.6.0      magrittr_2.0.2      \n [76] plyr_1.8.8           audio_0.1-10         threejs_0.3.3       \n [79] compiler_4.1.3       rstantools_2.3.1.1   lme4_1.1-32         \n [82] cli_3.6.0            DiceDesign_1.9       listenv_0.9.0       \n [85] janeaustenr_1.0.0    tidyselect_1.2.0     highr_0.10          \n [88] yaml_2.3.5           ggrepel_0.9.3        grid_4.1.3          \n [91] fastmatch_1.1-3      tools_4.1.3          future.apply_1.11.0 \n [94] parallel_4.1.3       rstudioapi_0.15.0    foreach_1.5.2       \n [97] quanteda_3.3.0       gridExtra_2.3        prodlim_2023.03.31  \n[100] farver_2.1.1         digest_0.6.29        shiny_1.7.2         \n[103] lava_1.7.3           later_1.3.0          httr_1.4.7          \n[106] colorspace_2.0-3     rvest_1.0.3          fs_1.5.2            \n[109] splines_4.1.3        graphlayouts_0.8.4   shinythemes_1.2.0   \n[112] xtable_1.8-4         jsonlite_1.8.4       nloptr_2.0.3        \n[115] tidygraph_1.2.3      timeDate_4032.109    rstan_2.21.7        \n[118] modeltools_0.2-23    ipred_0.9-14         R6_2.5.1            \n[121] lhs_1.1.6            pillar_1.9.0         htmltools_0.5.5     \n[124] mime_0.12            fastmap_1.1.0        minqa_1.2.5         \n[127] DT_0.31              class_7.3-20         codetools_0.2-18    \n[130] pkgbuild_1.4.3       furrr_0.3.1          utf8_1.2.2          \n[133] gtools_3.9.4         shinyjs_2.1.0        survival_3.2-13     \n[136] textclean_0.9.3      rmarkdown_2.25       munsell_0.5.0       \n[139] e1071_1.7-13         iterators_1.0.14     labelled_2.12.0     \n[142] haven_2.4.3          reshape2_1.4.4       gtable_0.3.4        \n```\n:::\n:::\n",
    "supporting": [
      "DS2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}